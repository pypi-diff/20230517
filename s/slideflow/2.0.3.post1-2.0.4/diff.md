# Comparing `tmp/slideflow-2.0.3.post1-py3-none-any.whl.zip` & `tmp/slideflow-2.0.4-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,27 +1,27 @@
-Zip file size: 1839705 bytes, number of entries: 359
+Zip file size: 1849158 bytes, number of entries: 362
 -rw-rw-r--  2.0 unx     1411 b- defN 23-Apr-09 06:29 slideflow/__init__.py
 -rw-rw-r--  2.0 unx     1662 b- defN 23-Apr-09 06:29 slideflow/_backend.py
--rw-rw-r--  2.0 unx      503 b- defN 23-Apr-23 04:02 slideflow/_version.py
--rw-rw-r--  2.0 unx   159998 b- defN 23-Apr-23 03:49 slideflow/dataset.py
--rw-rw-r--  2.0 unx     3866 b- defN 23-Apr-23 03:49 slideflow/errors.py
+-rw-rw-r--  2.0 unx      497 b- defN 23-May-17 16:22 slideflow/_version.py
+-rw-rw-r--  2.0 unx   160662 b- defN 23-May-17 15:54 slideflow/dataset.py
+-rw-rw-r--  2.0 unx     3922 b- defN 23-May-17 15:54 slideflow/errors.py
 -rw-rw-r--  2.0 unx    40025 b- defN 23-Apr-23 03:48 slideflow/heatmap.py
--rw-rw-r--  2.0 unx    25615 b- defN 23-Apr-23 03:49 slideflow/mosaic.py
--rw-rw-r--  2.0 unx   168044 b- defN 23-Apr-23 03:49 slideflow/project.py
+-rw-rw-r--  2.0 unx    26008 b- defN 23-May-17 15:55 slideflow/mosaic.py
+-rw-rw-r--  2.0 unx   169434 b- defN 23-May-17 15:51 slideflow/project.py
 -rw-rw-r--  2.0 unx    33332 b- defN 23-Apr-19 02:21 slideflow/project_utils.py
 -rw-rw-r--  2.0 unx      978 b- defN 22-Jul-18 12:12 slideflow/sample_actions.py
 -rw-rw-r--  2.0 unx     1195 b- defN 23-Apr-09 06:29 slideflow/biscuit/__init__.py
 -rw-rw-r--  2.0 unx     4281 b- defN 23-Apr-09 06:29 slideflow/biscuit/delong.py
 -rw-rw-r--  2.0 unx      318 b- defN 23-Apr-09 06:29 slideflow/biscuit/errors.py
 -rw-rw-r--  2.0 unx    46729 b- defN 23-Apr-09 06:29 slideflow/biscuit/experiment.py
 -rw-rw-r--  2.0 unx     1260 b- defN 23-Apr-09 06:29 slideflow/biscuit/hp.py
 -rw-rw-r--  2.0 unx    21373 b- defN 23-Apr-09 06:29 slideflow/biscuit/threshold.py
 -rw-rw-r--  2.0 unx    17143 b- defN 23-Apr-09 06:29 slideflow/biscuit/utils.py
--rw-rw-r--  2.0 unx    26315 b- defN 23-Apr-23 03:49 slideflow/cellseg/__init__.py
--rw-rw-r--  2.0 unx     5454 b- defN 23-Mar-01 23:20 slideflow/cellseg/seg_utils.py
+-rw-rw-r--  2.0 unx    26315 b- defN 23-May-17 15:51 slideflow/cellseg/__init__.py
+-rw-rw-r--  2.0 unx     5454 b- defN 23-May-17 15:51 slideflow/cellseg/seg_utils.py
 -rw-rw-r--  2.0 unx      444 b- defN 23-Apr-09 06:29 slideflow/clam/__init__.py
 -rw-rw-r--  2.0 unx      116 b- defN 22-Oct-06 15:16 slideflow/experimental/__init__.py
 -rw-rw-r--  2.0 unx    17224 b- defN 23-Feb-01 21:03 slideflow/experimental/embedding_search.py
 -rw-rw-r--  2.0 unx      273 b- defN 23-Feb-01 21:03 slideflow/gan/__init__.py
 -rw-rw-r--  2.0 unx    24993 b- defN 23-Apr-09 06:29 slideflow/gan/interpolate.py
 -rw-rw-r--  2.0 unx      949 b- defN 23-Feb-01 21:00 slideflow/gan/utils.py
 -rw-rw-r--  2.0 unx       45 b- defN 22-Oct-22 03:43 slideflow/gan/stylegan2/__init__.py
@@ -150,25 +150,25 @@
 -rw-rw-r--  2.0 unx     9460 b- defN 23-Apr-05 13:33 slideflow/gan/stylegan3/stylegan3/viz/pickle_widget.py
 -rw-rw-r--  2.0 unx    24417 b- defN 22-Oct-30 14:59 slideflow/gan/stylegan3/stylegan3/viz/renderer.py
 -rw-rw-r--  2.0 unx     5573 b- defN 23-Apr-03 13:00 slideflow/gan/stylegan3/stylegan3/viz/stylemix_widget.py
 -rw-rw-r--  2.0 unx     5825 b- defN 22-Oct-21 22:00 slideflow/gan/stylegan3/stylegan3/viz/thumb_widget.py
 -rw-rw-r--  2.0 unx     3845 b- defN 22-Oct-21 22:00 slideflow/gan/stylegan3/stylegan3/viz/trunc_noise_widget.py
 -rw-rw-r--  2.0 unx    15662 b- defN 23-Apr-09 06:29 slideflow/grad/__init__.py
 -rw-rw-r--  2.0 unx     7376 b- defN 23-Feb-01 21:03 slideflow/grad/plot_utils.py
--rw-rw-r--  2.0 unx    11715 b- defN 23-Apr-23 03:49 slideflow/io/__init__.py
+-rw-rw-r--  2.0 unx    11715 b- defN 23-May-17 15:51 slideflow/io/__init__.py
 -rw-rw-r--  2.0 unx    10541 b- defN 22-Jul-18 12:12 slideflow/io/gaussian.py
 -rw-rw-r--  2.0 unx     9918 b- defN 23-Apr-09 06:29 slideflow/io/io_utils.py
--rw-rw-r--  2.0 unx    34511 b- defN 23-Apr-23 03:49 slideflow/io/tensorflow.py
--rw-rw-r--  2.0 unx    45085 b- defN 23-Apr-23 03:49 slideflow/io/torch.py
+-rw-rw-r--  2.0 unx    34511 b- defN 23-May-17 15:51 slideflow/io/tensorflow.py
+-rw-rw-r--  2.0 unx    45085 b- defN 23-May-17 15:51 slideflow/io/torch.py
 -rw-rw-r--  2.0 unx       68 b- defN 23-Mar-13 02:04 slideflow/io/preservedsite/__init__.py
 -rw-rw-r--  2.0 unx     8419 b- defN 23-Mar-13 02:04 slideflow/io/preservedsite/crossfolds.py
 -rw-rw-r--  2.0 unx      284 b- defN 23-Apr-09 06:29 slideflow/mil/__init__.py
 -rw-rw-r--  2.0 unx    14819 b- defN 23-Apr-09 06:29 slideflow/mil/_params.py
 -rw-rw-r--  2.0 unx     5160 b- defN 23-Apr-14 13:28 slideflow/mil/data.py
--rw-rw-r--  2.0 unx    15565 b- defN 23-Apr-21 21:46 slideflow/mil/eval.py
+-rw-rw-r--  2.0 unx    15507 b- defN 23-May-17 15:45 slideflow/mil/eval.py
 -rw-rw-r--  2.0 unx     3890 b- defN 23-Apr-09 06:29 slideflow/mil/clam/__init__.py
 -rw-rw-r--  2.0 unx     4334 b- defN 23-Apr-09 06:29 slideflow/mil/clam/create_attention.py
 -rw-rw-r--  2.0 unx     1131 b- defN 23-Apr-09 06:29 slideflow/mil/clam/datasets/__init__.py
 -rw-rw-r--  2.0 unx    14990 b- defN 23-Apr-09 06:29 slideflow/mil/clam/datasets/dataset_generic.py
 -rw-rw-r--  2.0 unx     5914 b- defN 23-Apr-09 06:29 slideflow/mil/clam/utils/__init__.py
 -rw-rw-r--  2.0 unx    19782 b- defN 23-Apr-09 06:29 slideflow/mil/clam/utils/core_utils.py
 -rw-rw-r--  2.0 unx     4150 b- defN 23-Apr-09 06:29 slideflow/mil/clam/utils/eval_utils.py
@@ -176,84 +176,87 @@
 -rw-rw-r--  2.0 unx     3497 b- defN 23-Apr-09 06:29 slideflow/mil/clam/utils/loss_utils.py
 -rw-rw-r--  2.0 unx      185 b- defN 23-Apr-09 06:29 slideflow/mil/models/__init__.py
 -rw-rw-r--  2.0 unx      378 b- defN 23-Apr-09 06:29 slideflow/mil/models/_utils.py
 -rw-rw-r--  2.0 unx     3239 b- defN 23-Apr-21 21:43 slideflow/mil/models/att_mil.py
 -rw-rw-r--  2.0 unx    12816 b- defN 23-Apr-09 06:29 slideflow/mil/models/clam.py
 -rw-rw-r--  2.0 unx     3865 b- defN 23-Apr-18 22:07 slideflow/mil/models/mil_fc.py
 -rw-rw-r--  2.0 unx     4137 b- defN 23-Apr-09 06:29 slideflow/mil/models/transmil.py
--rw-rw-r--  2.0 unx    15008 b- defN 23-Apr-12 04:31 slideflow/mil/train/__init__.py
--rw-rw-r--  2.0 unx     8214 b- defN 23-Apr-23 03:49 slideflow/mil/train/_fastai.py
+-rw-rw-r--  2.0 unx    15008 b- defN 23-May-17 02:53 slideflow/mil/train/__init__.py
+-rw-rw-r--  2.0 unx     8214 b- defN 23-May-17 15:51 slideflow/mil/train/_fastai.py
 -rw-rw-r--  2.0 unx     7795 b- defN 23-Apr-09 06:29 slideflow/mil/train/_legacy.py
 -rw-rw-r--  2.0 unx     7485 b- defN 23-Apr-09 06:29 slideflow/model/__init__.py
 -rw-rw-r--  2.0 unx     1879 b- defN 23-Mar-13 02:04 slideflow/model/adv_utils.py
 -rw-rw-r--  2.0 unx    23588 b- defN 23-Apr-19 02:19 slideflow/model/base.py
--rw-rw-r--  2.0 unx    55334 b- defN 23-Apr-23 03:49 slideflow/model/features.py
--rw-rw-r--  2.0 unx   110908 b- defN 23-Apr-23 03:49 slideflow/model/tensorflow.py
+-rw-rw-r--  2.0 unx    55541 b- defN 23-May-17 15:51 slideflow/model/features.py
+-rw-rw-r--  2.0 unx   110908 b- defN 23-May-17 15:51 slideflow/model/tensorflow.py
 -rw-rw-r--  2.0 unx    22547 b- defN 23-Apr-03 05:27 slideflow/model/tensorflow_utils.py
--rw-rw-r--  2.0 unx   103271 b- defN 23-Apr-23 03:49 slideflow/model/torch.py
--rw-rw-r--  2.0 unx    17005 b- defN 23-Apr-23 03:49 slideflow/model/torch_utils.py
+-rw-rw-r--  2.0 unx   103271 b- defN 23-May-17 15:51 slideflow/model/torch.py
+-rw-rw-r--  2.0 unx    17005 b- defN 23-May-17 15:51 slideflow/model/torch_utils.py
 -rw-rw-r--  2.0 unx      394 b- defN 23-Apr-09 06:29 slideflow/model/extractors/__init__.py
 -rw-rw-r--  2.0 unx     3708 b- defN 23-Apr-09 06:29 slideflow/model/extractors/_factory.py
 -rw-rw-r--  2.0 unx     4544 b- defN 23-Apr-09 06:29 slideflow/model/extractors/_factory_tensorflow.py
--rw-rw-r--  2.0 unx     5711 b- defN 23-Apr-23 03:49 slideflow/model/extractors/_factory_torch.py
+-rw-rw-r--  2.0 unx     5711 b- defN 23-May-17 15:51 slideflow/model/extractors/_factory_torch.py
 -rw-rw-r--  2.0 unx     1570 b- defN 23-Apr-09 06:29 slideflow/model/extractors/_registry.py
--rw-rw-r--  2.0 unx     2646 b- defN 23-Apr-23 03:49 slideflow/model/extractors/_slide.py
--rw-rw-r--  2.0 unx    25681 b- defN 23-Apr-23 03:49 slideflow/model/extractors/ctranspath.py
--rw-rw-r--  2.0 unx    12045 b- defN 23-Apr-23 03:49 slideflow/model/extractors/retccl.py
--rw-rw-r--  2.0 unx    26156 b- defN 23-Apr-09 06:29 slideflow/norm/__init__.py
+-rw-rw-r--  2.0 unx     2646 b- defN 23-May-17 15:51 slideflow/model/extractors/_slide.py
+-rw-rw-r--  2.0 unx    25681 b- defN 23-May-17 15:51 slideflow/model/extractors/ctranspath.py
+-rw-rw-r--  2.0 unx    12045 b- defN 23-May-17 15:51 slideflow/model/extractors/retccl.py
+-rw-rw-r--  2.0 unx    26156 b- defN 23-May-17 15:51 slideflow/norm/__init__.py
 -rw-rw-r--  2.0 unx     1605 b- defN 23-Apr-09 06:29 slideflow/norm/augment.py
 -rw-rw-r--  2.0 unx    13438 b- defN 23-Apr-09 06:29 slideflow/norm/macenko.py
 -rw-rw-r--  2.0 unx   177672 b- defN 22-Jul-15 00:02 slideflow/norm/norm_tile.jpg
 -rw-rw-r--  2.0 unx    16964 b- defN 23-Apr-09 06:29 slideflow/norm/reinhard.py
 -rw-rw-r--  2.0 unx    15314 b- defN 23-Apr-09 06:29 slideflow/norm/utils.py
 -rw-rw-r--  2.0 unx     7836 b- defN 23-Apr-09 06:29 slideflow/norm/vahadane.py
 -rw-rw-r--  2.0 unx    11998 b- defN 23-Apr-09 06:29 slideflow/norm/tensorflow/__init__.py
 -rw-rw-r--  2.0 unx     5879 b- defN 22-Jul-15 00:02 slideflow/norm/tensorflow/color.py
--rw-rw-r--  2.0 unx    20759 b- defN 23-Apr-09 06:29 slideflow/norm/tensorflow/macenko.py
+-rw-rw-r--  2.0 unx    22672 b- defN 23-May-17 15:56 slideflow/norm/tensorflow/macenko.py
 -rw-rw-r--  2.0 unx    26169 b- defN 23-Apr-09 06:29 slideflow/norm/tensorflow/reinhard.py
 -rw-rw-r--  2.0 unx     1685 b- defN 23-Apr-09 06:29 slideflow/norm/tensorflow/utils.py
 -rw-rw-r--  2.0 unx    12095 b- defN 23-Apr-19 02:24 slideflow/norm/torch/__init__.py
 -rw-rw-r--  2.0 unx     7826 b- defN 22-Aug-06 13:13 slideflow/norm/torch/color.py
--rw-rw-r--  2.0 unx    15296 b- defN 23-Apr-23 03:49 slideflow/norm/torch/macenko.py
+-rw-rw-r--  2.0 unx    15306 b- defN 23-May-17 15:56 slideflow/norm/torch/macenko.py
 -rw-rw-r--  2.0 unx    24997 b- defN 23-Apr-19 00:55 slideflow/norm/torch/reinhard.py
 -rw-rw-r--  2.0 unx     1673 b- defN 23-Apr-09 06:29 slideflow/norm/torch/utils.py
--rw-rw-r--  2.0 unx      458 b- defN 23-Mar-13 02:04 slideflow/simclr/__init__.py
+-rw-rw-r--  2.0 unx      458 b- defN 23-May-17 15:51 slideflow/simclr/__init__.py
 -rw-rw-r--  2.0 unx        6 b- defN 23-Feb-07 02:07 slideflow/simclr/simclr/__init__.py
--rw-rw-r--  2.0 unx    21046 b- defN 23-Apr-21 22:18 slideflow/simclr/simclr/tf2/__init__.py
--rw-rw-r--  2.0 unx    10701 b- defN 23-Apr-17 17:52 slideflow/simclr/simclr/tf2/data.py
--rw-rw-r--  2.0 unx    18550 b- defN 23-Feb-03 23:00 slideflow/simclr/simclr/tf2/data_util.py
+-rw-rw-r--  2.0 unx    21046 b- defN 23-May-17 16:22 slideflow/simclr/simclr/tf2/__init__.py
+-rw-rw-r--  2.0 unx    10701 b- defN 23-May-17 16:22 slideflow/simclr/simclr/tf2/data.py
+-rw-rw-r--  2.0 unx    18550 b- defN 23-May-17 16:22 slideflow/simclr/simclr/tf2/data_util.py
 -rw-rw-r--  2.0 unx     6505 b- defN 23-Apr-17 18:03 slideflow/simclr/simclr/tf2/lars_optimizer.py
 -rw-rw-r--  2.0 unx     2997 b- defN 23-Jan-23 19:16 slideflow/simclr/simclr/tf2/metrics.py
 -rw-rw-r--  2.0 unx    12256 b- defN 23-Feb-03 23:00 slideflow/simclr/simclr/tf2/model.py
 -rw-rw-r--  2.0 unx     4983 b- defN 23-Jan-23 19:16 slideflow/simclr/simclr/tf2/objective.py
 -rw-rw-r--  2.0 unx    28397 b- defN 23-Feb-03 23:00 slideflow/simclr/simclr/tf2/resnet.py
 -rw-rw-r--  2.0 unx     6524 b- defN 23-Feb-03 23:00 slideflow/simclr/simclr/tf2/run.py
--rw-rw-r--  2.0 unx     9517 b- defN 23-Feb-06 18:24 slideflow/simclr/simclr/tf2/utils.py
--rw-rw-r--  2.0 unx   114953 b- defN 23-Apr-23 03:49 slideflow/slide/__init__.py
+-rw-rw-r--  2.0 unx     9517 b- defN 23-May-17 16:22 slideflow/simclr/simclr/tf2/utils.py
+-rw-rw-r--  2.0 unx   115204 b- defN 23-May-17 15:54 slideflow/slide/__init__.py
 -rw-rw-r--  2.0 unx    19076 b- defN 23-Apr-21 17:48 slideflow/slide/report.py
 -rw-rw-r--  2.0 unx    30934 b- defN 23-Apr-09 06:29 slideflow/slide/slideflow-logo-name-small.jpg
 -rw-rw-r--  2.0 unx     5516 b- defN 23-Apr-10 16:45 slideflow/slide/utils.py
--rw-rw-r--  2.0 unx      708 b- defN 23-Mar-01 23:20 slideflow/slide/backends/__init__.py
--rw-rw-r--  2.0 unx    14008 b- defN 23-Apr-09 06:29 slideflow/slide/backends/cucim.py
--rw-rw-r--  2.0 unx    22391 b- defN 23-Apr-23 03:49 slideflow/slide/backends/vips.py
--rw-rw-r--  2.0 unx      117 b- defN 23-Apr-23 03:49 slideflow/slide/qc/__init__.py
+-rw-rw-r--  2.0 unx     1035 b- defN 23-May-17 15:54 slideflow/slide/backends/__init__.py
+-rw-rw-r--  2.0 unx    14301 b- defN 23-May-17 15:54 slideflow/slide/backends/cucim.py
+-rw-rw-r--  2.0 unx    22863 b- defN 23-May-17 15:54 slideflow/slide/backends/vips.py
+-rw-rw-r--  2.0 unx      117 b- defN 23-May-17 15:51 slideflow/slide/qc/__init__.py
+-rw-rw-r--  2.0 unx     8151 b- defN 23-Apr-27 15:40 slideflow/slide/qc/deepfocus.py
 -rw-rw-r--  2.0 unx     1010 b- defN 22-Nov-29 16:52 slideflow/slide/qc/deepfocus_qc.py
--rw-rw-r--  2.0 unx     4304 b- defN 23-Apr-23 03:49 slideflow/slide/qc/gaussian.py
--rw-rw-r--  2.0 unx     5232 b- defN 23-Apr-23 03:49 slideflow/slide/qc/otsu.py
+-rw-rw-r--  2.0 unx     4304 b- defN 23-May-17 15:51 slideflow/slide/qc/gaussian.py
+-rw-rw-r--  2.0 unx     5341 b- defN 23-Apr-27 15:40 slideflow/slide/qc/gaussian_v2.py
+-rw-rw-r--  2.0 unx     5232 b- defN 23-May-17 15:51 slideflow/slide/qc/otsu.py
 -rw-rw-r--  2.0 unx     3028 b- defN 23-Mar-13 02:04 slideflow/slide/qc/saver.py
--rw-rw-r--  2.0 unx     4676 b- defN 23-Apr-23 03:49 slideflow/slide/qc/strided_dl.py
+-rw-rw-r--  2.0 unx     4676 b- defN 23-May-17 15:51 slideflow/slide/qc/strided_dl.py
+-rw-rw-r--  2.0 unx    13029 b- defN 23-Apr-27 15:40 slideflow/slide/qc/strided_qc.py
 -rw-rw-r--  2.0 unx      390 b- defN 23-Feb-01 21:02 slideflow/stats/__init__.py
 -rw-rw-r--  2.0 unx     4293 b- defN 23-Apr-09 06:29 slideflow/stats/delong.py
 -rw-rw-r--  2.0 unx    35785 b- defN 23-Apr-09 06:29 slideflow/stats/metrics.py
 -rw-rw-r--  2.0 unx     5757 b- defN 23-Apr-09 06:29 slideflow/stats/plot.py
--rw-rw-r--  2.0 unx    43101 b- defN 23-Apr-23 03:49 slideflow/stats/slidemap.py
--rw-rw-r--  2.0 unx     3261 b- defN 23-Apr-09 06:29 slideflow/stats/stats_utils.py
--rw-rw-r--  2.0 unx    77576 b- defN 23-Apr-09 06:29 slideflow/studio/__init__.py
+-rw-rw-r--  2.0 unx    43101 b- defN 23-May-17 15:51 slideflow/stats/slidemap.py
+-rw-rw-r--  2.0 unx     3261 b- defN 23-May-17 15:51 slideflow/stats/stats_utils.py
+-rw-rw-r--  2.0 unx    77576 b- defN 23-May-17 15:51 slideflow/studio/__init__.py
 -rw-rw-r--  2.0 unx     2187 b- defN 23-Apr-09 06:29 slideflow/studio/__main__.py
--rw-rw-r--  2.0 unx    19662 b- defN 23-Apr-23 03:49 slideflow/studio/_renderer.py
+-rw-rw-r--  2.0 unx    19662 b- defN 23-May-17 15:51 slideflow/studio/_renderer.py
 -rw-rw-r--  2.0 unx     3686 b- defN 23-Apr-09 06:29 slideflow/studio/utils.py
 -rw-rw-r--  2.0 unx        8 b- defN 23-Apr-09 06:29 slideflow/studio/gui/__init__.py
 -rw-rw-r--  2.0 unx    14387 b- defN 23-Apr-09 06:29 slideflow/studio/gui/_glfw.py
 -rw-rw-r--  2.0 unx     4116 b- defN 23-Apr-09 06:29 slideflow/studio/gui/annotator.py
 -rw-rw-r--  2.0 unx    11035 b- defN 23-Apr-09 06:29 slideflow/studio/gui/gl_utils.py
 -rw-rw-r--  2.0 unx    10029 b- defN 23-Apr-09 06:29 slideflow/studio/gui/imgui_utils.py
 -rw-rw-r--  2.0 unx    29775 b- defN 23-Apr-09 06:29 slideflow/studio/gui/logo_dark_outline.png
@@ -306,56 +309,56 @@
 -rw-rw-r--  2.0 unx     7568 b- defN 23-Apr-09 06:29 slideflow/studio/gui/icons/error.png
 -rw-rw-r--  2.0 unx     7286 b- defN 23-Apr-09 06:29 slideflow/studio/gui/icons/info.png
 -rw-rw-r--  2.0 unx   125763 b- defN 23-Apr-09 06:29 slideflow/studio/gui/icons/logo.png
 -rw-rw-r--  2.0 unx     7181 b- defN 23-Apr-09 06:29 slideflow/studio/gui/icons/success.png
 -rw-rw-r--  2.0 unx     6817 b- defN 23-Apr-09 06:29 slideflow/studio/gui/icons/warn.png
 -rw-rw-r--  2.0 unx      107 b- defN 23-Apr-09 06:29 slideflow/studio/gui/viewer/__init__.py
 -rw-rw-r--  2.0 unx     7874 b- defN 23-Apr-21 17:43 slideflow/studio/gui/viewer/_mosaic.py
--rw-rw-r--  2.0 unx    26041 b- defN 23-Apr-18 20:39 slideflow/studio/gui/viewer/_slide.py
+-rw-rw-r--  2.0 unx    26041 b- defN 23-May-17 15:51 slideflow/studio/gui/viewer/_slide.py
 -rw-rw-r--  2.0 unx    14452 b- defN 23-Apr-09 06:29 slideflow/studio/gui/viewer/_viewer.py
 -rw-rw-r--  2.0 unx      439 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/__init__.py
 -rw-rw-r--  2.0 unx      735 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/_utils.py
--rw-rw-r--  2.0 unx     4264 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/capture.py
--rw-rw-r--  2.0 unx     5412 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/extensions.py
+-rw-rw-r--  2.0 unx     4362 b- defN 23-May-17 15:54 slideflow/studio/widgets/capture.py
+-rw-rw-r--  2.0 unx     5412 b- defN 23-May-17 15:51 slideflow/studio/widgets/extensions.py
 -rw-rw-r--  2.0 unx    16890 b- defN 23-Apr-14 13:28 slideflow/studio/widgets/heatmap.py
 -rw-rw-r--  2.0 unx     3842 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/layer_umap.py
 -rw-rw-r--  2.0 unx    24474 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/model.py
--rw-rw-r--  2.0 unx    14307 b- defN 23-Apr-23 03:49 slideflow/studio/widgets/mosaic.py
+-rw-rw-r--  2.0 unx    14307 b- defN 23-May-17 15:51 slideflow/studio/widgets/mosaic.py
 -rw-rw-r--  2.0 unx     2597 b- defN 23-Mar-19 15:05 slideflow/studio/widgets/mosaic_experimental.py
 -rw-rw-r--  2.0 unx     4662 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/performance.py
 -rw-rw-r--  2.0 unx     6437 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/picam.py
 -rw-rw-r--  2.0 unx     7726 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/project.py
 -rw-rw-r--  2.0 unx     5983 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/seed_map.py
 -rw-rw-r--  2.0 unx    19875 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/segment.py
 -rw-rw-r--  2.0 unx     2071 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/settings.py
--rw-rw-r--  2.0 unx    31018 b- defN 23-Apr-14 13:28 slideflow/studio/widgets/slide.py
+-rw-rw-r--  2.0 unx    31018 b- defN 23-Apr-27 17:21 slideflow/studio/widgets/slide.py
 -rw-rw-r--  2.0 unx    16402 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/stylegan.py
--rw-rw-r--  2.0 unx    32357 b- defN 23-Apr-23 03:52 slideflow/test/__init__.py
+-rw-rw-r--  2.0 unx    32357 b- defN 23-Apr-24 21:32 slideflow/test/__init__.py
 -rw-rw-r--  2.0 unx    12446 b- defN 23-Feb-01 21:02 slideflow/test/dataset_test.py
 -rw-rw-r--  2.0 unx     9560 b- defN 23-Mar-26 19:33 slideflow/test/functional.py
 -rw-rw-r--  2.0 unx     8052 b- defN 23-Apr-09 06:29 slideflow/test/model_test.py
 -rw-rw-r--  2.0 unx    12098 b- defN 23-Mar-01 23:20 slideflow/test/norm_test.py
 -rw-rw-r--  2.0 unx     2909 b- defN 23-Apr-09 06:29 slideflow/test/slide_test.py
 -rw-rw-r--  2.0 unx    11481 b- defN 23-Mar-13 02:04 slideflow/test/stats_test.py
 -rw-rw-r--  2.0 unx    11752 b- defN 23-Apr-09 06:29 slideflow/test/utils.py
 -rw-rw-r--  2.0 unx      891 b- defN 23-Mar-13 02:04 slideflow/tfrecord/__init__.py
 -rw-rw-r--  2.0 unx     2905 b- defN 22-Dec-02 04:52 slideflow/tfrecord/iterator_utils.py
 -rw-rw-r--  2.0 unx    15505 b- defN 23-Apr-21 04:57 slideflow/tfrecord/reader.py
 -rw-rw-r--  2.0 unx     5637 b- defN 22-Jul-18 12:12 slideflow/tfrecord/writer.py
 -rw-rw-r--  2.0 unx      179 b- defN 22-Jul-18 12:12 slideflow/tfrecord/tools/__init__.py
 -rw-rw-r--  2.0 unx      310 b- defN 22-Jul-18 12:12 slideflow/tfrecord/torch/__init__.py
 -rw-rw-r--  2.0 unx     7857 b- defN 22-Jul-18 12:12 slideflow/tfrecord/torch/dataset.py
--rw-rw-r--  2.0 unx    41607 b- defN 23-Apr-23 04:00 slideflow/util/__init__.py
+-rw-rw-r--  2.0 unx    41943 b- defN 23-May-17 15:52 slideflow/util/__init__.py
 -rw-rw-r--  2.0 unx      738 b- defN 22-Jul-15 00:02 slideflow/util/colors.py
 -rw-rw-r--  2.0 unx    17912 b- defN 22-Jul-18 12:12 slideflow/util/example_pb2.py
 -rw-rw-r--  2.0 unx     4468 b- defN 23-Feb-01 21:02 slideflow/util/log_utils.py
 -rw-rw-r--  2.0 unx     4381 b- defN 22-Jul-18 12:12 slideflow/util/neptune_utils.py
 -rw-rw-r--  2.0 unx    20061 b- defN 23-Apr-09 06:29 slideflow/util/smac_utils.py
--rw-rw-r--  2.0 unx     8064 b- defN 23-Apr-23 03:49 slideflow/util/tfrecord2idx.py
--rwxrwxr-x  2.0 unx    14085 b- defN 23-Apr-23 04:02 slideflow-2.0.3.post1.data/scripts/slideflow-studio
--rwxrwxr-x  2.0 unx    14085 b- defN 23-Apr-10 13:18 slideflow-2.0.3.post1.data/scripts/slideflow-studio.py
--rw-rw-r--  2.0 unx    35149 b- defN 23-Apr-23 04:02 slideflow-2.0.3.post1.dist-info/LICENSE
--rw-rw-r--  2.0 unx    13030 b- defN 23-Apr-23 04:02 slideflow-2.0.3.post1.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Apr-23 04:02 slideflow-2.0.3.post1.dist-info/WHEEL
--rw-rw-r--  2.0 unx       10 b- defN 23-Apr-23 04:02 slideflow-2.0.3.post1.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx    35690 b- defN 23-Apr-23 04:02 slideflow-2.0.3.post1.dist-info/RECORD
-359 files, 4775687 bytes uncompressed, 1781985 bytes compressed:  62.7%
+-rw-rw-r--  2.0 unx     8064 b- defN 23-May-17 15:51 slideflow/util/tfrecord2idx.py
+-rwxrwxr-x  2.0 unx    14085 b- defN 23-May-17 16:22 slideflow-2.0.4.data/scripts/slideflow-studio
+-rwxrwxr-x  2.0 unx    14085 b- defN 23-Apr-10 13:18 slideflow-2.0.4.data/scripts/slideflow-studio.py
+-rw-rw-r--  2.0 unx    35149 b- defN 23-May-17 16:22 slideflow-2.0.4.dist-info/LICENSE
+-rw-rw-r--  2.0 unx    13038 b- defN 23-May-17 16:22 slideflow-2.0.4.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-May-17 16:22 slideflow-2.0.4.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       10 b- defN 23-May-17 16:22 slideflow-2.0.4.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx    35917 b- defN 23-May-17 16:22 slideflow-2.0.4.dist-info/RECORD
+362 files, 4808789 bytes uncompressed, 1791102 bytes compressed:  62.8%
```

## zipnote {}

```diff
@@ -705,29 +705,38 @@
 
 Filename: slideflow/slide/backends/vips.py
 Comment: 
 
 Filename: slideflow/slide/qc/__init__.py
 Comment: 
 
+Filename: slideflow/slide/qc/deepfocus.py
+Comment: 
+
 Filename: slideflow/slide/qc/deepfocus_qc.py
 Comment: 
 
 Filename: slideflow/slide/qc/gaussian.py
 Comment: 
 
+Filename: slideflow/slide/qc/gaussian_v2.py
+Comment: 
+
 Filename: slideflow/slide/qc/otsu.py
 Comment: 
 
 Filename: slideflow/slide/qc/saver.py
 Comment: 
 
 Filename: slideflow/slide/qc/strided_dl.py
 Comment: 
 
+Filename: slideflow/slide/qc/strided_qc.py
+Comment: 
+
 Filename: slideflow/stats/__init__.py
 Comment: 
 
 Filename: slideflow/stats/delong.py
 Comment: 
 
 Filename: slideflow/stats/metrics.py
@@ -1050,29 +1059,29 @@
 
 Filename: slideflow/util/smac_utils.py
 Comment: 
 
 Filename: slideflow/util/tfrecord2idx.py
 Comment: 
 
-Filename: slideflow-2.0.3.post1.data/scripts/slideflow-studio
+Filename: slideflow-2.0.4.data/scripts/slideflow-studio
 Comment: 
 
-Filename: slideflow-2.0.3.post1.data/scripts/slideflow-studio.py
+Filename: slideflow-2.0.4.data/scripts/slideflow-studio.py
 Comment: 
 
-Filename: slideflow-2.0.3.post1.dist-info/LICENSE
+Filename: slideflow-2.0.4.dist-info/LICENSE
 Comment: 
 
-Filename: slideflow-2.0.3.post1.dist-info/METADATA
+Filename: slideflow-2.0.4.dist-info/METADATA
 Comment: 
 
-Filename: slideflow-2.0.3.post1.dist-info/WHEEL
+Filename: slideflow-2.0.4.dist-info/WHEEL
 Comment: 
 
-Filename: slideflow-2.0.3.post1.dist-info/top_level.txt
+Filename: slideflow-2.0.4.dist-info/top_level.txt
 Comment: 
 
-Filename: slideflow-2.0.3.post1.dist-info/RECORD
+Filename: slideflow-2.0.4.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## slideflow/_version.py

```diff
@@ -4,18 +4,18 @@
 # unpacked source archive. Distribution tarballs contain a pre-generated copy
 # of this file.
 
 import json
 
 version_json = '''
 {
- "date": "2023-04-22T22:55:10-0500",
+ "date": "2023-05-17T11:18:57-0500",
  "dirty": false,
  "error": null,
- "full-revisionid": "95f96082e8a3a81ae8bd15b7b9fef5aa5f0b08ef",
- "version": "2.0.3-post1"
+ "full-revisionid": "26ce5cf0d34b65514223967ffc0628d0b5031d05",
+ "version": "2.0.4"
 }
 '''  # END VERSION_JSON
 
 
 def get_versions():
     return json.loads(version_json)
```

## slideflow/dataset.py

```diff
@@ -149,14 +149,24 @@
             slide = sf.WSI(path, **wsi_kwargs)
         if qc:
             slide.qc(method=qc, **qc_kwargs)
         return slide
     except errors.MissingROIError:
         log.debug(f'Missing ROI for slide {path}; skipping')
         return None
+    except errors.IncompatibleBackendError:
+        log.error('Slide {} has type {}, which is incompatible with the active '
+                  'slide reading backend, {}. Consider using a different '
+                  'backend, which can be set with the environmental variable '
+                  'SF_SLIDE_BACKEND. See https://slideflow.dev/installation/#cucim-vs-libvips '
+                  'for more information.'.format(
+                    path,
+                    sf.util.path_to_ext(path).upper(),
+                    sf.slide_backend()
+                  ))
     except errors.SlideLoadError as e:
         log.error(f'Error loading slide {path}: {e}. Skipping')
         return None
     except errors.QCError as e:
         log.error(e)
         return None
     except errors.TileCorruptionError:
@@ -1369,16 +1379,16 @@
         Extracted tiles are either saved in TFRecord format
         (``save_tfrecords=True``, default) or as loose \*.jpg / \*.png images
         (``save_tiles=True``). TFRecords or image tiles are saved in the
         the tfrecord and tile directories configured by
         :class:`slideflow.Dataset`.
 
         Keyword Args:
-            save_tiles (bool): Save images of extracted tiles to
-                project tile directory. Defaults to False.
+            save_tiles (bool, optional): Save tile images in loose format.
+                Defaults to False.
             save_tfrecords (bool): Save compressed image data from
                 extracted tiles into TFRecords in the corresponding TFRecord
                 directory. Defaults to True.
             source (str, optional): Name of dataset source from which to select
                 slides for extraction. Defaults to None. If not provided, will
                 default to all sources in project.
             stride_div (int): Stride divisor for tile extraction.
@@ -1465,14 +1475,16 @@
                 with more than this proportion of blur will be discarded.
                 Only used if qc=True. Defaults to 0.6.
             qc_mpp (float, optional): Microns-per-pixel indicating image
                 magnification level at which quality control is performed.
                 Defaults to mpp=4 (effective magnification 2.5 X)
             dry_run (bool, optional): Determine tiles that would be extracted,
                 but do not export any images. Defaults to None.
+            max_tiles (int, optional): Only extract this many tiles per slide.
+                Defaults to None.
 
         Returns:
             Dictionary mapping slide paths to each slide's SlideReport
             (:class:`slideflow.slide.report.SlideReport`)
         """
         if not self.tile_px or not self.tile_um:
             raise errors.DatasetError(
@@ -1942,15 +1954,15 @@
                 Defaults to False.
 
         """
         if splits is None:
             temp_dir = tempfile.TemporaryDirectory()
             splits = join(temp_dir.name, '_splits.json')
         else:
-            temp_file = None
+            temp_dir = None
         crossval_splits = []
         for k_fold_iter in range(k):
             split_kw = dict(
                 labels=labels,
                 val_strategy=('k-fold-preserved-site' if preserved_site
                               else 'k-fold'),
                 val_k_fold=k,
```

## slideflow/errors.py

```diff
@@ -125,15 +125,16 @@
 class SlideNotFoundError(SlideError):
     pass
 
 
 class SlideMissingMPPError(SlideLoadError):
     pass
 
-
+class IncompatibleBackendError(SlideLoadError):
+    pass
 
 class ROIError(SlideError):
     pass
 
 
 class MissingROIError(ROIError):
     pass
```

## slideflow/mosaic.py

```diff
@@ -364,14 +364,15 @@
         return self.points.loc[self.points.selected]
 
     def generate_grid(
         self,
         num_tiles_x: int = 50,
         tile_meta: Optional[Dict] = None,
         tile_select: str = 'first',
+        max_dist: Optional[float] = None,
     ):
         """Generate the mosaic map grid.
 
         Args:
             num_tiles_x (int, optional): Mosaic map grid size. Defaults to 50.
             tile_meta (dict, optional): Tile metadata, used for tile_select.
                 Dictionary should have slide names as keys, mapped to list of
@@ -407,18 +408,18 @@
 
         log.info("Building grid...")
         self.grid_idx = np.reshape(np.dstack(np.indices((self.num_tiles_x, self.num_tiles_y))), (self.num_tiles_x * self.num_tiles_y, 2))
         _grid_offset = np.array([(self.tile_size/2) + min_x, (self.tile_size/2) + min_y])
         self.grid_coords = (self.grid_idx * self.tile_size) + _grid_offset
 
         points_added = 0
-        x_bins = np.arange(min_x, max_x, ((max_x - min_x) / self.num_tiles_x))
-        y_bins = np.arange(min_y, max_y, ((max_y - min_y) / self.num_tiles_y))
-        self.points['grid_x'] = np.digitize(self.points.x.values, x_bins, right=True)
-        self.points['grid_y'] = np.digitize(self.points.y.values, y_bins, right=True)
+        x_bins = np.arange(min_x, max_x, ((max_x - min_x) / self.num_tiles_x))[1:]
+        y_bins = np.arange(min_y, max_y, ((max_y - min_y) / self.num_tiles_y))[1:]
+        self.points['grid_x'] = np.digitize(self.points.x.values, x_bins, right=False)
+        self.points['grid_y'] = np.digitize(self.points.y.values, y_bins, right=False)
         self.points['selected'] = False
         log.debug(f'{points_added} points added to grid')
 
         # Then, calculate distances from each point to each spot on the grid
         def select_nearest_points(idx):
             grid_x, grid_y = self.grid_idx[idx][0], self.grid_idx[idx][1]
             grid_coords = self.grid_coords[idx]
@@ -429,15 +430,20 @@
                 if tile_select == 'nearest':
                     point_coords = np.stack([_points.x.values, _points.y.values], axis=-1)
                     dist = np.linalg.norm(
                         point_coords - grid_coords,
                         ord=2,
                         axis=1.
                     )
-                    self.points.loc[_points.index[np.argmin(dist)], 'selected'] = True
+                    if max_dist is not None:
+                        masked_dist = np.ma.masked_array(dist, (dist >= (max_dist * self.tile_size)))
+                        if masked_dist.count():
+                            self.points.loc[_points.index[np.argmin(masked_dist)], 'selected'] = True
+                    else:
+                        self.points.loc[_points.index[np.argmin(dist)], 'selected'] = True
                 elif not tile_meta:
                     raise errors.MosaicError(
                         'Mosaic centroid option requires tile_meta.'
                     )
                 else:
                     centroid_index = get_centroid_index(_points.meta.values)
                     self.points.loc[_points.index[centroid_index], 'selected'] = True
@@ -445,15 +451,15 @@
         log.info('Selecting tile images...')
         start = time.time()
 
         if tile_select == 'first':
             grid_group = self.points.groupby(['grid_x', 'grid_y'])
             first_indices = grid_group.nth(0).points_index.values
             self.points.loc[first_indices, 'selected'] = True
-        elif tile_select == 'nearest':
+        elif tile_select in ('nearest', 'centroid'):
             self.points['selected'] = False
             dist_fn = partial(select_nearest_points)
             pool = DPool(os.cpu_count())
             for i, _ in track(enumerate(pool.imap_unordered(dist_fn, range(len(self.grid_idx))), 1), total=len(self.grid_idx)):
                 pass
             pool.close()
             pool.join()
```

## slideflow/project.py

```diff
@@ -1547,86 +1547,103 @@
             tile_px (int): Size of tiles to extract, in pixels.
             tile_um (int or str): Size of tiles to extract, in microns (int) or
                 magnification (str, e.g. "20x").
 
         Keyword Args:
             save_tiles (bool, optional): Save tile images in loose format.
                 Defaults to False.
-            save_tfrecords (bool, optional): Save tile images as TFRecords.
-                Defaults to True.
-            source (str, optional): Process slides only from this source.
-                Defaults to None (all slides in project).
-            stride_div (int, optional): Stride divisor. Defaults to 1.
+            save_tfrecords (bool): Save compressed image data from
+                extracted tiles into TFRecords in the corresponding TFRecord
+                directory. Defaults to True.
+            source (str, optional): Name of dataset source from which to select
+                slides for extraction. Defaults to None. If not provided, will
+                default to all sources in project.
+            stride_div (int): Stride divisor for tile extraction.
                 A stride of 1 will extract non-overlapping tiles.
-                A stride_div of 2 will extract overlapping tiles with a stride
-                equal to 50% of the tile width.
-            enable_downsample (bool, optional): Enable downsampling when
-                reading slides. Defaults to True. This may result in corrupted
-                image tiles if downsampled slide layers are corrupted or
-                incomplete. Recommend manual confirmation of tile integrity.
+                A stride_div of 2 will extract overlapping tiles, with a stride
+                equal to 50% of the tile width. Defaults to 1.
+            enable_downsample (bool): Enable downsampling for slides.
+                This may result in corrupted image tiles if downsampled slide
+                layers are corrupted or incomplete. Defaults to True.
             roi_method (str): Either 'inside', 'outside', 'auto', or 'ignore'.
                 Determines how ROIs are used to extract tiles.
                 If 'inside' or 'outside', will extract tiles in/out of an ROI,
                 and skip the slide if an ROI is not available.
                 If 'auto', will extract tiles inside an ROI if available,
                 and across the whole-slide if no ROI is found.
                 If 'ignore', will extract tiles across the whole-slide
                 regardless of whether an ROI is available.
                 Defaults to 'auto'.
-            skip_extracted (bool, optional): Skip already extracted slides.
-                Defaults to True.
-            tma (bool, optional): Reads slides as Tumor Micro-Arrays (TMAs),
+            roi_filter_method (str or float): Method of filtering tiles with
+                ROIs. Either 'center' or float (0-1). If 'center', tiles are
+                filtered with ROIs based on the center of the tile. If float,
+                tiles are filtered based on the proportion of the tile inside
+                the ROI, and ``roi_filter_method`` is interpreted as a
+                threshold. If the proportion of a tile inside the ROI is
+                greater than this number, the tile is included. For example,
+                if ``roi_filter_method=0.7``, a tile that is 80% inside of an
+                ROI will be included, and a tile that is 50% inside of an ROI
+                will be excluded. Defaults to 'center'.
+            skip_extracted (bool): Skip slides that have already
+                been extracted. Defaults to True.
+            tma (bool): Reads slides as Tumor Micro-Arrays (TMAs),
                 detecting and extracting tumor cores. Defaults to False.
-            randomize_origin (bool, optional): Randomize pixel starting
+                Experimental function with limited testing.
+            randomize_origin (bool): Randomize pixel starting
                 position during extraction. Defaults to False.
-            buffer (str, optional): Copy slides here before extraction.
-                Improves processing speed if using an SSD/ramdisk buffer.
-                Defaults to None.
-            num_workers (int, optional): Extract tiles from this many slides
-                simultaneously. Defaults to 1.
-            q_size (int, optional): Queue size for buffer. Defaults to 2.
+            buffer (str, optional): Slides will be copied to this directory
+                before extraction. Defaults to None. Using an SSD or ramdisk
+                buffer vastly improves tile extraction speed.
+            q_size (int): Size of queue when using a buffer.
+                Defaults to 2.
             qc (str, optional): 'otsu', 'blur', 'both', or None. Perform blur
                 detection quality control - discarding tiles with detected
                 out-of-focus regions or artifact - and/or otsu's method.
-                Defaults to None.
-            report (bool, optional): Save a PDF report of tile extraction.
+                Increases tile extraction time. Defaults to None.
+            report (bool): Save a PDF report of tile extraction.
                 Defaults to True.
             normalizer (str, optional): Normalization strategy.
                 Defaults to None.
             normalizer_source (str, optional): Path to normalizer source image.
-                Defaults to None (use internal image at slide.norm_tile.jpg).
-            whitespace_fraction (float, optional): Range 0-1. Defaults to 1.
-                Discard tiles with this fraction of whitespace. If 1, will not
-                perform whitespace filtering.
-            whitespace_threshold (int, optional): Range 0-255. Threshold above
-                which a pixel (RGB average) is considered whitespace.
-                Defaults to 230.
-            grayspace_fraction (float, optional): Range 0-1. Discard tiles with
-                this fraction of grayspace. If 1, will not perform grayspace
-                filtering. Defaults to 0.6.
-            grayspace_threshold (float, optional): Range 0-1. Pixels in HSV
-                format with saturation below this are considered grayspace.
-                Defaults to 0.05.
+                If None, will use slideflow.slide.norm_tile.jpg.
+                Defaults to None.
+            whitespace_fraction (float, optional): Range 0-1. Discard tiles
+                with this fraction of whitespace. If 1, will not perform
+                whitespace filtering. Defaults to 1.
+            whitespace_threshold (int, optional): Range 0-255. Defaults to 230.
+                Threshold above which a pixel (RGB average) is whitespace.
+            grayspace_fraction (float, optional): Range 0-1. Defaults to 0.6.
+                Discard tiles with this fraction of grayspace.
+                If 1, will not perform grayspace filtering.
+            grayspace_threshold (float, optional): Range 0-1. Defaults to 0.05.
+                Pixels in HSV format with saturation below this threshold are
+                considered grayspace.
             img_format (str, optional): 'png' or 'jpg'. Defaults to 'jpg'.
-                Image format to use in tfrecords. PNG (lossless) for
-                fidelity, JPG (lossy) for efficiency.
-            full_core (bool, optional): Only used if extracting from TMA. Save
-                entire TMA core as image. Otherwise, will extract sub-images
-                from each core at the tile micron size. Defaults to False.
-            shuffle (bool, optional): Shuffle tiles before tfrecords storage.
-                Defaults to True.
-            num_threads (int, optional): Threads for each tile extractor.
-                Defaults to 4.
-            qc_blur_radius (int, optional): Blur radius for out-of-focus area
-                detection. Used if qc=True. Defaults to 3.
-            qc_blur_threshold (float, optional): Blur threshold for detecting
-                out-of-focus areas. Used if qc=True. Defaults to 0.1.
-            qc_filter_threshold (float, optional): Float between 0-1.
-                Tiles with more than this proportion of blur will be discarded.
-                Used if qc=True. Defaults to 0.6.
+                Image format to use in tfrecords. PNG (lossless) for fidelity,
+                JPG (lossy) for efficiency.
+            full_core (bool, optional): Only used if extracting from TMA.
+                If True, will save entire TMA core as image.
+                Otherwise, will extract sub-images from each core using the
+                given tile micron size. Defaults to False.
+            shuffle (bool, optional): Shuffle tiles prior to storage in
+                tfrecords. Defaults to True.
+            num_threads (int, optional): Number of worker processes for each
+                tile extractor. When using cuCIM slide reading backend,
+                defaults to the total number of available CPU cores, using the
+                'fork' multiprocessing method. With Libvips, this defaults to
+                the total number of available CPU cores or 32, whichever is
+                lower, using 'spawn' multiprocessing.
+            qc_blur_radius (int, optional): Quality control blur radius for
+                out-of-focus area detection. Used if qc=True. Defaults to 3.
+            qc_blur_threshold (float, optional): Quality control blur threshold
+                for detecting out-of-focus areas. Only used if qc=True.
+                Defaults to 0.1
+            qc_filter_threshold (float, optional): Float between 0-1. Tiles
+                with more than this proportion of blur will be discarded.
+                Only used if qc=True. Defaults to 0.6.
             qc_mpp (float, optional): Microns-per-pixel indicating image
                 magnification level at which quality control is performed.
                 Defaults to mpp=4 (effective magnification 2.5 X)
             dry_run (bool, optional): Determine tiles that would be extracted,
                 but do not export any images. Defaults to None.
             max_tiles (int, optional): Only extract this many tiles per slide.
                 Defaults to None.
@@ -3886,16 +3903,21 @@
 
     # Overwrite any project configuration with user-specified keyword arguments
     cfg.update(kwargs)
 
     # Set up project at the given directory.
     log.info(f"Setting up project at {root}")
     if 'annotations' in cfg:
-        proj_kwargs['annotations'] = join(root, basename(cfg.annotations))
+        if root.startswith('.'):
+            proj_kwargs['annotations'] = join('.', basename(cfg.annotations))
+        else:
+            proj_kwargs['annotations'] = join(root, basename(cfg.annotations))
+
     P = sf.Project(root, **proj_kwargs, create=True)
+
     # Download annotations, if a URL.
     if 'annotations' in cfg and cfg.annotations.startswith('http'):
         log.info(f"Downloading {cfg.annotations}")
         r = requests.get(cfg.annotations)
         open(proj_kwargs['annotations'], 'wb').write(r.content)
         if cfg.annotations_md5 != sf.util.md5(proj_kwargs['annotations']):
             raise errors.ChecksumError(
```

## slideflow/mil/eval.py

```diff
@@ -85,17 +85,16 @@
     # Prepare bags and targets
     slides = list(labels.keys())
     if isinstance(bags, str):
         bags = dataset.pt_files(bags)
     else:
         bags = np.array([b for b in bags if path_to_name(b) in slides])
 
-    # Handle the case where some bags are missing.
-    if len(bags) != len(slides):
-        slides = [path_to_name(b) for b in bags]
+    # Ensure slide names are sorted according to the bags.
+    slides = [path_to_name(b) for b in bags]
 
     y_true = np.array([labels[s] for s in slides])
 
     # Detect feature size from bags
     n_features = torch.load(bags[0]).shape[-1]
     n_out = len(unique)
 
@@ -213,17 +212,16 @@
     # Prepare bags and targets.
     slides = list(labels.keys())
     if isinstance(bags, str):
         bags = dataset.pt_files(bags)
     else:
         bags = np.array([b for b in bags if path_to_name(b) in slides])
 
-    # Handle the case where some bags are missing.
-    if len(bags) != len(slides):
-        slides = [path_to_name(b) for b in bags]
+    # Ensure slide names are sorted according to the bags.
+    slides = [path_to_name(b) for b in bags]
 
     y_true = np.array([labels[s] for s in slides])
 
     # Inference.
     if (isinstance(config, TrainerConfigCLAM)
        or isinstance(config.model_config, ModelConfigCLAM)):
         y_pred, y_att = _predict_clam(model, bags, attention=attention)
```

## slideflow/model/features.py

```diff
@@ -500,28 +500,28 @@
             logit_header = [f'Class_{log}' for log in range(self.num_classes)]
             feature_header = [f'Feature_{f}' for f in range(self.num_features)]
             header = ['Slide'] + logit_header + feature_header
             csvwriter.writerow(header)
             for slide in track(slides):
                 if level == 'tile':
                     for i, tile_act in enumerate(self.activations[slide]):
-                        if self.predictions[slide] != []:
+                        if self.num_classes and self.predictions[slide] != []:
                             csvwriter.writerow(
                                 [slide]
                                 + self.predictions[slide][i].tolist()
                                 + tile_act.tolist()
                             )
                         else:
                             csvwriter.writerow([slide] + tile_act.tolist())
                 else:
                     act = meth_fn[method](
                         self.activations[slide],
                         axis=0
                     ).tolist()
-                    if self.predictions[slide] != []:
+                    if self.num_classes and self.predictions[slide] != []:
                         logit = meth_fn[method](
                             self.predictions[slide],
                             axis=0
                         ).tolist()
                         csvwriter.writerow([slide] + logit + act)
                     else:
                         csvwriter.writerow([slide] + act)
@@ -936,27 +936,29 @@
         self.predictions.update(df.predictions)
         self.uncertainty.update(df.uncertainty)
         self.locations.update(df.locations)
         self.tfrecords = np.concatenate([self.tfrecords, df.tfrecords])
         self.slides = list(self.activations.keys())
 
     def remove_slide(self, slide: str) -> None:
-        """Removes slide from internally cached activations."""
-        del self.activations[slide]
-        del self.predictions[slide]
-        del self.uncertainty[slide]
-        del self.locations[slide]
+        """Removes slide from calculated features."""
+        if slide in self.activations:
+            del self.activations[slide]
+        if slide in self.predictions:
+            del self.predictions[slide]
+        if slide in self.uncertainty:
+            del self.uncertainty[slide]
+        if slide in self.locations:
+            del self.locations[slide]
         self.tfrecords = np.array([
             t for t in self.tfrecords
             if sf.util.path_to_name(t) != slide
         ])
-        try:
+        if slide in self.slides:
             self.slides.remove(slide)
-        except ValueError:
-            pass
 
     def save_example_tiles(
         self,
         features: List[int],
         outdir: str,
         slides: Optional[List[str]] = None,
         tiles_per_feature: int = 100
@@ -1102,15 +1104,15 @@
         else:
             return self.generator(batch_img)
 
     def _process_out(self, model_out, batch_slides, batch_loc):
         model_out = sf.util.as_list(model_out)
 
         # Process data if the output is Tensorflow (SimCLR or Tensorflow model)
-        if self.is_simclr() or self.is_tf():
+        if self.is_tf():
             slides = [
                 bs.decode('utf-8')
                 for bs in batch_slides.numpy()
             ]
             model_out = [
                 m.numpy() if not isinstance(m, (list, tuple)) else m
                 for m in model_out
@@ -1288,14 +1290,16 @@
     def is_torch(self):
         if self.is_extractor():
             return self.model.is_torch()
         else:
             return sf.model.is_torch_model(self.model)
 
     def is_tf(self):
+        if self.is_simclr():
+            return True
         if self.is_extractor():
             return self.model.is_tensorflow()
         else:
             return sf.model.is_tensorflow_model(self.model)
 
     def has_torch_gpu_normalizer(self):
         return (
```

## slideflow/norm/tensorflow/macenko.py

```diff
@@ -7,14 +7,25 @@
 
 from slideflow.norm import utils as ut
 from .utils import clip_size, standardize_brightness
 
 # -----------------------------------------------------------------------------
 
 @tf.function
+def is_self_adjoint(matrix):
+    return tf.reduce_all(tf.math.equal(matrix, tf.linalg.adjoint(matrix)))
+
+@tf.function
+def normalize_c(C):
+    return tf.stack([
+        tfp.stats.percentile(C[0, :], 99), 
+        tfp.stats.percentile(C[1, :], 99)]
+    )
+
+@tf.function
 def _matrix_and_concentrations(
     img: tf.Tensor,
     Io: int = 255,
     alpha: float = 1,
     beta: float = 0.15,
     mask: bool = False,
     standardize: bool = True
@@ -128,15 +139,15 @@
             tf.Tensor: Concentrations of individual stains
     """
     HE, C = _matrix_and_concentrations(
         img, Io, alpha, beta, mask=mask, standardize=standardize
     )
 
     # normalize stain concentrations
-    maxC = tf.stack([tfp.stats.percentile(C[0, :], 99), tfp.stats.percentile(C[1, :], 99)])
+    maxC = normalize_c(C)
 
     return HE, maxC, C
 
 
 @tf.function
 def augmented_transform(
     img: tf.Tensor,
@@ -186,14 +197,15 @@
     target_concentrations: tf.Tensor,
     *,
     Io: int = 255,
     alpha: float = 1,
     beta: float = 0.15,
     ctx_maxC: Optional[tf.Tensor] = None,
     standardize: bool = True,
+    original_on_error: bool = True
 ) -> tf.Tensor:
     """Normalize an image.
 
     Args:
         img (tf.Tensor): Image to transform.
         stain_matrix_target (tf.Tensor): Target stain matrix.
         target_concentrations (tf.Tensor): Target concentrations.
@@ -209,31 +221,75 @@
         ctx_maxC (tf.Tensor, optional): Max concentration from context
             (e.g. whole-slide image). If None, calculates max concentration
             from the target image. Defaults to None.
 
     Returns:
         tf.Tensor: Transformed image.
     """
-
+    original_image = img
     h, w, c = img.shape
 
     Io = tf.cast(Io, tf.float32)
 
     HERef = stain_matrix_target
     maxCRef = target_concentrations
 
+    # reshape image
+    img = tf.reshape(img, (-1, 3))
+
+    # -------------------------------------------------------------------------
+
+    if standardize:
+        img = standardize_brightness(img)
+
+    # calculate optical density
+    OD = -tf.math.log((tf.cast(img, tf.float32) + 1) / Io)
+
+    # remove transparent pixels
+    ODhat = OD[~ tf.math.reduce_any(OD < beta, axis=1)]
+
+    # compute eigenvectors
+    covar = tfp.stats.covariance(ODhat)
+    if original_on_error and not is_self_adjoint(covar):
+        return original_image
+    eigvals, eigvecs = tf.linalg.eigh(covar)
+
+    # project on the plane spanned by the eigenvectors corresponding to the two
+    # largest eigenvalues
+    That = dot(ODhat, eigvecs[:, 1:3])
+
+    phi = tf.math.atan2(That[:, 1],That[:,0])
+
+    minPhi = tfp.stats.percentile(phi, alpha)
+    maxPhi = tfp.stats.percentile(phi, 100-alpha)
+
+    vMin = dot(eigvecs[:, 1:3], tf.transpose(tf.stack((tf.math.cos(minPhi), tf.math.sin(minPhi)))[tf.newaxis, :]))
+    vMax = dot(eigvecs[:, 1:3], tf.transpose(tf.stack((tf.math.cos(maxPhi), tf.math.sin(maxPhi)))[tf.newaxis, :]))
+
+    # a heuristic to make the vector corresponding to hematoxylin first and the
+    # one corresponding to eosin second
+    if vMin[0] > vMax[0]:
+        HE = tf.transpose(tf.stack((vMin[:, 0], vMax[:, 0])))
+    else:
+        HE = tf.transpose(tf.stack((vMax[:, 0], vMin[:, 0])))
+
+    # rows correspond to channels (RGB), columns to OD values
+    OD = tf.reshape(OD, (-1, 3))
+
+    Y = tf.transpose(OD)
+
+    # determine concentrations of the individual stains
+    C = tf.linalg.lstsq(HE, Y)
+
+    # -------------------------------------------------------------------------
+
     if ctx_maxC is not None:
-        HE, C = _matrix_and_concentrations(
-            img, Io, alpha, beta, standardize=standardize
-        )
         maxC = ctx_maxC
     else:
-        HE, maxC, C = matrix_and_concentrations(
-            img, Io, alpha, beta, standardize=standardize
-        )
+        maxC = normalize_c(C)
 
     tmp = tf.math.divide(maxC, maxCRef)
     C2 = tf.math.divide(C, tmp[:, tf.newaxis])
 
     # recreate the image using reference mixing matrix
     Inorm = tf.math.multiply(Io, tf.math.exp(dot(-HERef, C2)))
     Inorm = tf.experimental.numpy.clip(Inorm, 0, 255)
@@ -316,28 +372,30 @@
     def _fit(self, target: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:
         return fit(target, self.Io, self.alpha, self.beta)
 
     def _transform(
         self,
         I: tf.Tensor,
         *,
-        augment: bool = False
+        augment: bool = False,
+        original_on_error: bool = True
     ) -> tf.Tensor:
         """Normalize an image."""
         if augment and not any(m in self._augment_params
                                for m in ('matrix_stdev', 'concentrations_stdev')):
             raise ValueError("Augmentation space not configured.")
 
         fn = augmented_transform if augment else transform
         aug_kw = self._augment_params if augment else {}
         return fn(
             I,
             self.stain_matrix_target,
             self.target_concentrations,
             ctx_maxC=self._ctx_maxC,
+            original_on_error=original_on_error,
             **aug_kw
         )
 
     def fit(self, target: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:
         """Fit normalizer to a target image.
 
         Calculates the stain matrix and concentrations for the given image,
@@ -540,29 +598,31 @@
             standardize=False
         )
 
     def _transform(
         self,
         I: tf.Tensor,
         *,
-        augment: bool = False
+        augment: bool = False,
+        original_on_error: bool = True
     ) -> tf.Tensor:
         """Normalize an image."""
         if augment and not any(m in self._augment_params
                                for m in ('matrix_stdev', 'concentrations_stdev')):
             raise ValueError("Augmentation space not configured.")
 
         fn = augmented_transform if augment else transform
         aug_kw = self._augment_params if augment else {}
         return fn(
             I,
             self.stain_matrix_target,
             self.target_concentrations,
             ctx_maxC=self._ctx_maxC,
             standardize=False,
+            original_on_error=original_on_error,
             **aug_kw
         )
 
     def set_context(self, I: Union[np.ndarray, tf.Tensor]):
         """Set the whole-slide context for the stain normalizer.
 
         With contextual normalization, max concentrations are determined
```

## slideflow/norm/torch/macenko.py

```diff
@@ -275,15 +275,15 @@
         return HE, maxC, C
 
     def transform(
         self,
         img: torch.Tensor,
         *,
         augment: bool = False,
-        allow_errors: bool = True
+        original_on_error: bool = True
     ) -> torch.Tensor:
         """Normalize an H&E image.
 
         Args:
             img (torch.Tensor): Image, RGB uint8 with dimensions W, H, C.
 
         Keyword args:
@@ -329,15 +329,15 @@
         try:
             if self._ctx_maxC is not None:
                 HE, C = self._matrix_and_concentrations(img)
                 maxC = self._ctx_maxC
             else:
                 HE, maxC, C = self.matrix_and_concentrations(img)
         except Exception as e:
-            if allow_errors:
+            if original_on_error:
                 log.debug(
                     "Error encountered during normalization. Returning "
                     f"original image. Error: {e}"
                 )
                 return img
             else:
                 raise
```

## slideflow/slide/__init__.py

```diff
@@ -23,25 +23,24 @@
 from PIL import Image, ImageDraw
 from rich.progress import Progress
 from skimage import img_as_ubyte
 from slideflow import errors
 from functools import partial
 from os.path import exists, join
 from types import SimpleNamespace
-from typing import (Any, Callable, Dict, List, Optional, Tuple, Union,
-                    TYPE_CHECKING)
+from typing import Any, Callable, Dict, List, Optional, Tuple, Union
 
 import slideflow as sf
 import slideflow.slide.qc
 from slideflow.util import SUPPORTED_FORMATS  # noqa F401
 from slideflow.util import log, path_to_name  # noqa F401
 from .report import ExtractionPDF  # noqa F401
 from .report import ExtractionReport, SlideReport
 from .utils import *
-from .backends import tile_worker, wsi_reader
+from .backends import tile_worker, wsi_reader, backend_formats
 
 
 warnings.simplefilter('ignore', Image.DecompressionBombWarning)
 Image.MAX_IMAGE_PIXELS = 100000000000
 
 # -----------------------------------------------------------------------
 
@@ -254,20 +253,25 @@
         # Initiate supported slide reader
         if not os.path.exists(path):
             raise errors.SlideNotFoundError(f"Could not find slide {path}.")
         if self.filetype.lower() not in sf.util.SUPPORTED_FORMATS:
             raise errors.SlideLoadError(
                 f"{self.name}: unsupported filetype '{self.filetype}'"
             )
+        if self.filetype.lower() not in backend_formats():
+            raise errors.IncompatibleBackendError(
+                f"{self.name}: filetype '{self.filetype}' is not supported "
+                f"by the current backend, {sf.slide_backend()}"
+            )
 
         # Collect basic slide information
         try:
             self.mpp = float(self.slide.mpp)
         except Exception as e:
-            raise errors.SlideLoadError(
+            raise errors.SlideMissingMPPError(
                 f"Slide [green]{self.name}[/] missing MPP ({OPS_MPP_X})"
             )
 
         # Calculate downsample by magnification
         if isinstance(tile_um, str):
             sf.util.assert_is_mag(tile_um)
             _mag_lvl = 10 / (np.array(self.slide.level_downsamples) * self.mpp)
```

## slideflow/slide/backends/__init__.py

```diff
@@ -1,10 +1,11 @@
 """Abstraction to support both Libvips and cuCIM backends."""
 
 import slideflow as sf
+from typing import List
 
 
 def tile_worker(*args, **kwargs):
     if sf.slide_backend() == 'libvips':
         from .vips import tile_worker
     elif sf.slide_backend() == 'cucim':
         from .cucim import tile_worker
@@ -16,7 +17,15 @@
     if sf.slide_backend() == 'libvips':
         from .vips import get_libvips_reader
         return get_libvips_reader(path, *args, **kwargs)
 
     elif sf.slide_backend() == 'cucim':
         from .cucim import get_cucim_reader
         return get_cucim_reader(path, *args, **kwargs)
+
+def backend_formats() -> List[str]:
+    if sf.slide_backend() == 'libvips':
+        from .vips import SUPPORTED_BACKEND_FORMATS
+        return SUPPORTED_BACKEND_FORMATS
+    elif sf.slide_backend() == 'cucim':
+        from .cucim import SUPPORTED_BACKEND_FORMATS
+        return SUPPORTED_BACKEND_FORMATS
```

## slideflow/slide/backends/cucim.py

```diff
@@ -13,19 +13,25 @@
 from skimage.util import img_as_float
 from skimage.color import rgb2hsv
 from slideflow.slide.utils import *
 
 if TYPE_CHECKING:
     from cucim import CuImage
 
+# -----------------------------------------------------------------------------
+
+SUPPORTED_BACKEND_FORMATS = ['svs', 'tif', 'tiff']
+
+# -----------------------------------------------------------------------------
 
 __cv2_resize__ = True
 __cuimage__ = None
 __cuimage_path__ = None
 
+# -----------------------------------------------------------------------------
 
 def get_cucim_reader(path: str, *args, **kwargs):
     return _cuCIMReader(path, *args, **kwargs)
 
 
 def cucim2numpy(img: "CuImage") -> np.ndarray:
     return ((img_as_float(np.asarray(img))) * 255).astype(np.uint8)
```

## slideflow/slide/backends/vips.py

```diff
@@ -16,20 +16,27 @@
 
 try:
     import pyvips as vips
 except (ModuleNotFoundError, OSError) as e:
     log.error("Unable to load vips; slide processing will be unavailable. "
               f"Error raised: {e}")
 
+# -----------------------------------------------------------------------------
+
+SUPPORTED_BACKEND_FORMATS = ['svs', 'tif', 'ndpi', 'vms', 'vmu', 'scn', 'mrxs',
+                             'tiff', 'svslide', 'bif', 'jpg', 'jpeg', 'png']
+
+# -----------------------------------------------------------------------------
 
 __vipsreader__ = None
 __vipsreader_path__ = None
 __vipsreader_args__ = None
 __vipsreader_kwargs__ = None
 
+# -----------------------------------------------------------------------------
 
 VIPS_FORMAT_TO_DTYPE = {
     'uchar': np.uint8,
     'char': np.int8,
     'ushort': np.uint16,
     'short': np.int16,
     'uint': np.uint32,
@@ -553,17 +560,19 @@
     has_levels = False
 
     def __init__(
         self,
         path: str,
         mpp: Optional[float] = None,
         cache_kw = None,
-        ignore_missing_mpp: bool = True
+        ignore_missing_mpp: bool = True,
+        pad_missing: bool = True
     ) -> None:
         self.path = path
+        self.pad_missing = pad_missing
         self.full_image = vips.Image.new_from_file(path)
         self.cache_kw = cache_kw if cache_kw else {}
         if not self.full_image.hasalpha():
             self.full_image = self.full_image.addalpha()
         self.properties = {}
         for field in self.full_image.get_fields():
             self.properties.update({field: self.full_image.get(field)})
```

## slideflow/studio/widgets/capture.py

```diff
@@ -93,12 +93,14 @@
         elif self.dump_gui or self.dump_view:
             viz.capture_next_frame()
             self._crop_next = self.dump_view
             self.dump_view = self.dump_gui = False
         captured_frame = viz.pop_captured_frame()
         if captured_frame is not None:
             if self._crop_next:
-                captured_frame = captured_frame[self.viz.offset_y_pixels:, self.viz.offset_x_pixels:, :]
+                h = self.viz.status_bar_height
+                r = self.viz.pixel_ratio
+                captured_frame = captured_frame[self.viz.offset_y_pixels: -int(h*r), self.viz.offset_x_pixels:, :]
             self.dump_png(captured_frame)
             self._crop_next = False
 
 #----------------------------------------------------------------------------
```

## slideflow/util/__init__.py

```diff
@@ -213,20 +213,32 @@
     Args:
         console (rich.console.Console, optional): Active console, if one exists.
             Defaults to None.
     """
     if console is None:
         console = Console()
     col1 = 'yellow' if sf.backend() == 'tensorflow' else 'purple'
-    col2 = 'green' if sf.slide_backend() == 'cucim' else 'cyan'
+    if sf.slide_backend() == 'libvips':
+        try:
+            import pyvips
+            _version = '{}.{}.{}'.format(
+                pyvips.major, pyvips.minor, pyvips.micro
+            )
+        except Exception:
+            _version = 'unknown'
+        col2 = 'cyan'
+        slide_backend = 'libvips ({})'.format(_version)
+    else:
+        slide_backend = sf.slide_backend()
+        col2 = 'green'
     console.print(
         Panel(f"[white bold]Slideflow[/]"
               f"\nVersion: {sf.__version__}"
               f"\nBackend: [{col1}]{sf.backend()}[/]"
-              f"\nSlide Backend: [{col2}]{sf.slide_backend()}[/]"
+              f"\nSlide Backend: [{col2}]{slide_backend}[/]"
               "\n[blue]https://slideflow.dev[/]",
               border_style='purple'),
         justify='left')
 
 
 # --- Data download functions -------------------------------------------------
```

## Comparing `slideflow-2.0.3.post1.data/scripts/slideflow-studio` & `slideflow-2.0.4.data/scripts/slideflow-studio`

 * *Files identical despite different names*

## Comparing `slideflow-2.0.3.post1.data/scripts/slideflow-studio.py` & `slideflow-2.0.4.data/scripts/slideflow-studio.py`

 * *Files identical despite different names*

## Comparing `slideflow-2.0.3.post1.dist-info/LICENSE` & `slideflow-2.0.4.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `slideflow-2.0.3.post1.dist-info/METADATA` & `slideflow-2.0.4.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: slideflow
-Version: 2.0.3.post1
+Version: 2.0.4
 Summary: Deep learning tools for digital histology
 Home-page: https://github.com/jamesdolezal/slideflow
 Author: James Dolezal
 Author-email: james.dolezal@uchospitals.edu
 Classifier: Programming Language :: Python :: 3
 Classifier: License :: OSI Approved :: GNU General Public License v3 (GPLv3)
 Classifier: Operating System :: OS Independent
@@ -87,15 +87,15 @@
 
 [ArXiv](https://arxiv.org/abs/2304.04142) | [Docs](https://slideflow.dev) | [Slideflow Studio](https://slideflow.dev/studio/) | [Cite](#reference)
 
 Slideflow is a deep learning library for digital pathology that provides a unified API for building, training, and testing models using Tensorflow or PyTorch.
 
 Slideflow includes tools for **[whole-slide image processing](https://slideflow.dev/slide_processing)**, **customizable deep learning [model training](https://slideflow.dev/training)** with dozens of supported architectures, **[multi-instance learning](https://slideflow.dev/mil)**, **[self-supervised learning](https://slideflow.dev/ssl)**, **[cell segmentation](https://slideflow.dev/cellseg)**, **explainability tools** (including [heatmaps](https://slideflow.dev/evaluation/#heatmaps), [mosaic maps](https://slideflow.dev/posthoc/#mosaic-maps), [GANs](https://slideflow.dev/stylegan/), and [saliency maps](https://slideflow.dev/saliency/)), **analysis of [layer activations](https://slideflow.dev/posthoc/)**, **[uncertainty quantification](https://slideflow.dev/uq/)**, and more.
 
-A variety of fast, optimized whole-slide image processing tools are included, including background filtering, blur/artifact detection, [stain normalization](https://slideflow.dev/norm), and efficient storage in `*.tfrecords` format. Model training is easy and highly configurable, with an straightforward API for training custom architectures. Slideflow can be used as an image processing backend for external training loops, serving an optimized `tf.data.Dataset` or `torch.utils.data.DataLoader` to read and process slide images and perform real-time stain normalization.
+A variety of fast, optimized whole-slide image processing tools are included, including background filtering, blur/artifact detection, [stain normalization/augmentation](https://slideflow.dev/norm), and efficient storage in `*.tfrecords` format. Model training is easy and highly configurable, with an straightforward API for training custom architectures. Slideflow can be used as an image processing backend for external training loops, serving an optimized `tf.data.Dataset` or `torch.utils.data.DataLoader` to read and process slide images and perform real-time stain normalization.
 
 Full documentation with example tutorials can be found at [slideflow.dev](https://www.slideflow.dev/).
 
 ![Studio preview](https://slideflow.dev/_images/studio_saliency.jpg)
 *Slideflow Studio: a visualization tool for interacting with models and whole-slide images.*
 
 ## Requirements
@@ -256,16 +256,16 @@
 - [Dolezal et al](https://www.nature.com/articles/s41379-020-00724-3), _Modern Pathology_, 2020
 - [Rosenberg et al](https://ascopubs.org/doi/10.1200/JCO.2020.38.15_suppl.e23529), _Journal of Clinical Oncology_ [abstract], 2020
 - [Howard et al](https://www.nature.com/articles/s41467-021-24698-1), _Nature Communications_, 2021
 - [Dolezal et al](https://www.nature.com/articles/s41467-022-34025-x) _Nature Communications_, 2022
 - [Storozuk et al](https://www.nature.com/articles/s41379-022-01039-1.pdf), _Modern Pathology_ [abstract], 2022
 - [Partin et al](https://doi.org/10.3389/fmed.2023.1058919) _Front Med_, 2022
 - [Dolezal et al](https://ascopubs.org/doi/abs/10.1200/JCO.2022.40.16_suppl.8549) [abstract], 2022
-- [Howard et al](https://www.biorxiv.org/content/10.1101/2022.07.07.499039v1) [bioRxiv], 2022
 - [Dolezal et al](https://arxiv.org/abs/2211.06522) [arXiv], 2022
+- [Howard et al](https://www.nature.com/articles/s41523-023-00530-5) _npj Breast Cancer_, 2023
 - [Hieromnimon et al](https://doi.org/10.1101/2023.03.22.533810) [bioRxiv], 2023
 
 ## License
 This code is made available under the GPLv3 License and is available for non-commercial academic purposes.
 
 ## Reference
 If you find our work useful for your research, or if you use parts of this code, please consider citing as follows:
```

## Comparing `slideflow-2.0.3.post1.dist-info/RECORD` & `slideflow-2.0.4.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 slideflow/__init__.py,sha256=Y463ep8Pwe89TUUVaqmFAbKmtQVjjDEEZHIlQ8unTE0,1411
 slideflow/_backend.py,sha256=Yi7LUgiYUUVlGdi6DBYe2raev3LLdYdtR6PtHozFORU,1662
-slideflow/_version.py,sha256=II0pqgwrffvH1AAQWjAORRADtcNS_xKqhrnkPgrOgNE,503
-slideflow/dataset.py,sha256=qWnY-2SB1iAYEIKiDefgAiif7nIfAdZCnpWhCJdOQmg,159998
-slideflow/errors.py,sha256=ux67x8a-JeQ9cyc8aZubFPIzGGxi3fxsBllyEPZUeEQ,3866
+slideflow/_version.py,sha256=r_K8GkuKKfau-zsPfxEFORCPadj6CgUro02PHUcnJSY,497
+slideflow/dataset.py,sha256=a_s_R7lekiKnwxiljxAXtoz-eDmVuUqewJ5WsEuR7Tc,160662
+slideflow/errors.py,sha256=wmud1rBTRwbI3PYmPz4HClXE2Ly-FnyQSJs0CGVU0LI,3922
 slideflow/heatmap.py,sha256=WVrSejL5bYz1QGjOSPd6uGIwCV-tIdSkR2qPyLUK9gU,40025
-slideflow/mosaic.py,sha256=GjceACaGgxo2UKqa4AA0RSNaiGTMvEgW0ceFPUpjkrA,25615
-slideflow/project.py,sha256=do9n8psKyemUyWQ7nY1yl_ofI1JtZDB8kYrjIjga8YQ,168044
+slideflow/mosaic.py,sha256=JcnXKOSNGV0Lvlmpx0e18QSBmaKPoMXxy06kwTOmzKE,26008
+slideflow/project.py,sha256=THsmn_9T2cCMVUz-pJNbn_a7QeRh7a8B42j8oxLronA,169434
 slideflow/project_utils.py,sha256=ollersimiyYZC6VYRBvom_Q4Ij15Ku18BtRwEFMuzfw,33332
 slideflow/sample_actions.py,sha256=khhho6m0GzAXUD9licPFKlq8oxqY3hdP1qg1B3CTOMY,978
 slideflow/biscuit/__init__.py,sha256=iSjHWIB2GZloqeMxPhNSpb90gBagYm_hX7xut8rKf48,1195
 slideflow/biscuit/delong.py,sha256=3zc0ctK1ZVHaeyFfxOzkKU8doNlzbfPiNkeA18moCs0,4281
 slideflow/biscuit/errors.py,sha256=nAGXgZnJT6GAUs0zw6tNZ3jCfPM_7U3rcu1roSWe1zA,318
 slideflow/biscuit/experiment.py,sha256=SNrkbYkrOlX_-Pf1LY7cuG2GcX8UYvrhbVhcPkOr5Gs,46729
 slideflow/biscuit/hp.py,sha256=bSuup8s4G9mxpSZ0Wy1ADlpmsNfbBsXzv1dmspAOPGU,1260
@@ -159,15 +159,15 @@
 slideflow/io/tensorflow.py,sha256=R52b44ZkKdUUoXHGDh02v28pV1fJ07EJ1LhmYKQQRi0,34511
 slideflow/io/torch.py,sha256=AD-9UXRWlHWXaGt8sgblar7gp9nZ5M1Jow6nMkSw7iQ,45085
 slideflow/io/preservedsite/__init__.py,sha256=9chqMmsn_iKvFwnTxZtVr4Pn08dyOeEi4YpgKhrf1Kw,68
 slideflow/io/preservedsite/crossfolds.py,sha256=UD4e0JqgZJeYl9lfrFHkCKhePJHGbsB20ZK6CA3g7bU,8419
 slideflow/mil/__init__.py,sha256=H_nvcxN4HLMS_rnghdaBTqeaG6gb-7sJctm0UVz38Fc,284
 slideflow/mil/_params.py,sha256=sCpjitfJxCcsx7iTnOHqD2cLXJe0Z-qxzcldUTYWgBI,14819
 slideflow/mil/data.py,sha256=DIUUAPhAk0qthJQT6Oe4cfIxJmR5BXKPTbnXzH_sKoo,5160
-slideflow/mil/eval.py,sha256=I5nqtWM-NzxVt5QboL5hU8nhEMcC1AgWfa5oYS6Xi-g,15565
+slideflow/mil/eval.py,sha256=doaogpmKGolnA8PRDWWpl6jQldiV5JYQoe6AK6_nFvs,15507
 slideflow/mil/clam/__init__.py,sha256=XFJYtb4FK5xQm7DqdmW3gBnG8IHYEjh3S1pzwFcbDKE,3890
 slideflow/mil/clam/create_attention.py,sha256=oGjZEfcT0zRqMhB8XITtFXHdw5Y9lNT9ZeiOcjntFtE,4334
 slideflow/mil/clam/datasets/__init__.py,sha256=lrqpfKa8fvcZHBzpmdJWt1uikjTNV8ZKqqpMIoRJkh4,1131
 slideflow/mil/clam/datasets/dataset_generic.py,sha256=Ulj-XQigidFsdx_DAoJ-RTQnY3jZucDtZH3YJ95Sw4g,14990
 slideflow/mil/clam/utils/__init__.py,sha256=EbG-maRA3elGYWTGMzVZbQfRqf2p9I8ojMHHJkb1MgU,5914
 slideflow/mil/clam/utils/core_utils.py,sha256=hWgMxfLv4gRWwyBzS0vhDRGJ4IF_AUz6IA6SedbII7U,19782
 slideflow/mil/clam/utils/eval_utils.py,sha256=zFFeNXOP-FhUg2HrYJxG_k5BUFwso1tJo_-kpIxAmWY,4150
@@ -181,15 +181,15 @@
 slideflow/mil/models/transmil.py,sha256=CpVxNifuytkGE7oRUcc2nFWJQHWo51xGXHtn8BIvk7A,4137
 slideflow/mil/train/__init__.py,sha256=SNILpMx3nYeBFYmO2Y_PoJAiC0LgdGKRAKD_pE052ec,15008
 slideflow/mil/train/_fastai.py,sha256=Af8wZL5gOaoKYq8helUE5SpfuxfcdZ8XxB24p4XXFTA,8214
 slideflow/mil/train/_legacy.py,sha256=v1s5Gqc46BZggwz7dcNyLuqVIM9lIYgUfNqTfH6d90A,7795
 slideflow/model/__init__.py,sha256=oJpmQVOsQiDUhI7RqD7WC3n5dKxkrOSA5Emkfgs-Vf0,7485
 slideflow/model/adv_utils.py,sha256=qt25QlPxEQk7vJtqc82DBlkw9KgSf8KkJvpC0ATzF7s,1879
 slideflow/model/base.py,sha256=0tOogk4fN9FMkrJCK5K0lgh3_vVI6KQIrfgMKBPQtg4,23588
-slideflow/model/features.py,sha256=_iiSEho53mP1F4u2f8qNI9_6LuyvEVFy9oXa4wiIU4c,55334
+slideflow/model/features.py,sha256=0rsbGiPHgPRn_nZllWmltuph8dYOXTAevbqwYsoIALc,55541
 slideflow/model/tensorflow.py,sha256=OY3JY_UK5ZIPdHGkjzQJfGE141LsWeQbaSWP7WMIYHg,110908
 slideflow/model/tensorflow_utils.py,sha256=5HYrVE8Ph3pSXjMfSRi7vmJIC_8mD3pQd28LLj1YAEY,22547
 slideflow/model/torch.py,sha256=vwjNP-xIB7MPpmCsjrgBLhckJ0M2OKYMaL6F1MlDFUo,103271
 slideflow/model/torch_utils.py,sha256=wFUA6VgDydOFVqZj-pWRXlp7PPbdV7-W_ZlMi9rszSU,17005
 slideflow/model/extractors/__init__.py,sha256=MEt448aADc_WUGzTSGF5IvW4Neu2atSiAFAyxzc-4uI,394
 slideflow/model/extractors/_factory.py,sha256=CXR4fa08GLM8Q4b_S5qIO1bmtzRX1VDtYrU7PjPFUHI,3708
 slideflow/model/extractors/_factory_tensorflow.py,sha256=zpvP7rOYQEvbuZbSlFY_L7iV0dub53kHS8fAcYNnaHs,4544
@@ -203,47 +203,50 @@
 slideflow/norm/macenko.py,sha256=eu58kIhs8FK_6xiJr8rlzFOxxlPR1lJ2GMnAPG7Pl-Y,13438
 slideflow/norm/norm_tile.jpg,sha256=Y3wWM8FDrsfYdiMhReDBC90Rf7Io5s8Ga0UJx4oBGQk,177672
 slideflow/norm/reinhard.py,sha256=cYI--gXzLY-xpqPURpJKF8YsPIXcY0tAQ3MgVJacgwM,16964
 slideflow/norm/utils.py,sha256=dA9JzmAhz1tnzKoCBAgbTPX6iLNhfm6phd9Ng5xWrz0,15314
 slideflow/norm/vahadane.py,sha256=YIRyky8TCVqT_H95wijSbwgOPoOMhH9bApKABypLP30,7836
 slideflow/norm/tensorflow/__init__.py,sha256=EKJBEUXsly7J1j_Z5byskYVpQJzMXUXsOWMpJjrq3lM,11998
 slideflow/norm/tensorflow/color.py,sha256=ei3alBtNb-xm1pHhJdtJoVuS_tPkISh1rXZ6Sl_DvwM,5879
-slideflow/norm/tensorflow/macenko.py,sha256=J4jfuDBJUWpxriY8uPg23QDZyNfYh7Lsurn1j_eTOTE,20759
+slideflow/norm/tensorflow/macenko.py,sha256=8c-gPeMAuc1aUf0FC4acPgcgtJmUoEM9xA9-ZXB9GB8,22672
 slideflow/norm/tensorflow/reinhard.py,sha256=w0DsrQx7bq57u7HpC5bgQZBjOlqNsHOnEfQrfXfcASU,26169
 slideflow/norm/tensorflow/utils.py,sha256=IcTPD8wR5h8Gqso0O-d6mlR-LrU6d1cJdnkj62XIHm0,1685
 slideflow/norm/torch/__init__.py,sha256=xigN3UHKRzO_--2eUzfmKi9F6MgV5rSMuJErCzVt14c,12095
 slideflow/norm/torch/color.py,sha256=dN1FpcvdVLvmkjGdc77rA4r0q0Clhhr_sQR2fEh18Vc,7826
-slideflow/norm/torch/macenko.py,sha256=OzwzBmbTNjk5fIT_6PxsPsHAxY4J2YkSvsrFUYetPMM,15296
+slideflow/norm/torch/macenko.py,sha256=OrMPj4geCkKYc_MabCZpaVP5QEBplq0vdUdsMcpK9FM,15306
 slideflow/norm/torch/reinhard.py,sha256=xE74ZJQTDJckRgumwNikRy3UT8KDq1EoumHO3x3BaVc,24997
 slideflow/norm/torch/utils.py,sha256=MstCD6KIJGG2a7xHAfSpLVr95jcoKrXrW2xDxch79pQ,1673
 slideflow/simclr/__init__.py,sha256=o8TiOkbZzvsQo6bISoejBrOscbq_l-akGzbGr92rkK4,458
 slideflow/simclr/simclr/__init__.py,sha256=M1HPoNrZnhd3zOIQyYO1YXGBeA22ZXmi6BeSccg5774,6
 slideflow/simclr/simclr/tf2/__init__.py,sha256=_z4lp94Onev6T60Ny_ScPHYZoLMoNhuwCxxBNkjSXdo,21046
 slideflow/simclr/simclr/tf2/data.py,sha256=wKVweVOUpusJfo9lkGpN5lo_xiDOr-lUfjBtZIlymzA,10701
 slideflow/simclr/simclr/tf2/data_util.py,sha256=wu0vlo_H_yL8aFCWWGpknf1Z3Apu3gsiyaiEGaEPcRY,18550
 slideflow/simclr/simclr/tf2/lars_optimizer.py,sha256=XWLnxqVxRlUY6PsQOHiCsFB6Lluk3TOokasLH9TTO-o,6505
 slideflow/simclr/simclr/tf2/metrics.py,sha256=RUtmvVamcnS-8_ZXLE2XdALsLgNgVPOUNl17hKPk13Y,2997
 slideflow/simclr/simclr/tf2/model.py,sha256=3p7YnZeZS09XOkPbVJ19dl77h7w3DNuf4c6rd6gqlqA,12256
 slideflow/simclr/simclr/tf2/objective.py,sha256=v5V1UzGCaSzT1i6xDe4UOaUIOhQyZ9sPDlrEP_2XYQ8,4983
 slideflow/simclr/simclr/tf2/resnet.py,sha256=BJgzhGO3TudNubzAAsx3jl8wsUW6DJ8EzivN3qlV9wY,28397
 slideflow/simclr/simclr/tf2/run.py,sha256=8Ej3YtqrKgpqlh0sjyqbUmKvLPGIRLz7XYi44dpvPE0,6524
 slideflow/simclr/simclr/tf2/utils.py,sha256=BEiKTWmuJ0XbZfG15413xPs_KnNmRg5uYL0QZEzgDYo,9517
-slideflow/slide/__init__.py,sha256=V9AzoJOlJnvihmy_wM4spLRWeK6-g_uNLPwQJCrjnQQ,114953
+slideflow/slide/__init__.py,sha256=ro-ibaeiE_w4BuVE2aVrbmjtgGnkTmciU-9_qvHOW3o,115204
 slideflow/slide/report.py,sha256=4vAxYiLaqHaoLSeLFLxZmSbIhg7Hv3UbhPhQk1xuC6g,19076
 slideflow/slide/slideflow-logo-name-small.jpg,sha256=C9-2QV_cZkmn_FqzvorF5GvrkD__VE-7NSKME58fTR8,30934
 slideflow/slide/utils.py,sha256=5NmVU1LdFdBciwJLg_Sh9xMU4DgXEVKEB-XV7jBf2lc,5516
-slideflow/slide/backends/__init__.py,sha256=9BjTu2AaVW8zySEvLrZ-RQ21ET9kqSajYV8YkCMpAzU,708
-slideflow/slide/backends/cucim.py,sha256=dcQzgy8BzktiOY2v8t_EJn35X7OG4orC1RMWPv-qRZ4,14008
-slideflow/slide/backends/vips.py,sha256=VbBwd4S8q2-YyXl_56Nb12E8XW5-u8gWu43jXo6YN9A,22391
+slideflow/slide/backends/__init__.py,sha256=hqSG2dXl8jj578W6wa-3uPgKugBqwj2zKO7ugfku71o,1035
+slideflow/slide/backends/cucim.py,sha256=jweC9lnylwQLlg0FbMFFU48VukShrciWx8UoSA8f6PI,14301
+slideflow/slide/backends/vips.py,sha256=yTKwt7Doxd0e5bZkhHMdZrE3vNOR_4blVoV0cyeusxs,22863
 slideflow/slide/qc/__init__.py,sha256=ePMfd6ZlrWdxYiRkS6gsCIMoGfS3hDPuqIyjX7kQT30,117
+slideflow/slide/qc/deepfocus.py,sha256=6wN5GWvXOi6QEIdAYMccuG1YTzLh5-u-yh6CnEBh1TI,8151
 slideflow/slide/qc/deepfocus_qc.py,sha256=TuHOVLYPWUD_8hYS0OFzmLvgDNAoxxuykeEcb4_xuKc,1010
 slideflow/slide/qc/gaussian.py,sha256=JGBXw0A2mDx34EZepK6A8DT22DppkZIj8P3HZcM6QEU,4304
+slideflow/slide/qc/gaussian_v2.py,sha256=w3FQGsrfI_wXZhEcU15m8cWDvQB9v4-xLZXtZD1Zdqs,5341
 slideflow/slide/qc/otsu.py,sha256=l1ipll7WH8XSno5jCNf6Jdct6cVmwjiKC7IXD_L1UKA,5232
 slideflow/slide/qc/saver.py,sha256=g4aT4PGxNjHj0ZCvWx0odkc_b-_pFXvCYEYKEMR4z3Y,3028
 slideflow/slide/qc/strided_dl.py,sha256=rQqqovzbjFQrPp8ZvOjewQqbL1DMZGzfEc68NrPybhA,4676
+slideflow/slide/qc/strided_qc.py,sha256=ioSC_GSaZ9fBQrfv6D8A61Tww9pVJLkUhFXl884TvUI,13029
 slideflow/stats/__init__.py,sha256=PoUMiNzTv2ra_wvkFgwz7ZjJRu0G_aD2tebhEc01BKw,390
 slideflow/stats/delong.py,sha256=C6QaDckNp9FDmwjPkoHDv8qTaT_Yaipa-ky-43tDBtM,4293
 slideflow/stats/metrics.py,sha256=h0cR4Yuh1FziuL0RZNGrNlDn69c-Q6ASL2aFTqiRqMw,35785
 slideflow/stats/plot.py,sha256=qnyOA--h_SmGR0uyGGRXVQhk-Z3wRMM38__leADAtrQ,5757
 slideflow/stats/slidemap.py,sha256=vXS39-CyQ-3WA_ILUQs99GcBTtKjWyUjw2ebVlyMpuQ,43101
 slideflow/stats/stats_utils.py,sha256=jk7vmXMk_cGUrMwT0vGc1JSwnNCXj97LoWS7IzN8G6k,3261
 slideflow/studio/__init__.py,sha256=pwtCiDS_IMebIAytNu8p1XH3OgY_YJRMWz443mE_P1w,77576
@@ -309,15 +312,15 @@
 slideflow/studio/gui/icons/warn.png,sha256=mAVKiVI85LF10roGtrrOf43DE5gpR4XORYh3z62iACU,6817
 slideflow/studio/gui/viewer/__init__.py,sha256=9wiXSrhD8Raz5AVGdCBrF-Fykn1sNqkqGgjfXtRwNuU,107
 slideflow/studio/gui/viewer/_mosaic.py,sha256=dKDyGt12-f9sju5g0plSJUoOiP4uYAH2emiK3vQFUb0,7874
 slideflow/studio/gui/viewer/_slide.py,sha256=JZHy-MzIOBxn6gEyMcoNx3CmXnplYsiOWirt_2rY5CQ,26041
 slideflow/studio/gui/viewer/_viewer.py,sha256=M_aVUL7tZRyOI2OhI3xiRUVpQe3kunoLAt5kfRMxZSM,14452
 slideflow/studio/widgets/__init__.py,sha256=M8gSPhj8W4FThgSm5kMF1GuAffF1PkauBfU5xtwAmxI,439
 slideflow/studio/widgets/_utils.py,sha256=jI9Ah-aO4SPN8CdBB0pWV2-bxifLSW6DpGK106938js,735
-slideflow/studio/widgets/capture.py,sha256=MtXvouNKrMcxfmHVN4xBv1ODK-clnC3-QzH8waowHmc,4264
+slideflow/studio/widgets/capture.py,sha256=ReS_0x1Alz328yTnDy4Wq09XQZ1aFb0HYJoM90CsY_4,4362
 slideflow/studio/widgets/extensions.py,sha256=V7u_T1t5IxiqRfiza9ru5UgvPBUruvLI7dXmTBwlnm8,5412
 slideflow/studio/widgets/heatmap.py,sha256=P_7Bpz3T9MxxFBCeA9moD0TcLRkrbJvV_1QlRVbRriY,16890
 slideflow/studio/widgets/layer_umap.py,sha256=Dol3NIxJge6Ff2e80Ydjvfh0xc8CBMb34DmM-n1lPmg,3842
 slideflow/studio/widgets/model.py,sha256=T50CTM8jt1e_lNrmh4zx7XOQdTh9S6RApmnJp1Gh7fw,24474
 slideflow/studio/widgets/mosaic.py,sha256=u1a_HvZ20PWuzdQ1EVAWIP9HOUE85m42OvLDY0i4pKk,14307
 slideflow/studio/widgets/mosaic_experimental.py,sha256=_Z3huwfE3uJeP3-Fs_PwAvJ00T8ekykeWBvTH2AXN4k,2597
 slideflow/studio/widgets/performance.py,sha256=kTk3fuS6M5mQ5K4pmKZvx5sVJC070IHImfPTCQbxNec,4662
@@ -339,21 +342,21 @@
 slideflow/tfrecord/__init__.py,sha256=YsF14xnyOnYgR2CCaj6zl0_YSeF7z3CqxZ0yO11dll0,891
 slideflow/tfrecord/iterator_utils.py,sha256=IFRjADsWLpfN65GSZp_1F2CEcgPRw77FszXHNcSegvs,2905
 slideflow/tfrecord/reader.py,sha256=vGf6X-5JRMeUQN1gDDvfXJ131QbHEHhK16bq8CDN_Bw,15505
 slideflow/tfrecord/writer.py,sha256=47JbvdMp9xcx3RgacsIXZ0MlDm2bjREIYWG-XlcFzpQ,5637
 slideflow/tfrecord/tools/__init__.py,sha256=3082iuyLMnQ8Gc2WFwulW1sSJwBqIJPnBNoMT-VuW-o,179
 slideflow/tfrecord/torch/__init__.py,sha256=zl9XVfdCnojlhGDx0mwtqCbjMyj1ypROP-Ut2J_M7eQ,310
 slideflow/tfrecord/torch/dataset.py,sha256=Vc9q1vHG0xTtMu-tsi-kX1c9wM95BNWb9r5CWzh8B0w,7857
-slideflow/util/__init__.py,sha256=TMQxyDxeUjuQnaD6wymJ5tm8iuL5ERyTwbLvkoF2Sj4,41607
+slideflow/util/__init__.py,sha256=AI2iiKFF9EScqoauo5GQqxbWXcXePId48EmDfXfszKk,41943
 slideflow/util/colors.py,sha256=KOfggJhBNe3uHYa4MNQYdJnOb3A-Nyl1lxIMQ6Sqivc,738
 slideflow/util/example_pb2.py,sha256=oU4oQBXz89HAyrehrDeK-uJYqL7eNznjd8y3YDwn0dY,17912
 slideflow/util/log_utils.py,sha256=kyfTOCmSJW7gIW_1nHXiyPydN-jyO8YEBM3wiEb5OUc,4468
 slideflow/util/neptune_utils.py,sha256=rus5wDerStaFQalTbF9VaEbi6OelhkpkUHmwt0ggejQ,4381
 slideflow/util/smac_utils.py,sha256=T_-b1Wv0V2fQVX-FGlnhX1i4bu69imixlbAJd2aNJgs,20061
 slideflow/util/tfrecord2idx.py,sha256=wQjewrIjxXrC3Z9Zp9-jfjrPR-WOHC3lohoftSrxtEk,8064
-slideflow-2.0.3.post1.data/scripts/slideflow-studio,sha256=BljDc6Eig-Hl5HLA41v-5VENDbTTkmHtK-mUAGHM1Ro,14085
-slideflow-2.0.3.post1.data/scripts/slideflow-studio.py,sha256=dYg_ktDH_I74oIs8Sj4l56M-03frzO4KisE7WeXAofI,14085
-slideflow-2.0.3.post1.dist-info/LICENSE,sha256=OXLcl0T2SZ8Pmy2_dmlvKuetivmyPd5m1q-Gyd-zaYY,35149
-slideflow-2.0.3.post1.dist-info/METADATA,sha256=awKv87-0h-uwmA4cJAzqx11wzxMX-DNSkXf0rwgi3dU,13030
-slideflow-2.0.3.post1.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-slideflow-2.0.3.post1.dist-info/top_level.txt,sha256=FRikcoh3_TcsLUYbI4LowF3nrEDWcGLaAyNgsi9Lu9M,10
-slideflow-2.0.3.post1.dist-info/RECORD,,
+slideflow-2.0.4.data/scripts/slideflow-studio,sha256=BljDc6Eig-Hl5HLA41v-5VENDbTTkmHtK-mUAGHM1Ro,14085
+slideflow-2.0.4.data/scripts/slideflow-studio.py,sha256=dYg_ktDH_I74oIs8Sj4l56M-03frzO4KisE7WeXAofI,14085
+slideflow-2.0.4.dist-info/LICENSE,sha256=OXLcl0T2SZ8Pmy2_dmlvKuetivmyPd5m1q-Gyd-zaYY,35149
+slideflow-2.0.4.dist-info/METADATA,sha256=Vz4WD-VPZMkeDS5TxOGAlWn_PgmilDXVzufTPtFwjkQ,13038
+slideflow-2.0.4.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+slideflow-2.0.4.dist-info/top_level.txt,sha256=FRikcoh3_TcsLUYbI4LowF3nrEDWcGLaAyNgsi9Lu9M,10
+slideflow-2.0.4.dist-info/RECORD,,
```

