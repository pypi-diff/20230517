# Comparing `tmp/bpnet_lite-0.3.1-py3-none-any.whl.zip` & `tmp/bpnet_lite-0.3.2-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,18 +1,19 @@
-Zip file size: 30120 bytes, number of entries: 16
--rwxr-xr-x  2.0 unx     9234 b- defN 23-Apr-11 06:06 bpnet_lite-0.3.1.data/scripts/bpnet
--rwxr-xr-x  2.0 unx     8649 b- defN 23-Apr-11 06:06 bpnet_lite-0.3.1.data/scripts/chrombpnet
+Zip file size: 36058 bytes, number of entries: 17
+-rwxr-xr-x  2.0 unx    10342 b- defN 23-May-17 20:55 bpnet_lite-0.3.2.data/scripts/bpnet
+-rwxr-xr-x  2.0 unx     8915 b- defN 23-May-17 20:55 bpnet_lite-0.3.2.data/scripts/chrombpnet
 -rw-r--r--  2.0 unx      175 b- defN 23-Apr-11 06:05 bpnetlite/__init__.py
--rw-r--r--  2.0 unx    10712 b- defN 23-Mar-23 21:47 bpnetlite/attributions.py
--rw-r--r--  2.0 unx    15775 b- defN 23-Apr-11 05:40 bpnetlite/bpnet.py
--rw-r--r--  2.0 unx     5827 b- defN 23-Feb-26 21:40 bpnetlite/chrombpnet.py
--rw-r--r--  2.0 unx    17015 b- defN 22-Nov-17 02:16 bpnetlite/io.py
+-rw-r--r--  2.0 unx    10686 b- defN 23-Apr-22 03:34 bpnetlite/attributions.py
+-rw-r--r--  2.0 unx    16333 b- defN 23-Apr-21 21:12 bpnetlite/bpnet.py
+-rw-r--r--  2.0 unx     8981 b- defN 23-Apr-21 21:11 bpnetlite/chrombpnet.py
+-rw-r--r--  2.0 unx    17417 b- defN 23-Apr-22 00:32 bpnetlite/io.py
 -rw-r--r--  2.0 unx     1643 b- defN 22-Oct-24 22:28 bpnetlite/logging.py
 -rw-r--r--  2.0 unx     2418 b- defN 22-May-03 00:14 bpnetlite/losses.py
--rw-r--r--  2.0 unx     3674 b- defN 23-Jan-20 02:13 bpnetlite/marginalize.py
+-rw-r--r--  2.0 unx     4566 b- defN 23-Apr-22 06:53 bpnetlite/marginalize.py
+-rw-r--r--  2.0 unx     9144 b- defN 23-May-17 19:48 bpnetlite/negatives.py
 -rw-r--r--  2.0 unx    13599 b- defN 22-May-04 18:11 bpnetlite/performance.py
--rw-r--r--  2.0 unx     1072 b- defN 23-Apr-11 06:06 bpnet_lite-0.3.1.dist-info/LICENSE
--rw-r--r--  2.0 unx      722 b- defN 23-Apr-11 06:06 bpnet_lite-0.3.1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-11 06:06 bpnet_lite-0.3.1.dist-info/WHEEL
--rw-r--r--  2.0 unx       10 b- defN 23-Apr-11 06:06 bpnet_lite-0.3.1.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     1294 b- defN 23-Apr-11 06:06 bpnet_lite-0.3.1.dist-info/RECORD
-16 files, 91911 bytes uncompressed, 28006 bytes compressed:  69.5%
+-rw-r--r--  2.0 unx     1072 b- defN 23-May-17 20:55 bpnet_lite-0.3.2.dist-info/LICENSE
+-rw-r--r--  2.0 unx      722 b- defN 23-May-17 20:55 bpnet_lite-0.3.2.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-17 20:55 bpnet_lite-0.3.2.dist-info/WHEEL
+-rw-r--r--  2.0 unx       10 b- defN 23-May-17 20:55 bpnet_lite-0.3.2.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     1374 b- defN 23-May-17 20:55 bpnet_lite-0.3.2.dist-info/RECORD
+17 files, 107489 bytes uncompressed, 33824 bytes compressed:  68.5%
```

## zipnote {}

```diff
@@ -1,11 +1,11 @@
-Filename: bpnet_lite-0.3.1.data/scripts/bpnet
+Filename: bpnet_lite-0.3.2.data/scripts/bpnet
 Comment: 
 
-Filename: bpnet_lite-0.3.1.data/scripts/chrombpnet
+Filename: bpnet_lite-0.3.2.data/scripts/chrombpnet
 Comment: 
 
 Filename: bpnetlite/__init__.py
 Comment: 
 
 Filename: bpnetlite/attributions.py
 Comment: 
@@ -24,26 +24,29 @@
 
 Filename: bpnetlite/losses.py
 Comment: 
 
 Filename: bpnetlite/marginalize.py
 Comment: 
 
+Filename: bpnetlite/negatives.py
+Comment: 
+
 Filename: bpnetlite/performance.py
 Comment: 
 
-Filename: bpnet_lite-0.3.1.dist-info/LICENSE
+Filename: bpnet_lite-0.3.2.dist-info/LICENSE
 Comment: 
 
-Filename: bpnet_lite-0.3.1.dist-info/METADATA
+Filename: bpnet_lite-0.3.2.dist-info/METADATA
 Comment: 
 
-Filename: bpnet_lite-0.3.1.dist-info/WHEEL
+Filename: bpnet_lite-0.3.2.dist-info/WHEEL
 Comment: 
 
-Filename: bpnet_lite-0.3.1.dist-info/top_level.txt
+Filename: bpnet_lite-0.3.2.dist-info/top_level.txt
 Comment: 
 
-Filename: bpnet_lite-0.3.1.dist-info/RECORD
+Filename: bpnet_lite-0.3.2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## bpnetlite/attributions.py

```diff
@@ -1,19 +1,23 @@
 # attributions.py
 # Author: Jacob Schreiber <jmschreiber91@gmail.com>
 
+import time
 import numpy
 import numba
 import torch
 import pandas
 import logomaker
 
 from tqdm import trange
 from captum.attr import DeepLiftShap
 
+import warnings
+warnings.filterwarnings("ignore", category=UserWarning)
+
 
 class ProfileWrapper(torch.nn.Module):
 	"""A wrapper class that returns transformed profiles.
 
 	This class takes in a trained model and returns the weighted softmaxed
 	outputs of the first dimension. Specifically, it takes the predicted
 	"logits" and takes the dot product between them and the softmaxed versions
@@ -59,56 +63,56 @@
 		self.model = model
 
 	def forward(self, X, X_ctl=None, **kwargs):
 		return self.model(X, X_ctl, **kwargs)[1]
 
 
 def hypothetical_attributions(multipliers, inputs, baselines):
-    """A function for aggregating contributions into hypothetical attributions.
+	"""A function for aggregating contributions into hypothetical attributions.
 
-    When handling categorical data, like one-hot encodings, the attributions
-    returned by a method like DeepLIFT/SHAP may need to be modified slightly.
-    Specifically, one needs to account for each nucleotide change actually
-    being the addition of one category AND the subtraction of another category.
-    Basically, once you've calculated the multipliers, you need to subtract
-    out the contribution of the nucleotide actually present and then add in
-    the contribution of the nucleotide you are becomming.
+	When handling categorical data, like one-hot encodings, the attributions
+	returned by a method like DeepLIFT/SHAP may need to be modified slightly.
+	Specifically, one needs to account for each nucleotide change actually
+	being the addition of one category AND the subtraction of another category.
+	Basically, once you've calculated the multipliers, you need to subtract
+	out the contribution of the nucleotide actually present and then add in
+	the contribution of the nucleotide you are becomming.
 
-    These values are then averaged over all references.
+	These values are then averaged over all references.
 
 
-    Parameters
-    ----------
-    multipliers: torch.tensor, shape=(n_baselines, 4, length)
-    	The multipliers determined by DeepLIFT
+	Parameters
+	----------
+	multipliers: torch.tensor, shape=(n_baselines, 4, length)
+		The multipliers determined by DeepLIFT
 
-    inputs: torch.tensor, shape=(n_baselines, 4, length)
-    	The one-hot encoded sequence being explained, copied several times.
+	inputs: torch.tensor, shape=(n_baselines, 4, length)
+		The one-hot encoded sequence being explained, copied several times.
 
-    baselines: torch.tensor, shape=(n_baselines, 4, length)
-    	The one-hot encoded baseline sequences.
+	baselines: torch.tensor, shape=(n_baselines, 4, length)
+		The one-hot encoded baseline sequences.
 
 
-    Returns
-    -------
+	Returns
+	-------
 	projected_contribs: torch.tensor, shape=(1, 4, length)
 		The attribution values for each nucleotide in the input.
 	"""
 
-    projected_contribs = torch.zeros_like(baselines[0], dtype=baselines[0].dtype)
-    
-    for i in range(inputs[0].shape[1]):
-        hypothetical_input = torch.zeros_like(inputs[0], dtype=baselines[0].dtype)
-        hypothetical_input[:, i] = 1.0
-        hypothetical_diffs = hypothetical_input - baselines[0]
-        hypothetical_contribs = hypothetical_diffs * multipliers[0]
-        
-        projected_contribs[:, i] = torch.sum(hypothetical_contribs, dim=1)
-    
-    return (projected_contribs,)
+	projected_contribs = torch.zeros_like(baselines[0], dtype=baselines[0].dtype)
+	
+	for i in range(inputs[0].shape[1]):
+		hypothetical_input = torch.zeros_like(inputs[0], dtype=baselines[0].dtype)
+		hypothetical_input[:, i] = 1.0
+		hypothetical_diffs = hypothetical_input - baselines[0]
+		hypothetical_contribs = hypothetical_diffs * multipliers[0]
+		
+		projected_contribs[:, i] = torch.sum(hypothetical_contribs, dim=1)
+
+	return (projected_contribs,)
 
 
 @numba.jit('void(int64, int64[:], int64[:], int32[:, :], int32[:,], int32[:, :], float32[:, :, :])')
 def _fast_shuffle(n_shuffles, chars, idxs, next_idxs, next_idxs_counts, counters, shuffled_sequences):
 	"""An internal function for fast shuffling using numba."""
 
 	for i in range(n_shuffles):
@@ -263,15 +267,15 @@
 		wrapper = ProfileWrapper(model)
 	elif model_output == "count":
 		wrapper = CountWrapper(model)
 	else:
 		raise ValueError("model_output must be one of 'profile' or 'count'.")
 
 	ig = DeepLiftShap(wrapper)
-	
+
 	attributions = []
 	references = []
 	with torch.no_grad():
 		for i in trange(len(X), disable=not verbose):
 			X_ = X[i:i+1]
 			reference = dinucleotide_shuffle(X_[0], n_shuffles=n_shuffles, 
 				random_state=random_state).cuda()
@@ -290,15 +294,15 @@
 			if not hypothetical:
 				attr = (attr * X_)
 			
 			if return_references:
 				references.append(reference.unsqueeze(0))
 
 			attributions.append(attr.cpu())
-	
+
 	attributions = torch.cat(attributions)
 
 	if return_references:
 		return attributions, torch.cat(references)
 	return attributions
```

## bpnetlite/bpnet.py

```diff
@@ -254,15 +254,15 @@
 
 			y_profiles = torch.cat(y_profiles)
 			y_counts = torch.cat(y_counts)
 			return y_profiles, y_counts
 
 	def fit(self, training_data, optimizer, X_valid=None, X_ctl_valid=None, 
 		y_valid=None, max_epochs=100, batch_size=64, validation_iter=100, 
-		verbose=True):
+		early_stopping=None, verbose=True):
 		"""Fit the model to data and validate it periodically.
 
 		This method controls the training of a BPNet model. It will fit the
 		model to examples generated by the `training_data` DataLoader object
 		and, if validation data is provided, will periodically validate the
 		model against it and return those values. The periodicity can be
 		controlled using the `validation_iter` parameter.
@@ -304,28 +304,35 @@
 
 		validation_iter: int
 			The number of batches to train on before validating against the
 			entire validation set. When the validation set is large, this
 			enables the total validating time to be small compared to the
 			training time by only validating periodically. Default is 100.
 
+		early_stopping: int or None
+			Whether to stop training early. If None, continue training until
+			max_epochs is reached. If an integer, continue training until that
+			number of `validation_iter` ticks has been hit without improvement
+			in performance. Default is None.
+
 		verbose: bool
 			Whether to print out the training and evaluation statistics during
 			training. Default is True.
 		"""
 
 		if X_valid is not None:
 			X_valid = X_valid.cuda()
 			y_valid_counts = y_valid.sum(dim=2)
 
 		if X_ctl_valid is not None:
 			X_ctl_valid = X_ctl_valid.cuda()
 
 
 		iteration = 0
+		early_stop_count = 0
 		best_loss = float("inf")
 		self.logger.start()
 
 		for epoch in range(max_epochs):
 			tic = time.time()
 
 			for data in training_data:
@@ -397,17 +404,26 @@
 							(valid_loss < best_loss).item()])
 
 						self.logger.save("{}.log".format(self.name))
 
 						if valid_loss < best_loss:
 							torch.save(self, "{}.torch".format(self.name))
 							best_loss = valid_loss
+							early_stop_count = 0
+						else:
+							early_stop_count += 1
+
+				if early_stopping is not None and early_stop_count >= early_stopping:
+					break
 
 				iteration += 1
 
+			if early_stopping is not None and early_stop_count >= early_stopping:
+				break
+
 		torch.save(self, "{}.final.torch".format(self.name))
 
 
 	@classmethod
 	def from_chrombpnet_lite(cls, filename):
 		"""Loads a model from ChromBPNet-lite TensorFlow format.
```

## bpnetlite/chrombpnet.py

```diff
@@ -12,14 +12,28 @@
 
 from .logging import Logger
 
 
 class ChromBPNet(torch.nn.Module):
 	"""A ChromBPNet model.
 
+	ChromBPNet is an extension of BPNet to handle chromatin accessibility data,
+	in contrast to the protein binding data that BPNet handles. The distinction
+	between these data types is that an enzyme used in DNase-seq and ATAC-seq
+	experiments itself has a soft sequence preference, meaning that the
+	strength of the signal is driven by real biology but that the exact read
+	mapping locations are driven by the soft sequence bias of the enzyme.
+
+	ChromBPNet handles this by treating the data using two models: a bias
+	model that is initially trained on background (non-peak) regions where
+	the bias dominates, and an accessibility model that is subsequently trained
+	using a frozen version of the bias model. The bias model learns to remove
+	the enzyme bias so that the accessibility model can learn real motifs.
+
+
 	Parameters
 	----------
 	bias: torch.nn.Module 
 		This model takes in sequence and outputs the shape one would expect in 
 		ATAC-seq data due to Tn5 bias alone. This is usually a BPNet model
 		from the bpnet-lite repo that has been trained on GC-matched non-peak
 		regions.
@@ -38,19 +52,15 @@
 		super(ChromBPNet, self).__init__()
 		for parameter in bias.parameters():
 			parameter.requires_grad = False
 
 		self.bias = bias
 		self.accessibility = accessibility
 		self.name = name
-		self.logger = Logger(["Epoch", "Iteration", "Training Time",
-			"Validation Time", "Training MNLL", "Training Count MSE", 
-			"Validation MNLL", "Validation Profile Correlation", 
-			"Validation Count Pearson", "Validation Count MSE", "Saved?"], 
-			verbose=True)
+		self.logger = None
 
 	def forward(self, X, X_ctl=None):
 		"""A forward pass through the network.
 
 		This function is usually accessed through calling the model, e.g.
 		doing `model(x)`. The method defines how inputs are transformed into
 		the outputs through interactions with each of the layers.
@@ -109,24 +119,85 @@
 		for start in range(0, len(X), batch_size):
 			y_profile_, y_counts_ = self(X[start:start+batch_size])
 			y_profile.append(y_profile_.cpu())
 			y_counts.append(y_counts_.cpu())
 
 		return torch.cat(y_profile), torch.cat(y_counts)
 
-	def fit_generator(self, training_data, optimizer, X_valid=None, y_valid=None,
-		max_epochs=100, batch_size=64, validation_iter=100, verbose=True):
-		"""Fit an entire DragoNNFruit model to the data.
+	def fit(self, training_data, optimizer, X_valid=None, y_valid=None,
+		max_epochs=100, batch_size=64, validation_iter=100, early_stopping=None, 
+		verbose=True):
+		"""Fit the ChromBPNet model to data.
+
+		Specifically, this function will fit the accessibility model to
+		observed chromatin accessibility data, and assume that the bias model
+		is frozen and pre-trained. Hence, the only parameters being trained
+		in this function are those in the accessibility model.
+
+		This function will save the best full ChromBPNet model, as well as the
+		best accessibility model, found during training.
+
+
+		Parameter
+		---------
+		training_data: torch.utils.data.DataLoader
+			A data set that generates one-hot encoded sequence as input and
+			read count signal for the output.
+
+		optimizer: torch.optim.Optimizer
+			A PyTorch optimizer.
+
+		X_valid: torch.Tensor or None, shape=(-1, 4, length)
+			A tensor of one-hot encoded sequences to use as input for the
+			validation steps. If None, do not do validation. Default is None.
+
+		y_valid: torch.Tensor or None, shape=(-1, 1, length)
+			A tensor of read counts matched with the `X_valid` input. If None,
+			do not do validation. Default is None.
+
+		max_epochs: int
+			The maximum number of training epochs to perform before stopping.
+			Default is 100.
+
+		batch_size: int
+			The number of examples to use in each batch. Default is 64.
+
+		validation_iter: int
+			The number of training batches to perform before doing another
+			round of validation. Set higher to spend a higher percentage of
+			time in the training step.
+
+		early_stopping: int or None
+			Whether to stop training early. If None, continue training until
+			max_epochs is reached. If an integer, continue training until that
+			number of `validation_iter` ticks has been hit without improvement
+			in performance. Default is None.
+
+		verbose: bool
+			Whether to print the log as it is being generated. A log will
+			be returned at the end of training regardless of this option, but
+			when False, nothing will be printed to the screen during training.
+			Default is False
 		"""
 
 		X_valid = X_valid.cuda(non_blocking=True)
 		y_bias_profile, y_bias_counts = self.bias.predict(X_valid)
 
+
+		self.logger = Logger(["Epoch", "Iteration", "Training Time",
+			"Validation Time", "Training MNLL", "Training Count MSE", 
+			"Validation MNLL", "Validation Profile Correlation", 
+			"Validation Count Pearson", "Validation Count MSE", "Saved?"], 
+			verbose=verbose)
+
+		early_stop_count = 0
 		start, best_loss = time.time(), float("inf")
+		
 		self.logger.start()
+		self.bias.eval()
 		for epoch in range(max_epochs):
 			for iteration, (X, y) in enumerate(training_data):
 				self.accessibility.train()
 
 				X = X.cuda()
 				y = y.cuda()
 
@@ -184,14 +255,26 @@
 							numpy.nan_to_num(profile_corr).mean(),
 							numpy.nan_to_num(count_corr).mean(), 
 							measures['count_mse'].mean().item(),
 							(valid_loss < best_loss).item()])
 
 						if valid_loss < best_loss:
 							torch.save(self, "{}.torch".format(self.name))
+							torch.save(self.accessibility, 
+								"{}.accessibility.torch".format(self.name))
 							best_loss = valid_loss
+							early_stop_count = 0
+						else:
+							early_stop_count += 1
 
 					start = time.time()
 
+				if early_stopping is not None and early_stop_count >= early_stopping:
+					break
+
 			self.logger.save("{}.log".format(self.name))
 
-		torch.save(self, "{}.final.torch".format(self.name, epoch))
+			if early_stopping is not None and early_stop_count >= early_stopping:
+				break
+
+		torch.save(self, "{}.final.torch".format(self.name))
+		torch.save(self, "{}.accessibility.final.torch".format(self.name))
```

## bpnetlite/io.py

```diff
@@ -161,15 +161,15 @@
 		if self.controls is not None:
 			return X, X_ctl, y
 
 		return X, y
 
 def extract_loci(loci, sequences, signals=None, controls=None, chroms=None, 
 	in_window=2114, out_window=1000, max_jitter=128, min_counts=None,
-	max_counts=None, verbose=False):
+	max_counts=None, n_loci=None, verbose=False):
 	"""Extract sequences and signals at coordinates from a locus file.
 
 	This function will take in genome-wide sequences, signals, and optionally
 	controls, and extract the values of each at the coordinates specified in
 	the locus file/s and return them as tensors.
 
 	Signals and controls are both lists with the length of the list, n_s
@@ -228,14 +228,20 @@
 		is None.
 
 	max_counts: float or None, optional
 		The maximum number of counts, summed across the length of each example
 		and across all tasks, needed to be kept. If None, no maximum. Default 
 		is None.  
 
+	n_loci: int or None, optional
+		A cap on the number of loci to return. Note that this is not the
+		number of loci that are considered. The difference is that some
+		loci may be filtered out for various reasons, and those are not
+		counted towards the total. If None, no cap. Default is None.
+
 	verbose: bool, optional
 		Whether to display a progress bar while loading. Default is False.
 
 	Returns
 	-------
 	seqs: torch.tensor, shape=(n, 4, in_window+2*max_jitter)
 		The extracted sequences in the same order as the loci in the locus
@@ -290,24 +296,28 @@
 			if isinstance(control, str):
 				controls[i] = pyBigWig.open(control, "r")
 
 	desc = "Loading Loci"
 	d = not verbose
 
 	max_width = max(in_width, out_width)
+	loci_count = 0
 
 	for chrom, start, end in tqdm(loci.values, disable=d, desc=desc):
 		mid = start + (end - start) // 2
 
 		if start - max_width - max_jitter < 0:
 			continue
 
 		if end + max_width + max_jitter >= len(sequences[chrom]):
 			continue
 
+		if n_loci is not None and loci_count == n_loci:
+			break 
+
 		start = mid - out_width - max_jitter
 		end = mid + out_width + max_jitter
 
 		# Extract the signal from each of the signal files
 		if signals is not None:
 			signals_.append([])
 			for signal in signals:
@@ -339,14 +349,15 @@
 		if isinstance(sequences, dict):
 			seq = sequences[chrom][start:end].T
 		else:
 			seq = one_hot_encode(sequences[chrom][start:end].seq.upper(), 
 				alphabet=['A', 'C', 'G', 'T', 'N']).T
 		
 		seqs.append(seq)
+		loci_count += 1
 
 	seqs = torch.tensor(numpy.array(seqs), dtype=torch.float32)
 
 	if signals is not None:
 		signals_ = torch.tensor(numpy.array(signals_), dtype=torch.float32)
 
 		idxs = torch.ones(signals_.shape[0], dtype=torch.bool)
```

## bpnetlite/marginalize.py

```diff
@@ -1,141 +1,183 @@
 # marginalize.py
 # Author: Jacob Schreiber <jmschreiber91@gmail.com>
 
 import os
+import time
 import numpy
 import torch
 import pandas
 import pyfaidx
 import seaborn
 import logomaker
 
 from .io import one_hot_encode
 from .attributions import calculate_attributions
 
 import matplotlib.pyplot as plt
 
 
+def read_meme(filename):
+	motifs = {}
+
+	with open(filename, "r") as infile:
+		motif, width, i = None, None, 0
+
+		for line in infile:
+			if motif is None:
+				if line[:5] == 'MOTIF':
+					motif = line.split()[1]
+				else:
+					continue
+
+			elif width is None:
+				if line[:6] == 'letter':
+					width = int(line.split()[5])
+					pwm = numpy.zeros((width, 4))
+
+			elif i < width:
+				pwm[i] = list(map(float, line.split()))
+				i += 1
+
+			else:
+				motifs[motif] = pwm
+				motif, width, i = None, None, 0
+
+	return motifs
+
+
 def marginalize(model, motif, X):
 	if isinstance(X, numpy.ndarray):
 		X = torch.from_numpy(X)
 
 	if model.n_control_tracks > 0:
 		X_ctl = torch.zeros(X.shape[0], model.n_control_tracks, X.shape[-1],
 			dtype=torch.float32)
 		args = (X_ctl,)
 	else:
 		X_ctl = None
 		args = None
 		
-
 	y_before_profile, y_before_counts = model.predict(X, X_ctl)
 	y_before_profile = torch.nn.functional.softmax(y_before_profile, dim=-1)
 	y_before = y_before_profile * y_before_counts.unsqueeze(-1)
 
-	attr_before = calculate_attributions(model, X, args=args)
+	attr_before = calculate_attributions(model, X, args=args, n_shuffles=10)
 
 	X_perturb = torch.clone(X)
-	motif_ohe = one_hot_encode(motif)
+	motif_ohe = one_hot_encode(motif, alphabet=['A', 'C', 'G', 'T', 'N'])
 	motif_ohe = torch.from_numpy(motif_ohe)
 
 	start = X.shape[-1] // 2 - len(motif) // 2
 	for i in range(len(motif)):
 		if motif_ohe[i].sum() > 0:
 			X_perturb[:, :, start+i] = motif_ohe[i]
 
 	y_after_profile, y_after_counts = model.predict(X_perturb, X_ctl)
 	y_after_profile = torch.nn.functional.softmax(y_after_profile, dim=-1)
 	y_after = y_after_profile * y_after_counts.unsqueeze(-1)
 
-	attr_after = calculate_attributions(model, X_perturb, args=args)
+	attr_after = calculate_attributions(model, X_perturb, args=args, 
+		n_shuffles=10)
+
 	return y_before, y_after, attr_before, attr_after
 
 
 def path_to_image_html(path):
-	return '<img src="'+ path + '" width="240" >'
+	return '<img src="' + path + '" width="240" >'
 
-def _plot_predictions(y, path, figsize=(10,3), **kwargs):
+def _plot_predictions(y, ylim, path, figsize=(10,3), **kwargs):
 	plt.figure(figsize=figsize)
-	plt.plot(y)
-
-	print(y.shape)
+	plt.plot(y, color='r')
+	#plt.plot(y_after, color='r')
 
 	seaborn.despine()
 	plt.xlim(0, y.shape[0])
+	plt.ylim(*ylim)
 	plt.yticks(fontsize=12)
 	plt.savefig(path)
 	plt.close()
 	
 
-def _plot_attributions(y, path, figsize=(10,3), **kwargs):
+def _plot_attributions(y, ylim, path, figsize=(10,3), **kwargs):
 	fig = plt.figure(figsize=figsize)
 	ax = fig.add_subplot(111) 
 
 	df = pandas.DataFrame(y, columns=['A', 'C', 'G', 'T'])
 	df.index.name = 'pos'
 
 	crp_logo = logomaker.Logo(df, ax=ax)
 	crp_logo.style_spines(visible=False)
 
 	plt.yticks(fontsize=12)
+	plt.ylim(*ylim)
 	plt.savefig(path)
 	plt.close()
 
 
 def marginalization_report(model, motifs, sequences, output_dir):
+	motifs = list(read_meme(motifs).items())[:50]
+
 	if not os.path.isdir(output_dir):
 		os.mkdir(output_dir)
 
 	results = {
 		'name': [],
 		'sequence': [],
-		'predictions (before)': [],
-		'predictions (after)': [],
-		'attributions (before)': [],
-		'attributions (after)': []
+		'predictions': [],
+		'attributions': []
 	}
 
-	for name in motifs.keys():
-		motif = motifs[name][:].seq
+	pred_diff, attr_diff = [], []
 
-		pfname = output_dir + name + ".pred."
-		afname = output_dir + name + ".attr."
+	for i, (name, pwm) in enumerate(motifs):
+		motif = ''.join(numpy.array(['A', 'C', 'G', 'T'])[pwm.argmax(axis=1)])
+		print(i, len(motifs), name, motif)
 
+		pred_before, pred_after, attr_before, attr_after = marginalize(model, 
+			motif, sequences)
 
-		y_before, y_after, attr_before, attr_after = marginalize(model, motif, 
-			sequences)
+		mid = attr_before.shape[-1] // 2
+		w = 15
+		s, e = mid - w, mid + w
 
-		print(sequences.shape, y_before.shape, y_after.shape)
+		pred_diff_ = (pred_after - pred_before).mean(axis=0).T
+		pred_diff.append(pred_diff_)
 
-		_plot_predictions(y_before.mean(axis=0).T, pfname + "before.png")
-		_plot_predictions(y_after.mean(axis=0).T, pfname + "after.png")
+		attr_diff_ = (attr_after - attr_before).mean(axis=0)[:, s:e].T
+		attr_diff.append(attr_diff_)
 
+	pred_diff = torch.stack(pred_diff)
+	attr_diff = torch.stack(attr_diff)
 
-		mid = attr_before.shape[-1] // 2
-		w = 15
-		s, e = mid - w, mid + w
+	pred_ylim = pred_diff.min() * 0.95, pred_diff.max() * 1.05
+	attr_ylim = attr_diff.min() * 0.95, attr_diff.max() * 1.05
+
+	idxs = pred_diff.max(axis=1).values.numpy()[:, 0].argsort()[::-1]
+	for i, idx in enumerate(idxs):
+		name, pwm = motifs[idx]
+
+		pfname = output_dir + name + ".pred.png"
+		afname = output_dir + name + ".attr.png"
+
+		motif = ''.join(numpy.array(['A', 'C', 'G', 'T'])[pwm.argmax(axis=1)])
+
+		_plot_predictions(pred_diff[idx], pred_ylim, pfname)
+		_plot_attributions(attr_diff[idx], attr_ylim, afname)
 
-		_plot_attributions(attr_before.mean(axis=0)[:, s:e].T, afname + 
-			"before.png")
-		_plot_attributions(attr_after.mean(axis=0)[:, s:e].T, afname + 
-			"after.png")
+		motif_ = motif[:25] + ('...' if len(motif) > 25 else '')
 
 		results['name'].append(name)
-		results['sequence'].append(motif)
-		results['predictions (before)'].append(pfname + "before.png")
-		results['predictions (after)'].append(pfname + "after.png")
-		results['attributions (before)'].append(afname + "before.png")
-		results['attributions (after)'].append(afname + "after.png")
+		results['sequence'].append(motif_)
+		results['predictions'].append(pfname)
+		results['attributions'].append(afname)
 
 
 	formatters = {
-		'predictions (before)': path_to_image_html,
-		'predictions (after)': path_to_image_html,
-		'attributions (before)': path_to_image_html,
-		'attributions (after)': path_to_image_html
+		'predictions': path_to_image_html,
+		'attributions': path_to_image_html
 	}
 
 	results_df = pandas.DataFrame(results)
 	results_df.to_html(open('marginalization.html'.format(output_dir), 'w'),
 		escape=False, formatters=formatters, index=False)
```

## Comparing `bpnet_lite-0.3.1.data/scripts/bpnet` & `bpnet_lite-0.3.2.data/scripts/bpnet`

 * *Files 8% similar despite different names*

```diff
@@ -11,93 +11,203 @@
 from bpnetlite import BPNet
 from bpnetlite.io import PeakGenerator
 from bpnetlite.io import extract_loci
 
 from bpnetlite.attributions import calculate_attributions
 from bpnetlite.marginalize import marginalization_report
 
+from bpnetlite.negatives import extract_matching_loci
+
+import pandas
+import pyBigWig
 import json
 
 desc = """BPNet is an neural network primarily composed of dilated residual
 	convolution layers for modeling the associations between biological
 	sequences and biochemical readouts. This tool will take in a fasta
 	file for the sequence, a bed file for signal peak locations, and bigWig
 	files for the signal to predict and the control signal, and train a
 	BPNet model for you."""
 
 # Read in the arguments
 parser = argparse.ArgumentParser(description=desc)
-subparsers = parser.add_subparsers(help="Must be either 'train', 'predict', 'interpret', or 'marginalize'.", required=True, dest='cmd')
+subparsers = parser.add_subparsers(help="Must be either 'negatives', 'fit', 'predict', 'interpret', or 'marginalize'.", required=True, dest='cmd')
+
+negatives_parser = subparsers.add_parser("negatives", help="Sample GC-matched negatives.")
+negatives_parser.add_argument("-i", "--peaks", required=True, help="Peak bed file.")
+negatives_parser.add_argument("-f", "--fasta", help="Genome FASTA file.")
+negatives_parser.add_argument("-b", "--bigwig", required=True, help="GC content bigwig.")
+negatives_parser.add_argument("-o", "--output", required=True, help="Output bed file.")
+negatives_parser.add_argument("-l", "--bin_width", type=float, default=0.02, help="GC bin width to match.")
+negatives_parser.add_argument("-w", "--width", type=int, default=2114, help="Width for calculating GC content.")
+negatives_parser.add_argument("-v", "--verbose", default=True, action='store_true')
 
-train_parser = subparsers.add_parser("train", help="Train a BPNet model.")
+train_parser = subparsers.add_parser("fit", help="Fit a BPNet model.")
 train_parser.add_argument("-p", "--parameters", type=str, required=True,
-	help="A JSON file containing the parameters for training the model.")
+	help="A JSON file containing the parameters for fitting the model.")
 
 predict_parser = subparsers.add_parser("predict", help="Make predictions using a trained BPNet model.")
 predict_parser.add_argument("-p", "--parameters", type=str, required=True,
 	help="A JSON file containing the parameters for making predictions.")
 
 interpret_parser = subparsers.add_parser("interpret", help="Make interpretations using a trained BPNet model.")
 interpret_parser.add_argument("-p", "--parameters", type=str, required=True,
 	help="A JSON file containing the parameters for calculating attributions.")
 
 marginalize_parser = subparsers.add_parser("marginalize", help="Run marginalizations given motifs.")
 marginalize_parser.add_argument("-p", "--parameters", type=str, required=True,
 	help="A JSON file containing the parameters for calculating attributions.")
 
+###
+# Default Parameters
+###
+
+default_fit_parameters = {
+	'n_filters': 64,
+	'n_layers': 8,
+	'n_outputs': 2,
+	'n_control_tracks': 2,
+	'profile_output_bias': True,
+	'count_output_bias': True,
+	'name': None,
+
+	'batch_size': 64,
+	'in_window': 2114,
+	'out_window': 1000,
+	'max_jitter': 128,
+	'reverse_complement': True,
+	'max_epochs': 250,
+	'validation_iter': 100,
+	'lr': 0.001,
+	'alpha': 1,
+	'verbose': False,
+
+	'min_counts': 0,
+	'max_counts': 99999999,
+
+	'training_chroms': ['chr1', 'chr2', 'chr3', 'chr5', 'chr6', 'chr7', 
+		'chr8', 'chr9', 'chr10', 'chr12', 'chr13', 'chr14', 'chr16', 
+		'chr18', 'chr19', 'chr20', 'chr22'],
+	'validation_chroms': ['chr4', 'chr15', 'chr21'],
+	'sequences': None,
+	'loci': None,
+	'signals': None,
+	'controls': None,
+	'random_state': None
+}
+
+default_predict_parameters = {
+	'batch_size': 64,
+	'in_window': 2114,
+	'out_window': 1000,
+	'verbose': False,
+	'chroms': ['chr1', 'chr2', 'chr3', 'chr5', 'chr6', 'chr7', 
+		'chr8', 'chr9', 'chr10', 'chr12', 'chr13', 'chr14', 'chr16', 
+		'chr18', 'chr19', 'chr20', 'chr22'],
+	'sequences': None,
+	'loci': None,
+	'controls': None,
+	'model': None,
+	'profile_filename': 'y_profile.npz',
+	'count_filename': 'y_count.npz'
+}
+
+default_interpret_parameters = {
+	'batch_size': 64,
+	'in_window': 2114,
+	'out_window': 1000,
+	'verbose': False,
+	'chroms': ['chr1', 'chr2', 'chr3', 'chr5', 'chr6', 'chr7', 
+		'chr8', 'chr9', 'chr10', 'chr12', 'chr13', 'chr14', 'chr16', 
+		'chr18', 'chr19', 'chr20', 'chr22'],
+	'sequences': None,
+	'loci': None,
+	'model': None,
+	'output': 'count',
+	'ohe_filename': 'ohe.npz',
+	'shap_filename': 'shap.npz',
+	'random_state':0,
+}
+
+default_marginalize_parameters = {
+	'batch_size': 64,
+	'in_window': 2114,
+	'out_window': 1000,
+	'verbose': False,
+	'chroms': ['chr1', 'chr2', 'chr3', 'chr5', 'chr6', 'chr7', 
+		'chr8', 'chr9', 'chr10', 'chr12', 'chr13', 'chr14', 'chr16', 
+		'chr18', 'chr19', 'chr20', 'chr22'],
+	'sequences': None,
+	'motifs': None,
+	'loci': None,
+	'n_loci': None,
+	'shuffle': False,
+	'model': None,
+	'output_filename':'marginalize/',
+	'random_state':0,
+}
+
+###
+# Commands
+###
+
+def merge_parameters(parameters, default_parameters):
+	"""Merge the provided parameters with the default parameters.
+
+	
+	Parameters
+	----------
+	parameters: str
+		Name of the JSON folder with the provided parameters
+
+	default_parameters: dict
+		The default parameters for the operation.
+
+
+	Returns
+	-------
+	params: dict
+		The merged set of parameters.
+	"""
 
-# Pull the arguments
-args = parser.parse_args()
-
-if args.cmd == "train":
-	with open(args.parameters, "r") as infile:
+	with open(parameters, "r") as infile:
 		parameters = json.load(infile)
 
-	default_parameters = {
-		'n_filters': 64,
-		'n_layers': 8,
-		'n_outputs': 2,
-		'n_control_tracks': 2,
-		'profile_output_bias': True,
-		'count_output_bias': True,
-		'name': None,
-
-		'batch_size': 64,
-		'in_window': 2114,
-		'out_window': 1000,
-		'max_jitter': 128,
-		'reverse_complement': True,
-		'max_epochs': 250,
-		'validation_iter': 100,
-		'lr': 0.001,
-		'alpha': 1,
-		'verbose': False,
-
-		'min_counts': 0,
-		'max_counts': 99999999,
-
-		'training_chroms': ['chr1', 'chr2', 'chr3', 'chr5', 'chr6', 'chr7', 
-			'chr8', 'chr9', 'chr10', 'chr12', 'chr13', 'chr14', 'chr16', 
-			'chr18', 'chr19', 'chr20', 'chr22'],
-		'validation_chroms': ['chr4', 'chr15', 'chr21'],
-		'sequences': None,
-		'loci': None,
-		'signals': None,
-		'controls': None,
-		'random_state': None
-	}
-
 	for parameter, value in default_parameters.items():
 		if parameter not in parameters:
 			if value is None and parameter != "controls":
 				raise ValueError("Must provide value for '{}'".format(parameter))
 
 			parameters[parameter] = value
 
-	###
+	return parameters
+
+
+# Pull the arguments
+args = parser.parse_args()
+
+
+# Calculate GC-matched negatives
+if args.cmd == 'negatives':
+	if args.fasta is not None:
+		chroms = ['chr{}'.format(i) for i in range(1, 23)] + ['chrX']
+		calculate_gc_genomewide(args.fasta, args.bigwig, args.width, chroms, 
+			args.verbose)
+
+	numpy.random.seed(0)
+
+	# Extract regions that match the GC content of the peaks
+	matched_loci = extract_matching_loci(args.peaks, args.bigwig, args.width, 
+		args.bin_width, args.verbose)
+
+	matched_loci.to_csv(args.output, header=False, sep='\t', index=False)
+
+# Fit a BPNet model to data
+if args.cmd == "fit":
+	parameters = merge_parameters(args.parameters, default_fit_parameters)
 
 	training_data = PeakGenerator(
 		loci=parameters['loci'], 
 		sequences=parameters['sequences'],
 		signals=parameters['signals'],
 		controls=parameters['controls'],
 		chroms=parameters['training_chroms'],
@@ -139,48 +249,24 @@
 		profile_output_bias=parameters['profile_output_bias'],
 		count_output_bias=parameters['count_output_bias'],
 		alpha=parameters['alpha'],
 		trimming=trimming,
 		name=parameters['name'],
 		verbose=parameters['verbose']).cuda()
 
-	optimizer = torch.optim.Adam(model.parameters(), lr=parameters['lr'])
+	optimizer = torch.optim.AdamW(model.parameters(), lr=parameters['lr'])
 
 	model.fit(training_data, optimizer, X_valid=valid_sequences, 
 		X_ctl_valid=valid_controls, y_valid=valid_signals, 
 		max_epochs=parameters['max_epochs'], 
 		validation_iter=parameters['validation_iter'], 
 		batch_size=parameters['batch_size'])
 
 elif args.cmd == 'predict':
-	with open(args.parameters, "r") as infile:
-		parameters = json.load(infile)
-
-	default_parameters = {
-		'batch_size': 64,
-		'in_window': 2114,
-		'out_window': 1000,
-		'verbose': False,
-		'chroms': ['chr1', 'chr2', 'chr3', 'chr5', 'chr6', 'chr7', 
-			'chr8', 'chr9', 'chr10', 'chr12', 'chr13', 'chr14', 'chr16', 
-			'chr18', 'chr19', 'chr20', 'chr22'],
-		'sequences': None,
-		'loci': None,
-		'controls': None,
-		'model': None,
-		'profile_filename': 'y_profile.npz',
-		'count_filename': 'y_count.npz'
-	}
-
-	for parameter, value in default_parameters.items():
-		if parameter not in parameters:
-			if value is None and parameter != "controls":
-				raise ValueError("Must provide value for '{}'".format(parameter))
-
-			parameters[parameter] = value
+	parameters = merge_parameters(args.parameters, default_predict_parameters)
 
 	model = torch.load(parameters['model']).cuda()
 
 	examples = extract_loci(
 		sequences=parameters['sequences'],
 		controls=parameters['controls'],
 		loci=parameters['loci'],
@@ -201,40 +287,15 @@
 	y_profiles, y_counts = model.predict(X, X_ctl=X_ctl, 
 		batch_size=parameters['batch_size'])
 
 	numpy.savez_compressed(parameters['profile_filename'], y_profiles)
 	numpy.savez_compressed(parameters['count_filename'], y_counts)
 
 elif args.cmd == 'interpret':
-	with open(args.parameters, "r") as infile:
-		parameters = json.load(infile)
-
-	default_parameters = {
-		'batch_size': 64,
-		'in_window': 2114,
-		'out_window': 1000,
-		'verbose': False,
-		'chroms': ['chr1', 'chr2', 'chr3', 'chr5', 'chr6', 'chr7', 
-			'chr8', 'chr9', 'chr10', 'chr12', 'chr13', 'chr14', 'chr16', 
-			'chr18', 'chr19', 'chr20', 'chr22'],
-		'sequences': None,
-		'loci': None,
-		'model': None,
-		'output': 'count',
-		'ohe_filename': 'ohe.npz',
-		'shap_filename': 'shap.npz',
-		'random_state':0,
-	}
-
-	for parameter, value in default_parameters.items():
-		if parameter not in parameters:
-			if value is None and parameter != "controls":
-				raise ValueError("Must provide value for '{}'".format(parameter))
-
-			parameters[parameter] = value
+	parameters = merge_parameters(args.parameters, default_interpret_parameters)
 
 	model = torch.load(parameters['model']).cuda()
 
 	X = extract_loci(
 		sequences=parameters['sequences'],
 		loci=parameters['loci'],
 		chroms=parameters['chroms'],
@@ -251,57 +312,33 @@
 		model_output=parameters['output'], hypothetical=True, 
 		random_state=parameters['random_state'],
 		verbose=parameters['verbose'])
 
 	numpy.savez_compressed(parameters['ohe_filename'], X)
 	numpy.savez_compressed(parameters['shap_filename'], X_attr)
 
+# Marginalize motifs
 elif args.cmd == 'marginalize':
-	with open(args.parameters, "r") as infile:
-		parameters = json.load(infile)
-
-	default_parameters = {
-		'batch_size': 64,
-		'in_window': 2114,
-		'out_window': 1000,
-		'verbose': False,
-		'chroms': ['chr1', 'chr2', 'chr3', 'chr5', 'chr6', 'chr7', 
-			'chr8', 'chr9', 'chr10', 'chr12', 'chr13', 'chr14', 'chr16', 
-			'chr18', 'chr19', 'chr20', 'chr22'],
-		'sequences': None,
-		'motifs': None,
-		'loci': None,
-		'n_loci': None,
-		'shuffle': False,
-		'model': None,
-		'output_filename':'marginalize/',
-		'random_state':0,
-	}
-
-	for parameter, value in default_parameters.items():
-		if parameter not in parameters:
-			if value is None and parameter != "controls":
-				raise ValueError("Must provide value for '{}'".format(parameter))
-
-			parameters[parameter] = value
+	parameters = merge_parameters(args.parameters, 
+		default_marginalize_parameters)
 
 	model = torch.load(parameters['model']).cuda()
 
 	X = extract_loci(
 		sequences=parameters['sequences'],
 		loci=parameters['loci'],
 		chroms=parameters['chroms'],
 		max_jitter=0,
+		n_loci=parameters['n_loci'],
 		verbose=parameters['verbose']
 	)
 
 	if parameters['shuffle'] == True:
 		idxs = numpy.arange(X.shape[0])
 		numpy.random.shuffle(idxs)
 		X = X[idxs]
 
 	if parameters['n_loci'] is not None:
 		X = X[:parameters['n_loci']]
 
-	motifs = pyfaidx.Fasta(parameters['motifs'])
-	marginalization_report(model, motifs, X, 
+	marginalization_report(model, parameters['motifs'], X, 
 		parameters['output_filename'])
```

## Comparing `bpnet_lite-0.3.1.data/scripts/chrombpnet` & `bpnet_lite-0.3.2.data/scripts/chrombpnet`

 * *Files 6% similar despite different names*

```diff
@@ -24,69 +24,122 @@
 	where one models the bias explicitly and one models the accessibility
 	explicitly. This tool provides functionality for training the combination
 	of the bias model and accessibility model and making predictions using it.
 	After training, the accessibility model can be used using the `bpnet`
 	tool."""
 
 
-
 # Read in the arguments
 parser = argparse.ArgumentParser(description=desc)
-subparsers = parser.add_subparsers(help="Must be either 'bias' or 'train' or 'predict'.", required=True, dest='cmd')
+subparsers = parser.add_subparsers(help="Must be either 'bias' or 'fit' or 'predict'.", required=True, dest='cmd')
 
-train_parser = subparsers.add_parser("train", help="Train a ChromBPNet model.")
-train_parser.add_argument("-p", "--parameters", type=str, required=True,
+fit_parser = subparsers.add_parser("fit", help="Fit a ChromBPNet model.")
+fit_parser.add_argument("-p", "--parameters", type=str, required=True,
 	help="A JSON file containing the parameters for training the model.")
 
 predict_parser = subparsers.add_parser("predict", help="Make predictions using a trained ChromBPNet model.")
 predict_parser.add_argument("-p", "--parameters", type=str, required=True,
 	help="A JSON file containing the parameters for making predictions.")
 
-bias_parser = subparsers.add_parser("bias", help="Train a bias model.")
+bias_parser = subparsers.add_parser("bias", help="Fit a bias model.")
 bias_parser.add_argument("-p", "--parameters", type=str, required=True,
-	help="A JSON file containing the parameters for training the model.")
+	help="A JSON file containing the parameters for fitting the model.")
 
+###
+# Default Parameters
+###
+
+default_fit_parameters = {
+	'n_filters': 64,
+	'n_layers': 8,
+	'batch_size': 64,
+	'in_window': 2114,
+	'out_window': 1000,
+	'max_jitter': 128,
+	'reverse_complement': True,
+	'max_epochs': 250,
+	'validation_iter': 100,
+	'lr': 0.001,
+	'alpha': 1,
+	'verbose': False,
+
+	'min_counts': 0,
+	'max_counts': 99999999,
+	'bias_model': None,
+
+	'training_chroms': ['chr1', 'chr2', 'chr3', 'chr5', 'chr6', 'chr7', 
+		'chr8', 'chr9', 'chr10', 'chr12', 'chr13', 'chr14', 'chr16', 
+		'chr18', 'chr19', 'chr20', 'chr22'],
+	'validation_chroms': ['chr4', 'chr15', 'chr21'],
+	'sequences': None,
+	'loci': None,
+	'signals': None,
+	'random_state': None
+
+}
+
+default_predict_parameters = {
+	'batch_size': 64,
+	'in_window': 2114,
+	'out_window': 1000,
+	'verbose': False,
+	'chroms': ['chr1', 'chr2', 'chr3', 'chr5', 'chr6', 'chr7', 
+		'chr8', 'chr9', 'chr10', 'chr12', 'chr13', 'chr14', 'chr16', 
+		'chr18', 'chr19', 'chr20', 'chr22'],
+	'sequences': None,
+	'loci': None,
+	'model': None,
+	'profile_filename': 'y_profile.npz',
+	'count_filename': 'y_count.npz'
+}
+
+default_bias_parameters = {
+	'n_filters': 256,
+	'n_layers': 4,
+	'batch_size': 64,
+	'in_window': 2114,
+	'out_window': 1000,
+	'max_jitter': 128,
+	'reverse_complement': True,
+	'max_epochs': 250,
+	'validation_iter': 100,
+	'lr': 0.001,
+	'early_stopping': None,
+	'alpha': 1,
+	'beta': 0.5,
+	'verbose': False,
+
+	'min_counts': 0,
+	'max_counts': None,
+
+	'training_chroms': ['chr1', 'chr2', 'chr3', 'chr5', 'chr6', 'chr7', 
+		'chr8', 'chr9', 'chr10', 'chr12', 'chr13', 'chr14', 'chr16', 
+		'chr18', 'chr19', 'chr20', 'chr22'],
+	'validation_chroms': ['chr4', 'chr15', 'chr21'],
+	'sequences': None,
+	'peaks': None,
+	'negatives': None,
+	'signals': None,
+	'random_state': None
+
+}
+
+###
+# Commands
+###
 
 # Pull the arguments
 args = parser.parse_args()
 
-if args.cmd == "train":
+# Fit ChromBPNet model
+if args.cmd == "fit":
 	with open(args.parameters, "r") as infile:
 		parameters = json.load(infile)
 
-	default_parameters = {
-		'n_filters': 64,
-		'n_layers': 8,
-		'batch_size': 64,
-		'in_window': 2114,
-		'out_window': 1000,
-		'max_jitter': 128,
-		'reverse_complement': True,
-		'max_epochs': 250,
-		'validation_iter': 100,
-		'lr': 0.001,
-		'alpha': 1,
-		'verbose': False,
-
-		'min_counts': 0,
-		'max_counts': 99999999,
-		'bias_model': None,
-
-		'training_chroms': ['chr1', 'chr2', 'chr3', 'chr5', 'chr6', 'chr7', 
-			'chr8', 'chr9', 'chr10', 'chr12', 'chr13', 'chr14', 'chr16', 
-			'chr18', 'chr19', 'chr20', 'chr22'],
-		'validation_chroms': ['chr4', 'chr15', 'chr21'],
-		'sequences': None,
-		'loci': None,
-		'signals': None,
-		'random_state': None
-
-	}
-
-	for parameter, value in default_parameters.items():
+	for parameter, value in default_fit_parameters.items():
 		if parameter not in parameters:
 			if value is None:
 				raise ValueError("Must provide value for '{}'".format(parameter))
 
 			parameters[parameter] = value
 
 	###
@@ -130,41 +183,27 @@
 		trimming=trimming).cuda()
 
 	model = ChromBPNet(bias=bias, accessibility=accessibility,
 		name="chrombpnet.{}.{}".format(parameters['n_filters'], 
 			parameters['n_layers']))
 
 
-	optimizer = torch.optim.Adam(model.parameters(), lr=parameters['lr'])
+	optimizer = torch.optim.AdamW(model.parameters(), lr=parameters['lr'])
 
 	model.fit_generator(training_data, optimizer, X_valid=valid_sequences, 
 		y_valid=valid_signals, max_epochs=parameters['max_epochs'], 
 		validation_iter=parameters['validation_iter'], 
 		batch_size=parameters['batch_size'])
 
+# Make predictions from the full ChromBPNet model
 elif args.cmd == 'predict':
 	with open(args.parameters, "r") as infile:
 		parameters = json.load(infile)
 
-	default_parameters = {
-		'batch_size': 64,
-		'in_window': 2114,
-		'out_window': 1000,
-		'verbose': False,
-		'chroms': ['chr1', 'chr2', 'chr3', 'chr5', 'chr6', 'chr7', 
-			'chr8', 'chr9', 'chr10', 'chr12', 'chr13', 'chr14', 'chr16', 
-			'chr18', 'chr19', 'chr20', 'chr22'],
-		'sequences': None,
-		'loci': None,
-		'model': None,
-		'profile_filename': 'y_profile.npz',
-		'count_filename': 'y_count.npz'
-	}
-
-	for parameter, value in default_parameters.items():
+	for parameter, value in default_predict_parameters.items():
 		if parameter not in parameters:
 			if value is None:
 				raise ValueError("Must provide value for '{}'".format(parameter))
 
 			parameters[parameter] = value
 
 	model = torch.load(parameters['model']).cuda()
@@ -178,77 +217,48 @@
 	).cuda()
 
 	y_profiles, y_counts = model.predict(X, batch_size=parameters['batch_size'])
 
 	numpy.savez_compressed(parameters['profile_filename'], y_profiles)
 	numpy.savez_compressed(parameters['count_filename'], y_counts)
 
+# Fit the bias model
 elif args.cmd == 'bias':
 	with open(args.parameters, "r") as infile:
 		parameters = json.load(infile)
 
-	default_parameters = {
-		'n_filters': 256,
-		'n_layers': 4,
-		'batch_size': 64,
-		'in_window': 2114,
-		'out_window': 1000,
-		'max_jitter': 128,
-		'reverse_complement': True,
-		'max_epochs': 250,
-		'validation_iter': 100,
-		'lr': 0.001,
-		'alpha': 1,
-		'beta': 0.5,
-		'verbose': False,
-
-		'min_counts': 0,
-		'max_counts': None,
-
-		'training_chroms': ['chr1', 'chr2', 'chr3', 'chr5', 'chr6', 'chr7', 
-			'chr8', 'chr9', 'chr10', 'chr12', 'chr13', 'chr14', 'chr16', 
-			'chr18', 'chr19', 'chr20', 'chr22'],
-		'validation_chroms': ['chr4', 'chr15', 'chr21'],
-		'sequences': None,
-		'peaks': None,
-		'negatives': None,
-		'signals': None,
-		'random_state': None
-
-	}
-
-	for parameter, value in default_parameters.items():
+	for parameter, value in default_bias_parameters.items():
 		if parameter not in parameters:
-			if value is None:
+			if parameter != 'max_counts' and value is None:
 				raise ValueError("Must provide value for '{}'".format(parameter))
 
 			parameters[parameter] = value
 
 	###
 
 	if parameters['max_counts'] is None:
 		_, train_signals = extract_loci(
 			sequences=parameters['sequences'],
 			signals=parameters['signals'],
 			controls=None,
 			loci=parameters['peaks'],
-			chroms=parameters['validation_chroms'],
+			chroms=parameters['training_chroms'],
 			in_window=parameters['in_window'],
 			out_window=parameters['out_window'],
 			max_jitter=0,
 			verbose=parameters['verbose']
 		)
 
 		parameters['max_counts'] = train_signals.sum(dim=-1).min()
 
 	training_data = PeakGenerator(
 		loci=parameters['negatives'], 
 		sequences=parameters['sequences'],
 		signals=parameters['signals'],
-		chroms=parameters['validation_chroms'],
+		chroms=parameters['training_chroms'],
 		in_window=parameters['in_window'],
 		out_window=parameters['out_window'],
 		max_jitter=parameters['max_jitter'],
 		reverse_complement=parameters['reverse_complement'],
 		min_counts=parameters['min_counts'],
 		max_counts=parameters['max_counts']*parameters['beta'],
 		random_state=parameters['random_state'],
@@ -268,17 +278,19 @@
 		verbose=parameters['verbose']
 	)
 
 	trimming = (parameters['in_window'] - parameters['out_window']) // 2
 
 	model = BPNet(n_filters=parameters['n_filters'], 
 		n_layers=parameters['n_layers'], n_outputs=1, n_control_tracks=0,
-		alpha=parameters['alpha'],
+		alpha=parameters['alpha'], 
+		name='bias.{}.{}'.format(parameters['n_filters'], 
+			parameters['n_layers']),
 		trimming=trimming).cuda()
 
-	optimizer = torch.optim.Adam(model.parameters(), lr=parameters['lr'])
+	optimizer = torch.optim.AdamW(model.parameters(), lr=parameters['lr'])
 
-	model.fit_generator(training_data, optimizer, X_valid=valid_sequences, 
+	model.fit(training_data, optimizer, X_valid=valid_sequences, 
 		y_valid=valid_signals, max_epochs=parameters['max_epochs'], 
-		validation_iter=parameters['validation_iter'], 
+		validation_iter=parameters['validation_iter'],
+		early_stopping=parameters['early_stopping'],
 		batch_size=parameters['batch_size'])
-
```

## Comparing `bpnet_lite-0.3.1.dist-info/LICENSE` & `bpnet_lite-0.3.2.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `bpnet_lite-0.3.1.dist-info/METADATA` & `bpnet_lite-0.3.2.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: bpnet-lite
-Version: 0.3.1
+Version: 0.3.2
 Summary: bpnet-lite is a minimal implementation of BPNet, a neural network aimed at interpreting regulatory activity of the genome.
 Home-page: https://github.com/jmschrei/bpnet-lite
 Author: Jacob Schreiber
 Author-email: jmschreiber91@gmail.com
 License: LICENSE.txt
 License-File: LICENSE
 Requires-Dist: numpy (>=1.14.2)
```

## Comparing `bpnet_lite-0.3.1.dist-info/RECORD` & `bpnet_lite-0.3.2.dist-info/RECORD`

 * *Files 27% similar despite different names*

```diff
@@ -1,16 +1,17 @@
-bpnet_lite-0.3.1.data/scripts/bpnet,sha256=ybdcdcUn85c4APntmHXYr33oQBK0mLJiKuNtYxVUosE,9234
-bpnet_lite-0.3.1.data/scripts/chrombpnet,sha256=-q6JKUd4uPZfPjWRkmB0tKbWDTnvsdHwlR4Z9vP7ohQ,8649
+bpnet_lite-0.3.2.data/scripts/bpnet,sha256=ak2vUhhndj5fGwIanM7_jHPuQgjGCpiiG2JIEzyu3Kw,10342
+bpnet_lite-0.3.2.data/scripts/chrombpnet,sha256=-gGHT6R6zmNhvP4vLjX1_u6mW0SRZzOGPPfpelKcvoU,8915
 bpnetlite/__init__.py,sha256=CBKwUZ5qlYs6lYGRIjw3HqiicER6uONS2TsrdAoQbfw,175
-bpnetlite/attributions.py,sha256=5n1PKmAc_XBPTGILEgas7YyZh87L4ZlLb7emRFSJGHU,10712
-bpnetlite/bpnet.py,sha256=EjHJkuAfPr5WVNVm-W4SmgI21142MbhW0XdLs78z5nQ,15775
-bpnetlite/chrombpnet.py,sha256=aTtNg9hkXdlNPswmQczERSn9HZkEUYw38QBnjzKnrm0,5827
-bpnetlite/io.py,sha256=JCqy5evhTgjJGZ7PlWddBe8ESeonPOk4CaXHZ3bWUvo,17015
+bpnetlite/attributions.py,sha256=IEIESw9M8XFuT2wNydfkfeNSjQfBKotT7YZP4hIs8fo,10686
+bpnetlite/bpnet.py,sha256=mKYHAavrMCkMv1xEKr5EvueNNgKE_AnMx9fzpZzxM9Y,16333
+bpnetlite/chrombpnet.py,sha256=hafRto2GzMFakklq5-ZTNnCcMLBLj28DiFccRHf8MZw,8981
+bpnetlite/io.py,sha256=h22Bjzd3m91BEDom9lSiAH1YnYYJDpYvFSDFfVVvEbI,17417
 bpnetlite/logging.py,sha256=7dT7lGHcMxZgbI6_kqOBPN87WzJMvVrsA0XXLd3ZbAQ,1643
 bpnetlite/losses.py,sha256=2kPpx-_HpmjGdOaHgG9eKVEOQga2wCzkYuxXgBc64OE,2418
-bpnetlite/marginalize.py,sha256=DWv764jJmkQK4NYErIheD3GLh-9i-Yts6fo-7mwSa6k,3674
+bpnetlite/marginalize.py,sha256=rSXsDBUp3SWwdnrIdIla8L3toiaNo2YS13ZvFHEAkIk,4566
+bpnetlite/negatives.py,sha256=T66rIV249lvdfe3OyM5lz208xOhPFvLjh55zHkEgiOk,9144
 bpnetlite/performance.py,sha256=P6hbqcGsZscN8ee_R10TftQCt1moi0kU4s3Pa8LQGM4,13599
-bpnet_lite-0.3.1.dist-info/LICENSE,sha256=7INkXi8uNRhuIecag4RwrinhCQmP-P6pAWoK6UOxi1U,1072
-bpnet_lite-0.3.1.dist-info/METADATA,sha256=ShYIShxebFnuhQmd647ZuhSebJTWcSsj5d8yTn7qu1o,722
-bpnet_lite-0.3.1.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-bpnet_lite-0.3.1.dist-info/top_level.txt,sha256=SKuFVvK8spuR4slxk09vQL-IR3R_x4ahC68BLEU7y3g,10
-bpnet_lite-0.3.1.dist-info/RECORD,,
+bpnet_lite-0.3.2.dist-info/LICENSE,sha256=7INkXi8uNRhuIecag4RwrinhCQmP-P6pAWoK6UOxi1U,1072
+bpnet_lite-0.3.2.dist-info/METADATA,sha256=knVI_1YJWR_TgwfoC1wO6RBJvsdvyZj4R6hYo5qzGK4,722
+bpnet_lite-0.3.2.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+bpnet_lite-0.3.2.dist-info/top_level.txt,sha256=SKuFVvK8spuR4slxk09vQL-IR3R_x4ahC68BLEU7y3g,10
+bpnet_lite-0.3.2.dist-info/RECORD,,
```

