# Comparing `tmp/kptop-0.0.6-py3-none-any.whl.zip` & `tmp/kptop-0.0.7-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,22 +1,22 @@
-Zip file size: 45505 bytes, number of entries: 20
--rw-r--r--  2.0 unx      442 b- defN 23-May-09 23:35 kptop_tool.py
+Zip file size: 47893 bytes, number of entries: 20
+-rw-r--r--  2.0 unx      442 b- defN 23-May-13 21:13 kptop_tool.py
 -rw-r--r--  2.0 unx        0 b- defN 23-May-09 17:17 kubePtop/__init__.py
 -rw-r--r--  2.0 unx     5483 b- defN 23-May-09 17:17 kubePtop/ascii_graph.py
--rw-r--r--  2.0 unx     8249 b- defN 23-May-10 04:30 kubePtop/cli.py
+-rw-r--r--  2.0 unx     8250 b- defN 23-May-17 05:04 kubePtop/cli.py
 -rw-r--r--  2.0 unx      366 b- defN 23-May-09 17:17 kubePtop/colors.py
--rw-r--r--  2.0 unx      531 b- defN 23-May-09 17:17 kubePtop/global_attrs.py
+-rw-r--r--  2.0 unx      730 b- defN 23-May-17 05:13 kubePtop/global_attrs.py
 -rw-r--r--  2.0 unx     3464 b- defN 23-May-09 17:17 kubePtop/helper.py
 -rw-r--r--  2.0 unx     1053 b- defN 23-May-09 17:17 kubePtop/logging.py
--rw-r--r--  2.0 unx    58007 b- defN 23-May-10 04:33 kubePtop/node_metrics.py
+-rw-r--r--  2.0 unx    59470 b- defN 23-May-17 06:03 kubePtop/node_metrics.py
 -rw-r--r--  2.0 unx    59849 b- defN 23-May-09 17:17 kubePtop/node_monitor.py
--rw-r--r--  2.0 unx    53769 b- defN 23-May-09 17:17 kubePtop/pod_metrics.py
--rw-r--r--  2.0 unx    36836 b- defN 23-May-10 04:41 kubePtop/pod_monitor.py
--rw-r--r--  2.0 unx     2267 b- defN 23-May-09 17:17 kubePtop/read_env.py
--rw-r--r--  2.0 unx    16760 b- defN 23-May-09 17:17 kubePtop/session.py
--rw-r--r--  2.0 unx    35149 b- defN 23-May-10 04:43 kptop-0.0.6.dist-info/LICENSE
--rw-r--r--  2.0 unx      599 b- defN 23-May-10 04:43 kptop-0.0.6.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-May-10 04:43 kptop-0.0.6.dist-info/WHEEL
--rw-r--r--  2.0 unx       42 b- defN 23-May-10 04:43 kptop-0.0.6.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       20 b- defN 23-May-10 04:43 kptop-0.0.6.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     1549 b- defN 23-May-10 04:43 kptop-0.0.6.dist-info/RECORD
-20 files, 284527 bytes uncompressed, 43023 bytes compressed:  84.9%
+-rw-r--r--  2.0 unx    53769 b- defN 23-May-16 21:40 kubePtop/pod_metrics.py
+-rw-r--r--  2.0 unx    36836 b- defN 23-May-13 21:13 kubePtop/pod_monitor.py
+-rw-r--r--  2.0 unx     4694 b- defN 23-May-17 05:45 kubePtop/read_env.py
+-rw-r--r--  2.0 unx    27842 b- defN 23-May-17 05:04 kubePtop/session.py
+-rw-r--r--  2.0 unx    35149 b- defN 23-May-17 06:15 kptop-0.0.7.dist-info/LICENSE
+-rw-r--r--  2.0 unx      599 b- defN 23-May-17 06:15 kptop-0.0.7.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-17 06:15 kptop-0.0.7.dist-info/WHEEL
+-rw-r--r--  2.0 unx       42 b- defN 23-May-17 06:15 kptop-0.0.7.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       20 b- defN 23-May-17 06:15 kptop-0.0.7.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     1549 b- defN 23-May-17 06:15 kptop-0.0.7.dist-info/RECORD
+20 files, 299699 bytes uncompressed, 45411 bytes compressed:  84.8%
```

## zipnote {}

```diff
@@ -36,26 +36,26 @@
 
 Filename: kubePtop/read_env.py
 Comment: 
 
 Filename: kubePtop/session.py
 Comment: 
 
-Filename: kptop-0.0.6.dist-info/LICENSE
+Filename: kptop-0.0.7.dist-info/LICENSE
 Comment: 
 
-Filename: kptop-0.0.6.dist-info/METADATA
+Filename: kptop-0.0.7.dist-info/METADATA
 Comment: 
 
-Filename: kptop-0.0.6.dist-info/WHEEL
+Filename: kptop-0.0.7.dist-info/WHEEL
 Comment: 
 
-Filename: kptop-0.0.6.dist-info/entry_points.txt
+Filename: kptop-0.0.7.dist-info/entry_points.txt
 Comment: 
 
-Filename: kptop-0.0.6.dist-info/top_level.txt
+Filename: kptop-0.0.7.dist-info/top_level.txt
 Comment: 
 
-Filename: kptop-0.0.6.dist-info/RECORD
+Filename: kptop-0.0.7.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## kubePtop/cli.py

```diff
@@ -1,8 +1,7 @@
-from kubePtop.global_attrs import GlobalAttrs
 from kubePtop.read_env import ReadEnv
 # Read environment variables
 read_environment_variables = ReadEnv()
 read_environment_variables.read_env()
 import argparse
 from kubePtop.session import PrometheusAPI
 from kubePtop.node_monitor import Node_Monitoring
@@ -13,14 +12,16 @@
 
 node_monitor = Node_Monitoring()
 pod_monitor = Pod_Monitoring()
 pod_metrics = PrometheusPodsMetrics()
 node_metrics = PrometheusNodeMetrics()
 prometheus_api = PrometheusAPI()
 from kubePtop.logging import Logging
+from kubePtop.global_attrs import GlobalAttrs
+
 
 
 class Cli():
     def __init__(self):
         self.parser = None
         # CLI Input attributes
         # self.verify_prometheus = False
```

## kubePtop/global_attrs.py

```diff
@@ -1,9 +1,17 @@
 
 class GlobalAttrs:
+    
+    env_connection_method = None
+    
+    env_prometheus_pod_name = None
+    env_prometheus_pod_port = "9090"
+    env_prometheus_pod_namespace = "default"    
+    env_kube_config_file = ""
+    
     env_prometheus_server = "??"
     env_basic_auth_enabled = False
     env_prometheus_username = None
     env_prometheus_password = None
     env_insecure = False
     
     log_dir = "/tmp/"
```

## kubePtop/node_metrics.py

```diff
@@ -1285,15 +1285,15 @@
     #         output['fail_reason'] = e
     #         Logging.log.error(e)
     #         Logging.log.exception(traceback.format_stack())
 
     #     return output
 
 
-    def topNode(self, node=".*"):
+    def topNode(self, node=".*", option=""):
         """
         """
         output = {
             "success": False,
             "fail_reason": "",
             "result": {}
         }
@@ -1304,33 +1304,46 @@
                 output['fail_reason'] = f"could not get metric's value: {memory_total_query}"
                 return output
             if not memory_total.get('data').get('result'):
                 output['fail_reason'] =  f"Query did not return any data: {memory_total_query}"
                 return output
 
             nodes_dct = {}
+            
             for node_ in memory_total.get('data').get('result'):
-                nodes_dct[node_.get('metric').get(GlobalAttrs.node_exporter_node_label)] = {
-                    "memory_total": int(node_.get('value')[1]),
-                    "memory_free": -1,
-                    "memory_used": -1,
-                    "cpu_cores": -1,
-                    # "cpu_used": -1, # not sure of the metrics to get the used cpu in milicores.
-                    "cpu_used_percentage": -1,
-                    "running_pods_num": -1,
-                    "cluster": "",
-                    "node_os": "",
-                    "node_arch": "",
-                    "region": "",
-                    "az": "",
-                    "instance_type": "",
-                    "cluster_env": "Unknown",
-                    "node_group_capacity_type": "",
-                    "node_group_name": "",
-                }
+                
+                if (option == 'cloud') or (option == 'json'):
+                    nodes_dct[node_.get('metric').get(GlobalAttrs.node_exporter_node_label)] = {
+                        "memory_total": int(node_.get('value')[1]),
+                        "memory_free": -1,
+                        "memory_used": -1,
+                        "cpu_cores": -1,
+                        # "cpu_used": -1, # not sure of the metrics to get the used cpu in milicores.
+                        "cpu_used_percentage": -1,
+                        "running_pods_num": -1,
+                        "cluster": "?",
+                        "node_os": "?",
+                        "node_arch": "?",
+                        "region": "?",
+                        "az": "?",
+                        "instance_type": "?",
+                        "cluster_env": "Unknown",
+                        "node_group_capacity_type": "?",
+                        "node_group_name": "?",
+                    }
+                else:
+                    nodes_dct[node_.get('metric').get(GlobalAttrs.node_exporter_node_label)] = {
+                        "memory_total": int(node_.get('value')[1]),
+                        "memory_free": -1,
+                        "memory_used": -1,
+                        "cpu_cores": -1,
+                        # "cpu_used": -1, # not sure of the metrics to get the used cpu in milicores.
+                        "cpu_used_percentage": -1,
+                        "running_pods_num": -1,
+                    }
 
             memory_free_query = f'node_memory_MemFree_bytes{{{GlobalAttrs.node_exporter_node_label}=~"{node}"}}'
             memory_free = self.run_query(memory_free_query)
             if not memory_free.get('status') == 'success':
                 output['fail_reason'] = f"could not get metric's value: {memory_free_query}"
                 return output
             if not memory_free.get('data').get('result'):
@@ -1362,20 +1375,20 @@
                 output['fail_reason'] = f"could not get metric's value: {running_pods_count_query}"
                 return output
             if not running_pods_count.get('data').get('result'):
                 output['fail_reason'] =  f"Query did not return any data: {running_pods_count_query}"
                 return output
                 
             ## 
-            node_managed_k8s_info = self.nodeManagedK8sInfo(node=node)
-            if not node_managed_k8s_info.get('success'):
-                output['fail_reason'] = node_managed_k8s_info.get('fail_reason')
-                return output
+            if (option == 'cloud') or (option == 'json'):
+                node_managed_k8s_info = self.nodeManagedK8sInfo(node=node)
+                if not node_managed_k8s_info.get('success'):
+                    output['fail_reason'] = node_managed_k8s_info.get('fail_reason')
+                    return output
         
-            
             for node in memory_free.get('data').get('result'):
                 nodes_dct[node.get('metric').get(GlobalAttrs.node_exporter_node_label)]['memory_free'] = int(node.get('value')[1])
                 nodes_dct[node.get('metric').get(GlobalAttrs.node_exporter_node_label)]['memory_used'] = nodes_dct[node.get('metric').get(GlobalAttrs.node_exporter_node_label)]['memory_total'] - int(node.get('value')[1])
 
             for node in cpu_cores.get('data').get('result'):
                 try:
                     nodes_dct[node.get('metric').get('instance')]['cpu_cores'] = int(node.get('value')[1])
@@ -1387,92 +1400,99 @@
 
             for node in running_pods_count.get('data').get('result'):
                 try:
                     nodes_dct[node.get('metric').get('instance')]['running_pods_num'] = int(node.get('value')[1])
                 except KeyError:
                     pass # A KeyError Exception is expected as this metric returns the value for the master nodes while other metrics dont.
                     
+            # rich.print(node_managed_k8s_info)
+            if (option == 'cloud') or (option == 'json'):
+                for node in node_managed_k8s_info.get('result'):
+                    # General Labels (match different cloud providers)
+                    # rich.print(node_managed_k8s_info.get('result'))
+                    try:
+                        nodes_dct[node.get('metric').get('instance')]['node_arch'] = node['metric']['beta_kubernetes_io_arch']
+                        nodes_dct[node.get('metric').get('instance')]['node_os'] = node['metric']['beta_kubernetes_io_os']
+                        nodes_dct[node.get('metric').get('instance')]['region'] = node['metric']['topology_kubernetes_io_region']
+                        nodes_dct[node.get('metric').get('instance')]['az'] = node['metric']['topology_kubernetes_io_zone']
+                        nodes_dct[node.get('metric').get('instance')]['instance_type'] = node['metric']['node_kubernetes_io_instance_type'] 
+                        nodes_dct[node.get('metric').get('instance')]['node_group_name'] = node['metric']['eks_amazonaws_com_nodegroup']                    
+                                          
+                    except KeyError:
+                        pass # If labels are not found, means that most probably this is a Local cluster
+
+                    try:
+                        nodes_dct[node.get('metric').get('instance')]['cluster'] = node['metric']['cluster']
+                    except:
+                        pass # If labels are not found, means that most probably this is a Local cluster
+                    
+                    # AWS Labels
+                    try:
+                        nodes_dct[node.get('metric').get('instance')]['node_group_capacity_type'] = node['metric']['eks_amazonaws_com_capacityType']
+                        nodes_dct[node.get('metric').get('instance')]['node_group_name'] = node['metric']['eks_amazonaws_com_nodegroup']
+                        if nodes_dct[node.get('metric').get('instance')]['node_group_name']:
+                            nodes_dct[node.get('metric').get('instance')]['cluster_env'] = 'EKS'
+                    except KeyError:
+                        pass # If labels are not found, means that it's not an EKS cluster.
             
-            for node in node_managed_k8s_info.get('result'):
-                # General Labels (match different cloud providers)
-                try:
-                    nodes_dct[node.get('metric').get('instance')]['node_arch'] = node['metric']['beta_kubernetes_io_arch']
-                    nodes_dct[node.get('metric').get('instance')]['node_os'] = node['metric']['beta_kubernetes_io_os']
-                    nodes_dct[node.get('metric').get('instance')]['cluster'] = node['metric']['cluster']
-                    nodes_dct[node.get('metric').get('instance')]['region'] = node['metric']['topology_kubernetes_io_region']
-                    nodes_dct[node.get('metric').get('instance')]['az'] = node['metric']['topology_kubernetes_io_zone']
-                    nodes_dct[node.get('metric').get('instance')]['instance_type'] = node['metric']['node_kubernetes_io_instance_type']
-                except KeyError:
-                    pass # If labels are not found, means that most probably this is a Local cluster
-                
-                # AWS Labels
-                try:
-                    nodes_dct[node.get('metric').get('instance')]['node_group_capacity_type'] = node['metric']['eks_amazonaws_com_capacityType']
-                    nodes_dct[node.get('metric').get('instance')]['node_group_name'] = node['metric']['eks_amazonaws_com_nodegroup']
-                    if nodes_dct[node.get('metric').get('instance')]['node_group_name']:
-                        nodes_dct[node.get('metric').get('instance')]['cluster_env'] = 'EKS'
-                except KeyError:
-                    pass # If labels are not found, means that it's not an EKS cluster.
-            
-
             output['result'] = nodes_dct
             output['success'] = True
 
         except(KeyError, AttributeError) as e:
             output['success']: False
             output['fail_reason'] = e
             Logging.log.error(e)
             Logging.log.exception(traceback.format_stack())
 
         return output
     
     def topNodeJson(self, node=".*", color=False):
-        nodes_dct = self.topNode(node=node)
+        nodes_dct = self.topNode(node=node, option='json')
         if not nodes_dct.get('success'):
             print(f"ERROR -- Failed to get nodes \n{nodes_dct.get('fail_reason')}")
             exit(1)
             
         if color:
             rich.print_json(data=nodes_dct.get('result'))
         else:
             print(json.dumps(nodes_dct.get('result'), indent=4))
 
 
     def topNodeTable(self, option=""):
         """
         """
-        nodes_json = self.topNode()
+        nodes_json = self.topNode(option=option)
         # import rich
         # rich.print(nodes_json)
         if not nodes_json.get('success'):
             print(f"No nodes found \n{bcolors.WARNING + str(nodes_json.get('fail_reason')) + bcolors.ENDC}")
             exit(1)
 
 
         table = [['NODE', 'MEM TOTAL', 'MEM USAGE', 'MEM FREE', 'CPU CORES', 'CPU USAGE%', 'RUNNING PODS' ]]
         if option == 'cloud':
-            table = [['NODE', 'MEM TOTAL', 'MEM USAGE', 'MEM FREE', 'CPU CORES', 'CPU USAGE%', 'RUNNING PODS', 'CLUSTER', 'INSTANCE TYPE', 'AZ', 'ENV', 'NG CAPACITY TYPE']]
+            table = [['NODE', 'MEM TOTAL', 'MEM USAGE', 'MEM FREE', 'CPU CORES', 'CPU USAGE%', 'RUNNING PODS', 'CLUSTER', 'INSTANCE TYPE', 'AZ', 'ENV', 'NG CAPACITY TYPE', 'NG']]
             
         if option == 'cloud':
-            for  node, value in nodes_json.get('result').items():
+            for node, value in nodes_json.get('result').items():
                 row = [
                         node,
                         helper_.bytes_to_kb_mb_gb(value.get('memory_total')),
                         helper_.bytes_to_kb_mb_gb(value.get('memory_used')),
                         helper_.bytes_to_kb_mb_gb(value.get('memory_free')),
                         value.get('cpu_cores'),
                         str(round(value.get('cpu_used_percentage'))) + "%", 
                         value.get('running_pods_num'),
                         value.get('cluster'),
                         value.get('instance_type'),
                         # value.get('region'),
                         value.get('az'),
                         value.get('cluster_env'),
                         value.get('node_group_capacity_type'),
-                        # value.get('node_group_name'),
+                        value.get('node_group_name'),
                     ]
                 table.append(row)
         else:
             for  node, value in nodes_json.get('result').items():
                 row = [
                         node,
                         helper_.bytes_to_kb_mb_gb(value.get('memory_total')),
@@ -1497,15 +1517,15 @@
         """
         output = {
             "success": False,
             "fail_reason": "",
             "result": {}
         }
         try:
-            query = f'kubelet_node_name{{kubernetes_io_hostname=~"{node}"}}'
+            query = f'kubelet_node_name{{kubernetes_io_hostname=~"{node}"}}' # 'machine_cpu_cores' also has the needed labels
             result = self.run_query(query)
             if not result.get('status') == 'success':
                 output['fail_reason'] =  f"could not get metric's value: \n{query}"
                 return output
 
             if not result.get('data').get('result'):
                 output['fail_reason'] = f"Query did not return any data: \n{query}"
```

## kubePtop/read_env.py

```diff
@@ -1,50 +1,107 @@
 import os
 from kubePtop.global_attrs import GlobalAttrs
-gattrs = GlobalAttrs()
 
 class ReadEnv:
     def __init__(self):
         pass
+    
+    def check_env(self, envs):
+        """Checks if the ENV is defined
+
+        Args:
+            env (lst): takes a list of ENVs
+        Return: dct
+        """
+        output = {
+            "missing": False,
+            "missing_envs": []
+        }
+        for env in envs:
+            try:
+                os.environ[f'{env}']
+            except KeyError as e:
+                output['missing'] = True
+                output['missing_envs'].append(env)
+        return output
+        
 
     def read_env(self):
         """
         Read Environment variables
         """
-
         # Mandatory ENVs
-        try:
-            GlobalAttrs.env_prometheus_server  = os.environ['KPTOP_PROMETHEUS_SERVER']
-        except (KeyError) as e:
-            raise SystemExit(f"\nERROR -- ENV not found => {e}")
+        # try:
+        #     GlobalAttrs.env_prometheus_server  = os.environ['KPTOP_PROMETHEUS_SERVER']
+        # except (KeyError) as e:
+        #     raise SystemExit(f"\nERROR -- ENV not found => {e}")
 
         # Basic Auth ENVs
+        
+        # Default to "pod_portForward" if the ENV is not set.
+        check_conn_method = self.check_env(['KPTOP_CONNECTION_METHOD'])
+        if check_conn_method['missing']:
+            print(f"INFO -- ENV: {check_conn_method.get('missing_envs')} is missing\n")
+            print('github link')            
+            exit(1)
         try:
-            if os.environ['KPTOP_BASIC_AUTH_ENABLED']:
-                GlobalAttrs.env_basic_auth_enabled   = os.environ['KPTOP_BASIC_AUTH_ENABLED']
-                GlobalAttrs.env_prometheus_username  = os.environ['KPTOP_PROMETHEUS_USERNAME']
-                GlobalAttrs.env_prometheus_password  = os.environ['KPTOP_PROMETHEUS_PASSWORD']
-
-            if GlobalAttrs.env_basic_auth_enabled:
-                if (GlobalAttrs.env_prometheus_username is None or GlobalAttrs.env_prometheus_password is None):
-                    raise SystemExit("INFO -- ENV: KPTOP_PROMETHEUS_USERNAME or KPTOP_PROMETHEUS_PASSWORD is missing")
-
+            os.environ['KPTOP_CONNECTION_METHOD']
+        except KeyError:
+                os.environ['KPTOP_CONNECTION_METHOD'] = "pod_portForward"
+        
+        try:    
+            if os.environ['KPTOP_CONNECTION_METHOD'] == "pod_portForward":
+                GlobalAttrs.env_connection_method = os.environ['KPTOP_CONNECTION_METHOD']
+                
+                check = self.check_env(['KPTOP_PROMETHEUS_POD_NAME', 'KPTOP_PROMETHEUS_POD_PORT', 'KPTOP_PROMETHEUS_POD_NAMESPACE'])
+                if check['missing']:
+                    print(f"INFO -- ENVs: {check.get('missing_envs')} are missing")
+                    exit(1)
+                    
+                GlobalAttrs.env_prometheus_pod_name = os.environ['KPTOP_PROMETHEUS_POD_NAME']
+                GlobalAttrs.env_prometheus_pod_port = os.environ['KPTOP_PROMETHEUS_POD_PORT']
+                GlobalAttrs.env_prometheus_pod_namespace = os.environ['KPTOP_PROMETHEUS_POD_NAMESPACE']
+                
+
+            if os.environ['KPTOP_CONNECTION_METHOD'] == "prometheus_endpoint":
+                GlobalAttrs.env_connection_method = os.environ['KPTOP_CONNECTION_METHOD']
+                
+                check = self.check_env(['KPTOP_PROMETHEUS_SERVER'])
+                if check['missing']:
+                    print(f"INFO -- ENVs: {check.get('missing_envs')} are missing")
+                    exit(1)
+                GlobalAttrs.env_prometheus_server  = os.environ['KPTOP_PROMETHEUS_SERVER']
+                
+                if os.environ['KPTOP_BASIC_AUTH_ENABLED']:
+                    check = self.check_env(['KPTOP_PROMETHEUS_USERNAME', 'KPTOP_PROMETHEUS_PASSWORD'])
+                    if check['missing']:
+                        print(f"INFO -- ENVs: {check.get('missing_envs')} are missing")
+                        exit(1)
+                    GlobalAttrs.env_basic_auth_enabled   = os.environ['KPTOP_BASIC_AUTH_ENABLED']
+                    GlobalAttrs.env_prometheus_username  = os.environ['KPTOP_PROMETHEUS_USERNAME']
+                    GlobalAttrs.env_prometheus_password  = os.environ['KPTOP_PROMETHEUS_PASSWORD']
 
             if GlobalAttrs.env_basic_auth_enabled not in [True, False, 'true', 'false']:
                 print("INFO -- KPTOP_BASIC_AUTH_ENABLED > allowed options are: 'true' || 'false'")
                 exit(1)
 
             if GlobalAttrs.env_insecure not in [True, False, 'true', 'false']:
                 print("INFO -- KPTOP_INSECURE > allowed options are: 'true' || 'false'")
                 exit(1)
         except (KeyError) as e:
             SystemExit(f"\nERROR -- ENV not found => {e}")
 
     
         # Optional ENVs
+        
+        try:
+            GlobalAttrs.env_kube_config_file  = os.environ['KUBECONFIG']
+        except:
+            pass
+        
         try:
             GlobalAttrs.node_exporter_node_label  = os.environ['KPTOP_NODE_EXPORTER_NODE_LABEL']
         except:
             pass
 
         try:
             GlobalAttrs.env_insecure  = os.environ['KPTOP_INSECURE']
```

## kubePtop/session.py

```diff
@@ -9,21 +9,189 @@
 from kubePtop.logging import Logging
 logging = Logging()
 # Ignore Warning
 requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)
 # https://stackoverflow.com/a/41041028
 requests.packages.urllib3.util.ssl_.DEFAULT_CIPHERS += ':HIGH:!DH:!aNULL'
 
+import socket
+import six.moves.urllib.request as urllib_request
+import urllib.parse
+from kubernetes import config
+from kubernetes.client import Configuration
+from kubernetes.client.api import core_v1_api
+from kubernetes.client.rest import ApiException
+from kubernetes.stream import portforward
+import traceback
+
+class KubernetesPodPortForward:
+    def __init__(self, api_object, pod_name, pod_port, namespace) :
+        self.k8s_port_forward_socket = None    
+        self.core_v1 = api_object
+    
+        self.prometheus_pod_k8s_internal_endpoint = None
+        
+        self.namespace = namespace
+        self.pod_name = pod_name
+        self.pod_port = pod_port
+        
+    def createConnection(self, address, *args, **kwargs):
+        pf = portforward(self.core_v1.connect_get_namespaced_pod_portforward,
+                        self.pod_name, self.namespace, ports=str(self.pod_port))
+        return pf.socket(int(self.pod_port))
+    
+    def runSocket(self):
+        self.k8s_port_forward_socket = socket.create_connection = self.createConnection
+        return self.k8s_port_forward_socket
+    
+    def sendRequest(self, path='/-/healthy'):
+        try:            
+            if self.k8s_port_forward_socket is None:
+                socket_ = self.runSocket()
+                self.k8s_port_forward_socket = socket_
+                rich.print(f"[grey69]INFO [Beta-Feature] -- Port-forward socket created for pod: '{self.pod_name}' namespace: '{self.namespace}'")
+                logging.log.info(f"INFO [Beta-Feature] -- Port-forward socket created for pod: '{self.pod_name}' namespace: '{self.namespace}'")
+                # print(self.k8s_port_forward_socket)
+            
+            url = f'http://{self.pod_name}.pod.{self.namespace}.kubernetes:{self.pod_port}'
+        
+            request = urllib_request.urlopen(
+            url + path)
+                        
+            class Response:
+                    exit_code = request.code
+                    reason = request.reason
+                    text = request.read().decode('utf-8')
+            
+            res = Response()
+            return res
+        except ApiException as e:
+            print(f"Erorr -- can't port-forward pod connection")
+            print(e)
+            exit(1)
+        except KeyboardInterrupt as e:
+            print(f"\nOk.")
+            exit(1)
+        except Exception as e:
+            print(f"Error -- {e}")
+            traceback.print_exc()
+            # print(e)
+            exit(1)
+        # request.close()
+        # print('Status Code: %s' % request.code)
+        # print('Reason: %s' % request.reason)
+        # print(text)
+        
+    def runQuery(self, query, path='/api/v1/query?'):
+        try:            
+            if self.k8s_port_forward_socket is None:
+                socket_ = self.runSocket()
+                self.k8s_port_forward_socket = socket_
+                # print(self.k8s_port_forward_socket)
+                rich.print(f"[grey69]INFO [Beta-Feature] -- Port-forward socket created for pod: '{self.pod_name}' namespace: '{self.namespace}'")
+                logging.log.info(f"INFO [Beta-Feature] -- Port-forward socket created for pod: '{self.pod_name}' namespace: '{self.namespace}'")
+                
+                # print(self.k8s_port_forward_socket)
+            
+            url = f'http://{self.pod_name}.pod.{self.namespace}.kubernetes:{self.pod_port}'
+            params = urllib.parse.urlencode({'query': f'{query}'})
+            
+            # print(url + path + "%s" % params)
+            # http://prometheus-server-0.pod.monitoring.kubernetes:9090/api/v1/query?query=node_cpu_seconds_total
+                        
+            request = urllib_request.urlopen(
+            url + path + "%s" % params)
+            text = request.read().decode('utf-8')
+
+            if request.code == 200:
+                return json.loads(text)
+            else:
+                return {}
+        except ApiException as e:
+            print(f"Erorr -- can't port-forward pod connection")
+            print(e)
+            exit(1)
+        except KeyboardInterrupt as e:
+            print(f"\nOk.")
+            exit(1)
+        except Exception as e:
+            print(f"Error -- {e}")
+            traceback.print_exc()
+            # print(e)
+            exit(1)
+        # request.close()
+        # print('Status Code: %s' % request.code)
+        # print('Reason: %s' % request.reason)
+        # print(text)
+
+
 class PrometheusAPI:
 
     def __init__(self):
         self.verify = False
         self.session = None
         self.prometheus_url = GlobalAttrs.env_prometheus_server
         self.prometheus_url_query = self.prometheus_url + "/api/v1/query"
+        
+        self.core_v1 = None
+        
+        # Pod-PortForward object
+        self.pf = None
+        # if GlobalAttrs.env_connection_method == "pod_portForward":
+        #     self.K8s_authenticate()
+                
+
+    def K8s_authenticate(self):
+        pod_name = GlobalAttrs.env_prometheus_pod_name
+        pod_port = GlobalAttrs.env_prometheus_pod_port
+        pod_namespace = GlobalAttrs.env_prometheus_pod_namespace
+        
+        if GlobalAttrs.env_kube_config_file:
+            config.load_kube_config(
+                config_file=GlobalAttrs.env_kube_config_file
+            )
+        else:
+            config.load_kube_config()
+        # c = Configuration.get_default_copy()
+        # c.assert_hostname = False
+        # Configuration.set_default(c)
+        self.core_v1 = core_v1_api.CoreV1Api()
+        
+        self.pf = KubernetesPodPortForward(
+                    api_object=self.core_v1,
+                    pod_name=pod_name,
+                    pod_port=pod_port,
+                    namespace=pod_namespace)
+        
+        rich.print("[grey69]INFO [Beta-Feature] -- Authenticating K8s KubeConfig")
+        Logging.log.info(f"INFO [Beta-Feature] -- Authenticating K8s KubeConfig")
+        # Checking if the Prometheus pod exists
+        pod_check = self.K8s_APIs_podExists(pod_name, pod_namespace)
+        if not pod_check.get('found'):
+            print(f"ERROR -- Prometheus Pod '{pod_name}' does NOT exist in the '{pod_namespace}' namespace ")
+            Logging.log.error(f"ERROR -- Prometheus Pod '{pod_name}' does NOT exist in the '{pod_namespace}' namespace \n{pod_check.get('fail_reason')}")
+            rich.print(f"[light_yellow3]{pod_check.get('fail_reason')}")
+            exit(1)
+    
+    def K8s_APIs_podExists(self, pod_name, namespace):
+        """Checks if a pod exists
+        returns: (bool)
+        """
+        output = {
+            "found": False,
+            "fail_reason": ""
+        }
+        try:
+            self.core_v1.read_namespaced_pod(name=pod_name,
+                                            namespace=namespace)
+            output['found'] = True
+        except Exception as e:
+            output['fail_reason'] = e
+            # traceback.print_exc()
+        return output
 
     def get_session(self):
         try:
             session = requests.Session()
             Logging.log.info("Establishing a new connection with Prometheus")
             self.session = session
             session.verify = self.verify
@@ -65,46 +233,101 @@
     def verify_prometheus_connection(self):
         out = {
             "connected": False,
             "status_code": "?",
             "reason": "",
             "fail_reason": ""
         }
-        session = requests.Session()
-        session.verify = self.verify
-        try:
-            if GlobalAttrs.debug:
-                print("DEBUG -- Checking Prometheus existing connection")
-            Logging.log.info("Checking Prometheus existing connection")
-            prometheus_url = self.prometheus_url + "/-/healthy"
-            if GlobalAttrs.debug:
-                print(f"DEBUG -- Connecting to Prometheus: {prometheus_url}")
-            if GlobalAttrs.env_basic_auth_enabled:
-                req = session.get(prometheus_url, auth=(GlobalAttrs.env_prometheus_username, GlobalAttrs.env_prometheus_password))
-            else:
-                req = session.get(prometheus_url)
-            if req.status_code == 200:
-                Logging.log.info(f"connected successfully, status_code: {req.status_code}")
+        
+        if GlobalAttrs.env_connection_method == 'pod_portForward':
+            try:
                 if GlobalAttrs.debug:
-                    print(f"DEBUG -- connected successfully, status_code: {req.status_code}")
-                out["connected"] = True
-                out["status_code"] = req.status_code
-            else:
-                out["status_code"] = req.status_code
-                out["reason"] = req.reason
-                out["fail_reason"] = f"Failed to connect to Prometheus. Reason: {req.reason}"
-                Logging.log.error(f"Failed to connect to Prometheus. Reason: {req.reason}")
-        except Exception as e:
-            out["fail_reason"] = f"Failed to connect to Prometheus; {e}"
-            out["reason"] = "unable to connnect"
-            Logging.log.info(f"Failed to connect to Prometheus; {e}")
+                    print("DEBUG -- Checking Prometheus existing connection")
+                Logging.log.info("Checking Prometheus existing connection")
+                path = "/-/healthy"
+                prometheus_url = self.prometheus_url + path
+                if GlobalAttrs.debug:
+                    print(f"DEBUG -- Connecting to Prometheus: {prometheus_url}")
 
-        return out
+                req = self.get_request_raw_portForward(path=path)
+                if req.exit_code == 200:
+                    Logging.log.info(f"connected successfully, status_code: {req.exit_code}")
+                    if GlobalAttrs.debug:
+                        print(f"DEBUG -- connected successfully, status_code: {req.exit_code}")
+                    out["connected"] = True
+                    out["status_code"] = req.exit_code
+                    out["reason"] = req.reason
+                else:
+                    out["status_code"] = req.exit_code
+                    out["reason"] = req.reason
+                    out["fail_reason"] = f"Failed to connect to Prometheus. Reason: {req.reason}"
+                    Logging.log.error(f"Failed to connect to Prometheus. Reason: {req.reason}")
+            except Exception as e:
+                out["fail_reason"] = f"Failed to connect to Prometheus; {e}"
+                out["reason"] = "unable to connnect"
+                Logging.log.info(f"Failed to connect to Prometheus; {e}")
 
-    def run_query(self, query):
+            return out
+            
+        elif GlobalAttrs.env_connection_method == 'prometheus_endpoint':
+            session = requests.Session()
+            session.verify = self.verify
+            try:
+                if GlobalAttrs.debug:
+                    print("DEBUG -- Checking Prometheus existing connection")
+                Logging.log.info("Checking Prometheus existing connection")
+                prometheus_url = self.prometheus_url + "/-/healthy"
+                if GlobalAttrs.debug:
+                    print(f"DEBUG -- Connecting to Prometheus: {prometheus_url}")
+                if GlobalAttrs.env_basic_auth_enabled:
+                    req = session.get(prometheus_url, auth=(GlobalAttrs.env_prometheus_username, GlobalAttrs.env_prometheus_password))
+                else:
+                    req = session.get(prometheus_url)
+                if req.status_code == 200:
+                    Logging.log.info(f"connected successfully, status_code: {req.status_code}")
+                    if GlobalAttrs.debug:
+                        print(f"DEBUG -- connected successfully, status_code: {req.status_code}")
+                    out["connected"] = True
+                    out["status_code"] = req.status_code
+                    out["reason"] = req.reason
+                else:
+                    out["status_code"] = req.status_code
+                    out["reason"] = req.reason
+                    out["fail_reason"] = f"Failed to connect to Prometheus. Reason: {req.reason}"
+                    Logging.log.error(f"Failed to connect to Prometheus. Reason: {req.reason}")
+            except Exception as e:
+                out["fail_reason"] = f"Failed to connect to Prometheus; {e}"
+                out["reason"] = "unable to connnect"
+                Logging.log.info(f"Failed to connect to Prometheus; {e}")
+
+            return out
+    
+    def run_query_pod_portForward(self, query):
+        if self.core_v1 is None:
+            self.K8s_authenticate()
+        # pf = KubernetesPodPortForward(
+        #     api_object=self.core_v1,
+        #     pod_name=GlobalAttrs.env_prometheus_pod_name,
+        #     pod_port=GlobalAttrs.env_prometheus_pod_port,
+        #     namespace=GlobalAttrs.env_prometheus_pod_namespace)
+        result = self.pf.runQuery(query)
+        return result
+        
+    def get_request_raw_portForward(self, path='/api/v1/query?'):
+        if self.core_v1 is None:
+            self.K8s_authenticate()
+        # pf = KubernetesPodPortForward(
+        #     api_object=self.core_v1,
+        #     pod_name=GlobalAttrs.env_prometheus_pod_name,
+        #     pod_port=GlobalAttrs.env_prometheus_pod_port,
+        #     namespace=GlobalAttrs.env_prometheus_pod_namespace)
+        result = self.pf.sendRequest(path)        
+        return result
+
+    def run_query_prometheus_endpoint(self, query):
         if self.session is None:
             if GlobalAttrs.debug:
                 Logging.log.debug(f"While running a query .. establishing a new connection with Prometheus.")
                 print(f"DEBUG -- While running a query .. establishing a new connection with Prometheus.")
             self.get_session()
         try:
             Logging.log.info(f"Running Query:\n\t\t  => {query}")
@@ -130,39 +353,65 @@
             Logging.log.error(f"Query did NOT run successfully, {e}")
             raise SystemExit(f"> {e}")
         except (requests.exceptions.RequestException) as e:
             print(f"ERROR -- Failed to connect to Prometheus: Connection Failed\n")
             Logging.log.error(f"Query did NOT run successfully, {e}")
             raise SystemExit(f"> {e}")
             
+    def run_query(self, query):
+        if GlobalAttrs.env_connection_method == 'prometheus_endpoint':
+            return self.run_query_prometheus_endpoint(query)
+        elif GlobalAttrs.env_connection_method == 'pod_portForward':
+            if self.core_v1 is None:
+                self.K8s_authenticate()
+            return self.run_query_pod_portForward(query)
+
     def verifyNodeExporter(self):
         """
         not in use at the moment
         """
         output = {
             "success": False,
             "fail_reason": "",
             "result": {}
         }
         try:
             query = 'sum(node_exporter_build_info) by (version)'
-            result = self.run_query(query)
-            if not result.get('status') == 'success':
-                output['fail_reason'] = f"could not get metric value:\n {query}"
-                return output
-
-            if not result.get('data').get('result'):
-                output['fail_reason'] = f"Query did not return any data:\n {query}"
-                return output
-                
-            found_versions= {}
-            for v in result.get('data').get('result'):
-                found_versions[v.get('metric').get('version')] = v.get('value')[1]
-            output['result']['found_versions'] = found_versions
-            output['success'] = True
+            
+            if GlobalAttrs.env_connection_method == 'pod_portForward':
+                result = self.run_query(query)
+                if not result.get('status') == 'success':
+                    output['fail_reason'] = f"could not get metric value:\n {query}"
+                    return output
+
+                if not result.get('data').get('result'):
+                    output['fail_reason'] = f"Query did not return any data:\n {query}"
+                    return output
+                    
+                found_versions= {}
+                for v in result.get('data').get('result'):
+                    found_versions[v.get('metric').get('version')] = v.get('value')[1]
+                output['result']['found_versions'] = found_versions
+                output['success'] = True
+            
+            elif GlobalAttrs.env_connection_method == 'prometheus_endpoint':            
+                result = self.run_query(query)
+                if not result.get('status') == 'success':
+                    output['fail_reason'] = f"could not get metric value:\n {query}"
+                    return output
+
+                if not result.get('data').get('result'):
+                    output['fail_reason'] = f"Query did not return any data:\n {query}"
+                    return output
+                    
+                found_versions= {}
+                for v in result.get('data').get('result'):
+                    found_versions[v.get('metric').get('version')] = v.get('value')[1]
+                output['result']['found_versions'] = found_versions
+                output['success'] = True
 
         except(KeyError, AttributeError) as e:
             output['success']: False
             output['fail_reason'] = e
 
         return output
 
@@ -202,46 +451,50 @@
         
         # Verify node_exporter
         # Check build info
         # Needed results
         # - avaialable not not
         # - version
 
+    
+        # if GlobalAttrs.env_connection_method == 'pod_portForward':
+            # print(self.run_query_pod_portForward('machine_cpu_cores{instance="ip-10-129-184-213.eu-west-1.compute.internal"}'))
+                        
         print("")        
         rich.print("[underline]Verifying Prometheus connection:[/underline] ...                    ", end="\r")
         prometheus_connection = self.verify_prometheus_connection()
         if prometheus_connection['connected']:
             rich.print("[underline]Verifying Prometheus connection:[/underline] [bold green]Connected                     ")
             rich.print_json(data=prometheus_connection)
+            
+            print("")
+            rich.print("[underline]Verifying Prometheus Exporters:[/underline]")
+            print("")
+            rich.print("* Node Exporter:  ...               ", end="\r")
+            verify_node_exporter = self.verifyNodeExporter()
+            if verify_node_exporter.get('success'):
+                rich.print("* Node Exporter:  [bold green]Found           ", end="\r")
+            else:
+                rich.print("* Node Exporter:  [bold red]Not Found           ", end="\r")
+            print("")
+            rich.print_json(data=verify_node_exporter)
+            print("")
+            rich.print("* Kubernetes Exporter: ...         ", end="\r")
+            verify_kubernetes_exporter = self.verifyKubernetesExporter()
+            if verify_kubernetes_exporter.get('success'):
+                rich.print("* Kubernetes Exporter:  [bold green]Found           ", end="\r")
+            else:
+                rich.print("* Kubernetes Exporter:  [bold green]Not Found           ", end="\r")
+            print("")
+            rich.print_json(data=verify_kubernetes_exporter)
+            print(" ")
+        
         else:
             rich.print("[underline]Verifying Prometheus connection:[/underline] [bold red]Unable to connect                     ")
             rich.print_json(data=prometheus_connection)
-            exit(1)
-        
-        print("")
-        rich.print("[underline]Verifying Prometheus Exporters:[/underline]")
-        print("")
-        rich.print("* Node Exporter:  ...               ", end="\r")
-        verify_node_exporter = self.verifyNodeExporter()
-        if verify_node_exporter.get('success'):
-            rich.print("* Node Exporter:  [bold green]Found           ", end="\r")
-        else:
-            rich.print("* Node Exporter:  [bold red]Not Found           ", end="\r")
-        print("")
-        rich.print_json(data=verify_node_exporter)
-        print("")
-        rich.print("* Kubernetes Exporter: ...         ", end="\r")
-        verify_kubernetes_exporter = self.verifyKubernetesExporter()
-        if verify_kubernetes_exporter.get('success'):
-            rich.print("* Kubernetes Exporter:  [bold green]Found           ", end="\r")
-        else:
-            rich.print("* Kubernetes Exporter:  [bold green]Not Found           ", end="\r")
-        print("")
-        rich.print_json(data=verify_kubernetes_exporter)
-        print(" ")
 
 
     def check_metrics(self):
         """
         Checks the existence of the needed metrics
         -> Returns a structured table
         """
```

## Comparing `kptop-0.0.6.dist-info/LICENSE` & `kptop-0.0.7.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `kptop-0.0.6.dist-info/METADATA` & `kptop-0.0.7.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: kptop
-Version: 0.0.6
+Version: 0.0.7
 Summary: A CLI tool that provides Monitoring for Kubernetes resources on the terminal through Prometheus metircs
 Home-page: https://github.com/eslam-gomaa/kptop
 Author: Eslam Gomaa
 License: UNKNOWN
 Platform: UNKNOWN
 Classifier: Programming Language :: Python :: 3.6
 Classifier: Operating System :: OS Independent
```

